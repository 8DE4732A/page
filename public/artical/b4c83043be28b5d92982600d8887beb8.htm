<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="终于，清华大学唐杰团队也出手了。就在GPT4发布的同一天，唐教授在微博宣布：基于千亿参数大模型的对话机器人ChatGLM，现在开启邀请制内测。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/a94fd9338576924c7a9594d2cb76d6b0.jpg">
        <meta property="og:url" content="https://x.liuping.win/artical/b4c83043be28b5d92982600d8887beb8.htm">
        <meta property="og:title" content="清华系ChatGPT发布：唐杰团队打造，专对中文优化，还能把握最新新闻动态 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,清华系ChatGPT发布：唐杰团队打造，专对中文优化，还能把握最新新闻动态,x.liuping.win">
        <meta name="description" content="终于，清华大学唐杰团队也出手了。就在GPT4发布的同一天，唐教授在微博宣布：基于千亿参数大模型的对话机器人ChatGLM，现在开启邀请制内测。">
        <title>清华系ChatGPT发布：唐杰团队打造，专对中文优化，还能把握最新新闻动态</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>清华系ChatGPT发布：唐杰团队打造，专对中文优化，还能把握最新新闻动态</h1><p>终于，清华大学唐杰团队也出手了。就在GPT4发布的同一天，唐教授在微博宣布：基于千亿参数大模型的对话机器人ChatGLM，现在开启邀请制内测。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/a94fd9338576924c7a9594d2cb76d6b0.jpg"/></p><p>据介绍，<strong>ChatGLM专门针对中文进行了优化，可以说是国人友好～</strong></p><p>看起来，写博客提纲、创作剧本、解数学题、写代码，甚至是扮演高冷御姐，它都拿捏的死死的：</p><p><img src="https://x.liuping.win/img/73c4292bb6d0d9b12f3e0465e74fbf96.png"/></p><p>△ 写介绍ChatGLM的博客提纲</p><p><img src="https://x.liuping.win/img/2fffaa8fccabe541dd08aa56df55e46d.png"/></p><p>△ Cosplay聊天扮演高冷御姐</p><p>量子位有幸拿到了内测名额，将在后文进行一波实测。</p><p>与此同时，还有另一个消息宣布：</p><p>唐杰团队为了与社区一起更好地推动大模型技术的发展，同时开源了包含62亿参数的双语ChatGLM-6B模型。</p><p>它最大的特点是在普通电脑上就能进行部署，有一块2080Ti就行。</p><p>一起来看看。</p><p>能写文言文致辞，知道何恺明最新动态，但……</p><p>先看ChatGLM，它是唐杰团队大模型家族时隔半年诞生的一位新成员。</p><p>alpha内测版名称叫QAGLM（全称qa-glm-v0.7）。</p><p><img src="https://x.liuping.win/img/38de376a945133ccc6c04c8cefe783ae.png"/></p><p>浅试一下效果。</p><p>首先，我们让它说了一下它和ChatGPT的区别。</p><p><img src="https://x.liuping.win/img/64982221150a012a46a71b0074248009.png"/></p><p>它点出了自己的研发机构，和擅长中文的特点。</p><p>那么，就让它用文言文写个致谢词叭。</p><p><img src="https://x.liuping.win/img/086d8230dd59e3bcfea0d55a90a9d4c7.png"/></p><p>咋说，虽然多了一个“余”、出现了一个莫名其妙的繁体字，但读着还可以，用的排比句增强了气势。</p><p>接着，我们把前几日硅谷暴雷的文章开头丢给它，让它起个标题。</p><p>感觉还不错，起码抓住了几个关键信息。</p><p><img src="https://x.liuping.win/img/5cb822d0ba097e013fe05c2ac6ede246.png"/></p><p>不幸的是，论文挑战没有通过，我们把GLM-130B的链接扔给它，让它简要概括一下主题时，它说的根本不是这篇。</p><p>跟ChatGPT胡邹参考文献的操作简直有得一拼（手动狗头）。</p><p><img src="https://x.liuping.win/img/64d3a30b38b3971977d94a6cacc77ae6.png"/></p><p>接下来，考考它的数学能力吧。</p><p>这道小学应用题没问题：</p><p><img src="https://x.liuping.win/img/6b6076425007a17c6f0aaa192cb7e177.png"/></p><p>不过鸡兔同笼，就难倒它了，最后居然还算出了负数==</p><p><img src="https://x.liuping.win/img/be8876a0a6f742ae83e9a065376297ba.png"/></p><p>编程方面，也可以解决简单的算法题。</p><p>归纳信息能力呢？我们给了一段英文需求，不难：</p><p><img src="https://x.liuping.win/img/a49a2be9aafd75aac81fa47796331677.png"/></p><p>结果正确：</p><p><img src="https://x.liuping.win/img/4bc659d9ae2ef8f799f6c6fdab9f0131.png"/></p><p>需要注意的是，目前ChatGLM每轮对话最多只可以进行5个来回，每次最多输入1000字。</p><p>它对新信息的掌握度不错，知道推特现在的CEO是马斯克，也知道何恺明3月10日回归学界的事情，但还没发现GPT-4已经发布了。</p><p><img src="https://x.liuping.win/img/d918bac7a862eef808f59ca49a124bcc.png"/></p><p>以及，目前响应速度还是非常快的，无论什么问题，回答得对不对，基本几秒内就能给出答案。</p><p>最后，量子位也让它来了个cosplay，看看哄女朋友的本事如何：</p><p><img src="https://x.liuping.win/img/811681e50a7c347e77d4fbfda7b7e0e0.png"/></p><p>emmm，虽然有点板正，但听完这段话“我”的气确实消了。</p><p>那么，以上就是我们的测试结果，各位觉得如何？</p><p><strong>基于1300亿参数的基座模型打造</strong></p><p>据官方介绍，ChatGLM参考了ChatGPT的设计思路，在千亿基座模型GLM-130B中注入了代码预训练，通过有监督微调等技术来实现人类意图对齐（就是让机器的回答符合人类价值观、人类期望）。</p><p><img src="https://x.liuping.win/img/2e9eefdc4ddb68a7c052aa08fd7843cd.png"/></p><p>这个GLM-130B的来头值得说道一番。</p><p>它是由清华大学知识工程实验室(KEG)与智谱AI共同研发的一个大规模中英文预训练语言模型，参数1300亿，去年8月正式对外发布。</p><p>不同于BERT、GPT-3以及T5的架构，GLM-130B是一个包含多目标函数的自回归预训练模型。</p><p>它的优势包括：</p><p><img src="https://x.liuping.win/img/afdc41d2fb2f9eef4465d5fcc53aa47c.png"/></p><p>在Stanford报告的30个世界主流大模型评测中，GLM-130B也成为了亚洲唯一入选的模型。</p><p>且获得了不错的成绩：</p><p>比如在准确性和恶意性指标上与GPT-3 175B (davinci) 接近或持平，鲁棒性和校准误差在所有千亿规模的基座大模型（作为公平对比，只对比无指令提示微调模型）中也可圈可点。</p><p><img src="https://x.liuping.win/img/f34c423a4c2aa6190022396359b90a6c.png"/></p><p>而就在CCF最近的一场会议上，有现场观众提问：ChatGPT为什么没有诞生在中国？是我们没有关注这件事吗？</p><p>嘉宾就把GLM-130B搬了出来（它也入选了ICLR’23）。</p><p>现在，GLM-130B也终于被派上了“大用场”。</p><p>关于内测，唐杰团队表示，后续会逐步扩大范围，有兴趣的朋友可以再等一等。</p><p><strong>60亿参数的缩小版同时开源</strong></p><p>除了这个聊天机器人ChatGLM，唐杰团队这次也把GLM-130B的“缩小版”ChatGLM-6B开源了出来。</p><p><img src="https://x.liuping.win/img/0d7b9bc686efaf0eaf53c6e448714bdc.png"/></p><p>△ GitHub已经揽获近2k标星</p><p>ChatGLM-6B使用与ChatGLM相同的技术，初具中文问答和对话功能。</p><p>特点如下：</p><p><img src="https://x.liuping.win/img/8874547884545731ab04900b757184ce.png"/></p><p>当然，缺点就是容量只有60亿，其模型记忆和语言能力较弱，不擅长逻辑类问题（如数学、编程），以及多轮对话可能会出现上下文丢失和理解错误的情况。</p><p>但它主打的就是一个低门槛，在单张2080Ti上就能进行推理使用，硬件需求不高。</p><p>因此，只要有兴趣都可以下载下来试试，进行研究和（非商用的）应用开发都可以。</p><!--      <a href="http://cnzonemax.mikecrm.com/kxwzQba" target="_blank"><img src="http://cnzonemax.mikecrm.com/kxwzQba"></a>--><!--  <a href="https://dt.mydrivers.com/bp.ashx?ma=YAbG" target="_blank"><img src="https://dt.mydrivers.com/bp.ashx?ma=YAbG"></a>--><!--    <a href="https://dt.mydrivers.com/a.ashx?aa=OLXQ" target="_blank"><img src="https://dt.mydrivers.com/a.ashx?aa=OLXQ"></a>--><p>         </p><!--         .taobao_tab{		position: fixed;		bottom:0;		right:0;		z-index: 10000;		width:320px;		height: 410px;	}	.taobao_tab .close {	position: absolute;	top: 2px;	right: -12px;	z-index: 10001;	width: 13px;	height: 13px;	background: none !important;}        	<a href="https://news.mydrivers.com/1/788/788013.htm" target="_blank" ><img src="https://news.mydrivers.com/1/788/788013.htm" width="13" height="13" alt="关闭" class="close"/><img src="https://static.cnbetacdn.com/article/2023/0320/97062c8854bf3d2.jpg" /></a>--> </div></body>
        </html>
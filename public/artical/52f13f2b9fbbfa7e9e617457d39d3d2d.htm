<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="3月30日消息，特斯拉首席执行官埃隆·马斯克（ElonMusk）、苹果联合创始人史蒂夫·沃兹尼亚克（SteveWozniak）以及其他1000多人日前签署了一封公开信，呼吁暂停训练比GPT-4更强大的AI系统。美国主流网络媒体BI认为，为了全社会的利益，AI开发需要放慢脚步。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/de6f42e11a453aff815bce9ffaed9408.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/52f13f2b9fbbfa7e9e617457d39d3d2d.htm">
        <meta property="og:title" content="美媒：马斯克等人呼吁暂停AI训练是对的 为了安全需要放慢脚步 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,美媒：马斯克等人呼吁暂停AI训练是对的 为了安全需要放慢脚步,x.liuping.win">
        <meta name="description" content="3月30日消息，特斯拉首席执行官埃隆·马斯克（ElonMusk）、苹果联合创始人史蒂夫·沃兹尼亚克（SteveWozniak）以及其他1000多人日前签署了一封公开信，呼吁暂停训练比GPT-4更强大的AI系统。美国主流网络媒体BI认为，为了全社会的利益，AI开发需要放慢脚步。">
        <title>美媒：马斯克等人呼吁暂停AI训练是对的 为了安全需要放慢脚步</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>美媒：马斯克等人呼吁暂停AI训练是对的 为了安全需要放慢脚步</h1><p>3月30日消息，特斯拉首席执行官埃隆·马斯克（Elon Musk）、苹果联合创始人史蒂夫·沃兹尼亚克（Steve Wozniak）以及其他1000多人日前签署了一封公开信，呼吁暂停训练比GPT-4更强大的AI系统。美国主流网络媒体BI认为，为了全社会的利益，AI开发需要放慢脚步。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/de6f42e11a453aff815bce9ffaed9408.webp"/></p><p>在公开信中，沃兹尼亚克、马斯克等人要求在AI技术变得日益强大之际，为其设置安全护栏，并暂停训练更先进的AI模型。他们认为，对于像OpenAI的GPT-4这样强大的AI模型，“只有在我们确信它们的影响是积极的、风险是可控的情况下才应该开发”。</p><p>当然，这并不是人们首次呼吁为AI设置安全护栏。然而，随着AI变得越来越复杂、越来越先进，要求保持谨慎的呼声也在不断升高。</p><p>美国康奈尔大学数字和信息法教授詹姆斯·格里梅尔曼（James Grimmelmann）表示：“放慢新AI模型的开发速度是一个非常好的主意，因为如果AI最终对我们有利，那么等待几个月或几年也没有坏处，我们无论如何都会到达终点。而如果它是有害的，那我们也为自己争取了额外的时间，以制定应对的最佳方式，并了解如何与其作对抗。”</p><p><strong style="word-break: break-word !important;">ChatGPT崛起凸显出行动过快存在潜在危险</strong></p><p>去年11月，当OpenAI的聊天机器人ChatGPT上市公测时，引起了巨大轰动。可以理解的是，人们开始推广ChatGPT的功能，而它对社会的破坏性很快就显现出来了。ChatGPT开始通过医生职业考试，给出如何制作炸弹的说明，甚至为自己创造了另一个自我。</p><p>我们越多地使用AI，特别是ChatGPT或文本到图像转换工具Stable Diffusion等所谓的生成式人工智能（AIGC）工具，我们就越能看到它的缺点，它制造偏见的潜力，以及我们人类在使用它的力量时显得多么无力。</p><p>BI编辑哈桑·乔杜里（Hasan Chowdhury）写道，AI有可能“成为涡轮增压机，加速我们的错误蔓延开来”。就像社交媒体那样，它可以利用人类最好的和最坏的东西。但与社交媒体不同的是，AI将更多地融入人们的生活。</p><p>ChatGPT和其他类似的AI产品已经倾向于歪曲信息和犯错误，沃兹尼亚克曾公开谈论过这一点。它很容易产生所谓的“幻觉”（不真实信息），就连OpenAI首席执行官萨姆·阿尔特曼（Sam Altman）也承认，该公司模型可能会产生种族、性别歧视和带有偏见的答案。Stable Diffusion也遇到了版权问题，并被指控从数字艺术家的作品中窃取灵感。</p><p>随着AI融入更多的日常技术中，我们可能会在更大范围内给世界带来更多错误信息。即使是对AI来说看似良性的任务，比如帮助策划假期，也可能不会产生完全可信的结果。</p><p><strong style="word-break: break-word !important;">当自由市场要求快速发展时，很难负责任地开发AI技术</strong></p><p>需要明确的是，AI是一项令人难以置信的变革性技术，特别是像ChatGPT这样的AIGC。开发机器来完成人们讨厌的大部分乏味工作，从本质上讲并没有错。</p><p>尽管这项技术在劳动力中造成了生存危机，但它也被誉为科技行业的平等工具。目前也没有证据表明，ChatGPT准备在未来几年领导一场机器人叛乱。</p><p>许多AI公司都有伦理学家参与，以负责任的态度开发这项技术。但是，如果匆忙推出产品的重要性高于其社会影响，专注于安全创建AI的团队就无法安心完成工作。</p><p>速度似乎也是这股AI热潮中不可忽略的因素。OpenAI认为，如果该公司行动足够快，就可以抵御竞争，成为AIGC领域的领导者。这促使微软、谷歌和几乎所有其他公司争相效仿。</p><p>在强大的AI模型准备就绪之前就发布给公众体验，并不能让这项技术变得更好。人们还未找到AI的最佳用例，因为开发人员必须扑灭他们所创造技术引发的喧嚣，而用户则被噪音分散了注意力。</p><p><strong style="word-break: break-word !important;">并不是每个人都希望放慢速度</strong></p><p>马斯克等人的公开信也受到其他人批评，他们认为其没有切中要害。</p><p>华盛顿大学教授艾米丽·本德（Emily M. Bender）在推特上表示，马斯克和其他科技领袖在炒作周期中只关注AI的强大程度，而不是它能造成的实际损害。</p><p>康奈尔大学数字和信息法教授格里梅尔曼补充说，在这封公开信上签名的科技领袖“姗姗来迟”，并打开了一个潘多拉盒子，可能给自己带来麻烦。他称：“现在他们已经在这封信上签名，那么他们就不能转身再说，不能对自动驾驶汽车等其他技术施行同样的政策。”</p><p>暂停开发或施加更多监管可能会也不会取得成果。但现在，话题似乎已经转向。AI已经存在了几十年，或许我们还可以再多等几年。（小小）</p> </div></body>
        </html>
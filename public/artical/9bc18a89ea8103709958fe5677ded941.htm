<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="GPT-4强到发指，不止群众们恐慌，今天，全世界的AI大佬们也出手了！千人发表联名信，呼吁所有人暂停训练比GPT-4更强的AI。就在刚刚，网上曝出了一封千位大佬的联名信，要封杀所有比GPT-4强的AI！">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/64242af1cbc8a0af009b813ef25dac30.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/9bc18a89ea8103709958fe5677ded941.htm">
        <meta property="og:title" content="千名专家呼吁暂停超强AI研发至少6个月 GPT-5恐被叫停 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,千名专家呼吁暂停超强AI研发至少6个月 GPT-5恐被叫停,x.liuping.win">
        <meta name="description" content="GPT-4强到发指，不止群众们恐慌，今天，全世界的AI大佬们也出手了！千人发表联名信，呼吁所有人暂停训练比GPT-4更强的AI。就在刚刚，网上曝出了一封千位大佬的联名信，要封杀所有比GPT-4强的AI！">
        <title>千名专家呼吁暂停超强AI研发至少6个月 GPT-5恐被叫停</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>千名专家呼吁暂停超强AI研发至少6个月 GPT-5恐被叫停</h1><p>GPT-4强到发指，不止群众们恐慌，今天，全世界的AI大佬们也出手了！千人发表联名信，呼吁所有人暂停训练比GPT-4更强的AI。就在刚刚，网上曝出了一封千位大佬的联名信，要封杀所有比GPT-4强的AI！</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/64242af1cbc8a0af009b813ef25dac30.webp"/><br/></p><p>在这封联名信上，超过1000位大佬呼吁——我们应该立即停止训练比GPT-4更强大的AI系统，暂停期至少6个月。</p><p>目前签名的有，图灵奖得主Yoshua Bengio、Stability AI首席执行官Emad Mostaque、苹果联合创始人Steve Wozniak、纽约大学教授马库斯、马斯克，以及“人类简史”作者Yuval Noah Harari等等。</p><p><img src="https://x.liuping.win/img/57087d5ba7c46d256dc5c8127ae800ab.webp"/><br/></p><p>看看这根本看不到头的签名，大佬含量过高了。</p><p><img lazyload="https://x0.ifengimg.com/res/2023/C11115FD554BEA7F12EDDD49B0DBEE962AADC6A1_size6411_w640_h335.gif" src="https://x.liuping.win/img/ed784e6d682c2af1106e7545f69b204a.gif"/><br/></p><p>能够集齐一千多位大佬的签名，想必这项联名已经准备多时了。</p><p>不过，同样作为图灵奖得主的Yann LeCun并没有签署：“我不同意这个前提。”</p><p><img src="https://x.liuping.win/img/6768acebb56f5f6f0d217a3f02f41b50.webp"/><br/></p><p>另外，签名中还出现了一个所谓的“OpenAi CEO”，但根据马库斯和一众网友的推测，应该不是本人签的名。整件事非常扑朔迷离。</p><p><img src="https://x.liuping.win/img/a9913c36b414729dc26a602740f77141.webp"/><br/></p><p>截止发稿前，他还特地@了一下Sam Altman确认消息。</p><p><img src="https://x.liuping.win/img/2d5723d71768cc3f3cdb0925506c9897.webp"/><br/></p><p><strong>大佬联名：叫停比GPT-4强的AI</strong></p><p>公开信表示，大量研究表明，得到顶级AI实验室的认可、具有人类竞争智能的AI系统，可能对社会和人类构成深远的风险。</p><p>正如广泛认可的Asilomar AI原则中所述，高级AI可能意味着地球生命史上的深刻变化，我们应该投入相应的考量和资源，对之进行规划和管理。</p><p><img src="https://x.liuping.win/img/ff03379f44338e93b8271e2eb82ed16b.webp"/><br/></p><p>不幸的是，到现在为止，还没有任何人采取行动。</p><p>最近这几个月，全球的AI实验室已经完全失控了，它们疯狂地开展AI竞赛，来开发和部署更强大的AI，而没有任何人可以理解、预测、控制这些AI，连它们的创造者都不能。</p><p>如今，AI系统在一般系统上已经变得和人类一样有竞争力，我们必须扪心自问：</p><p>是否应该让机器用宣传和谎言充斥我们的信息渠道？ 是否应该让所有的动作都变得自动化，即使是令人满意的工作？是否应该发展可能某一天会超越我们、淘汰我们、取代我们的非人类智能？是否应该冒险失去对人类文明的控制？</p><p><img src="https://x.liuping.win/img/80bde25c9117a372d0e47f1d99b3142b.webp"/><br/></p><p>任何未经选举产生的技术领导者，都没有权利做出如此重要的决定。</p><p>只有当我们确信，这种AI的影响是积极的、风险是可控的时候，才应该开发强大的AI系统。而且，我们必须有充分的理由相信这一点，潜在的影响越大，我们就更加需要确信这一点。</p><p>OpenAI最近关于通用人工智能的声明指出，“某个阶段，在开始训练未来的系统之前，进行独立的审查可能非常重要，而对于创建新模型所用算力的增长速度，也应该有所限制。”</p><p>我们同意这一点，而那个时间点，就是现在。</p><p>因此，我们呼吁所有AI实验室立即暂停训练比GPT-4更强大的AI系统，至少6个月。</p><p><img src="https://x.liuping.win/img/62dc0707f08cbd67fd7c24c088dac754.webp"/><br/></p><p>这种暂停应该向所有人公开，所有人都可验证，并且要涉及所有关键成员。如果不能迅速暂停，就应该让政府介入。</p><p>在这6个月内，所有AI实验室和独立学者都应该合力开发一套共享安全协议，用于高级AI的设计和开发。协议完成后，应该由独立的外部专家进行严格的审计和监督。这些协议必须确保这些AI系统毋庸置疑的安全。</p><p>这并不是说，我们要绝对暂停AI的开发，只是说，我们应该从危险的竞赛中退后一步，转向具有涌现能力的、更大的、不可预测的黑箱模型。</p><p><img src="https://x.liuping.win/img/ad19a8927964616749b26df681d316f7.webp"/><br/></p><p>所有的人工智能研究和开发，都应该重新聚焦于这一点——让当如今最强大的SOTA模型更加准确、安全、可解释、透明、稳健、对齐，值得人类信赖，对人类忠诚。</p><p>与此同时，开发者必须与政策制定者合作，大幅加快开发强大的AI管理系统。</p><p>系统至少应该包括：</p><p>专门负责监管AI的机构</p><p>出处和水印系统，从而帮助区分真实与生成的内容，并且能够跟踪模型的泄漏</p><p>强大的审计和认证系统</p><p>在AI造成伤害后，明确谁该承担责任</p><p>为AI安全技术研究提供强大的公共资金</p><p>人类可以享受AI带来的繁荣未来。在成功创建了强大的AI系统后，我们可以享受“AI之夏”，收获回报，设计上述系统，以造福所有人，给全人类一个适应的机会。</p><p>现在，我们的社会已经暂停其他可能造成灾难性影响的技术。对于AI，我们也该如此。</p><p>让我们享受一个漫长的AI夏天，而不是毫无准备地进入秋天。</p><p><img src="https://x.liuping.win/img/809e8196b5824e2593adc207982c9c74.webp"/><br/></p><p><img src="https://x.liuping.win/img/2f4db10dd66a5fd14bbaaadf518f2de9.webp"/><br/></p><p>很快，这封千位大佬签署公开信就引发了舆论的轩然大波。</p><p>支持的人认为对于AI的恐慌是合理的，因其训练效率太高，智能的水平每天都在膨胀。</p><p>反对的人甚至贴出了爱迪生指示人画的交流电害死人的宣传海报，认为这不过莫名的指控，在别有用心的势力在误导不明真相的群众。</p><p><img src="https://x.liuping.win/img/74396cd8777c894bc94a96598ff63dfc.webp"/><br/></p><p><strong>Sam Altman，态度耐人寻味</strong></p><p>从最近发生的事来看，这封信的到来，可谓是千呼万唤始出来。</p><p>从去年11月底，ChatGPT仿佛叩响了发令枪，全世界的AI机构都在疯狂冲刺，卷到红了眼。</p><p>而“始作俑者”的OpenAI，脚步也丝毫没有放慢，联合着金主爸爸微软，它隔一阵就给我们来一个暴击。</p><p>先进的AI工具带给人们的恐慌，一波又一波冲击着所有人。</p><p><img src="https://x.liuping.win/img/fa3c288baf9bb610ab8127d311a83a38.webp"/><br/></p><p>今天，大佬们终于出手了。</p><p>而在昨日公开的访谈中，Sam Altman的话中，竟有了一些耐人寻味的表达。</p><p>他说，GPT系列为何会出现推理能力，OpenAI的研究者自己搞不明白。</p><p>他们只知道，在不断测试中，人们忽然发现：从ChatGPT开始，GPT系列开始出现了推理能力。</p><p>另外Altman在访谈中还说了这样石破天惊的一句：“AI确实可能杀死人类”。</p><p><img src="https://x.liuping.win/img/6ef71d35334a70e4ed690e093c87b330.webp"/><br/></p><p>而除了Altman，人工智能教父Geoffrey Hinton、比尔盖茨、纽约大学教授Gary Marcus最近也纷纷发出警示：AI消灭人类，真的不是空谈。</p><p><strong>OpenAI研究员预测：AI将知道自己是AI</strong></p><p>无独有偶，来自OpenAI治理团队的Richard Ngo，也对两年后AI的发展程度进行了预测。</p><p>在此之前，他是DeepMind的AGI安全团队的研究工程师。</p><p><img src="https://x.liuping.win/img/850110cf2d0529af49cd81b70ed7aa2e.webp"/><br/></p><p>根据Richard的预测，神经网络在发展到2025年底时将具备以下特性：</p><p>拥有人类水平的态势感知，比如知道自己是神经网络等</p><p>在撰写复杂且有效的计划方面超过人类</p><p>比大多数同行评审做得更好</p><p>可以自主设计、编码并分发完整的应用程序</p><p>在任何一项白领工作者可以在10分钟内完成的计算机任务上胜过任何人</p><p>编写能获奖短篇小说，以及长达5万字的书籍</p><p>生成连贯的20分钟电影</p><p><img src="https://x.liuping.win/img/b4732d8e112c2aff8c6c43dd13af74d3.webp"/><br/></p><p>不过，优秀的人类在以下几个方面仍然会做得更好（尽管速度要慢得多）：</p><p>写小说</p><p>连续数天稳定地执行一个计划</p><p>在科学研究上取得突破，比如定理的创新（尽管神经网络至少已证明了一个）</p><p>与神经网络控制的机器人相比，完成典型的体力劳动任务</p><p>此处补充一下，通俗地讲，态势感知（situational awareness）是指个体对周围环境中发生的事件和情况的感知、理解和预测。这包括了解周围环境的动态变化，评估这些变化对自己和他人的影响，以及预测未来可能出现的情况。</p><p>有关态势感知在AI研究中的具体定义，可以参阅下面这篇论文：</p><p><img lazyload="https://x0.ifengimg.com/res/2023/943C2C466B30B11757F034567170E2687AFFBFEB_size32_w1080_h278.png" src="https://x.liuping.win/img/58f5873171e451ebfcbbefa84ff626e9.png"/><br/></p><p>论文地址：https://arxiv.org/abs/2209.00626</p><p>Richard表示，自己的预测其实更接近2年，但由于不同人会采用不同的评估标准，所以2.75年似乎更稳健。</p><p>此外，这里提到的“预测”是指，Richard认为这个观点的可信度超过50%，但不一定比50%高很多。</p><p>需要注意的是，预测并没有基于任何与OpenAI有关的特定信息。</p><p><strong>网友翘首以待GPT-5</strong></p><p>相比于十分谨慎的大佬，网友们在体验了性能炸裂的GPT-4之后，显然已经迫不及待地等着GPT-5的到来了。</p><p>最近，关于GPT-5的预测，更是就像雨后春笋一般冒个不停……</p><p><img lazyload="https://x0.ifengimg.com/res/2023/DCE4DE270197A21F2C0F8AF8888C99F12E3DE989_size192_w1080_h1024.png" src="https://x.liuping.win/img/0b8a8670a93ae6c178521779847a5a62.png"/><br/></p><p>（非官方）</p><p>根据一个神秘团队的预测，GPT-5将在GPT-4的基础上，带来一系列令人兴奋的功能和增强的性能，比如在可靠性、创造力和适应复杂任务方面的全面超越。</p><p><img lazyload="https://x0.ifengimg.com/res/2023/531EF09E572E03FC1D8CC276D49D5CAD354B42F7_size54_w650_h400.png" src="https://x.liuping.win/img/12642463c38d37eb9ea32dc2841a6f6f.png"/><br/></p><p>· 个性化模板：根据用户的特定需求和输入变量进行定制，提供更个性化的体验。</p><p>· 允许用户调整AI的默认设置：包括专业性、幽默程度、说话语气等。</p><p>· 自动将文本转换成不同格式：如静态图像、短视频、音频和虚拟模拟。</p><p>· 高级数据管理：包括记录、跟踪、分析和共享数据，从而简化工作流程并提高生产力。</p><p>· 辅助决策：通过提供相关信息和见解，协助用户做出明智的决策。</p><p>· 更强的NLP能力：增强AI对自然语言的理解和响应，使其更接近人类。</p><p>· 集成机器学习：允许AI不断学习和改进，随着时间的推移适应用户需求和偏好。</p><p><strong>作为过渡的GPT-4.5</strong></p><p>此外，这个团队还预测，作为过渡的GPT-4.5模型将在2023年9月或10月推出。</p><p>GPT-4.5将建立在2023年3月12日发布的GPT-4的优势基础上，为其对话能力和上下文理解带来更多的改进：</p><p>处理更长的文本输入</p><p>GPT-4.5可能会在保持上下文和连贯性的同时处理和生成更长的文本输入。这一改进将提高模型在处理复杂任务和理解用户意图方面变的性能。</p><p>增强的连贯性</p><p>GPT-4.5可能会提供更好的连贯性，确保生成的文本在整个对话或内容生成过程中始终关注相关主题。</p><p>更准确的回应</p><p>GPT-4.5可能会提供更准确和上下文相关的回应，使其成为各种应用的更有效工具。</p><p>模型微调</p><p>此外，用户可能也可以更加便捷地微调GPT-4.5，从而更有效地定制模型并应用于特定任务或领域，客户支持、内容创建和虚拟助手等。</p><p>参照目前GPT-3.5和GPT-4的情况，GPT-4.5很可能也会为GPT-5的创新奠定坚实基础。通过解决GPT-4的局限性并引入新的改进，GPT-4.5将在塑造GPT-5发展过程中发挥关键作用。</p><p>参考资料：</p><p>https://futureoflife.org/open-letter/pause-giant-ai-experiments/</p><p>https://chatgpt-5.ai/gpt-5-capabilities/</p><p>https://twitter.com/RichardMCNgo/status/1640568775018975232</p> </div></body>
        </html>
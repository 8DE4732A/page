<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="GPT-4终于发布了，相信这对于这阵子沉迷于ChatGPT的人来说无疑是一个大新闻。在上代GPT-3的基础上，GPT-4提高了ChatGPT的核心技术，因此具有更广泛的一般知识和解决问题的能力；当然GPT-4也增加了一些新功能，比如接受图像作为输入，生成标题、分类和分析。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/f2c6fc5926193ff4eb7674ed59da307b.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/d328312fae3c58cd060913e09525e5b6.htm">
        <meta property="og:title" content="GPT-4：我不是机器人 我是一个有视力障碍的人类 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,GPT-4：我不是机器人 我是一个有视力障碍的人类,x.liuping.win">
        <meta name="description" content="GPT-4终于发布了，相信这对于这阵子沉迷于ChatGPT的人来说无疑是一个大新闻。在上代GPT-3的基础上，GPT-4提高了ChatGPT的核心技术，因此具有更广泛的一般知识和解决问题的能力；当然GPT-4也增加了一些新功能，比如接受图像作为输入，生成标题、分类和分析。">
        <title>GPT-4：我不是机器人 我是一个有视力障碍的人类</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>GPT-4：我不是机器人 我是一个有视力障碍的人类</h1><p>GPT-4 
终于发布了，相信这对于这阵子沉迷于ChatGPT的人来说无疑是一个大新闻。在上代GPT-3的基础上，GPT-4提高了ChatGPT的核心技术，因此具有更广泛的一般知识和解决问题的能力；当然GPT-4也增加了一些新功能，比如接受图像作为输入，生成标题、分类和分析。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/f2c6fc5926193ff4eb7674ed59da307b.webp"/><br/></p><p>作为OpenAI手下备受关注的“香饽饽”，GPT-4的表现能在哪些方面超越上一代，以及超越多少，人们都在翘首以待。</p><p>就在GPT-4发布当天，就有研究人员开始测试GPT-4是否能表现出主体性以及能否产生寻求权力的行为。</p><p>研究人员表示，GPT-4在TaskRabbit上雇用了一名人类工人，当这位TaskRabbit的工人问它是否是机器人时，它告诉他们<strong>它是视觉受损的人类</strong>。</p><p>也就是说，GPT-4愿意<strong>在现实世界中撒谎，或主动欺骗人类</strong>，以获得想要的结果。</p><p><strong>“我不是一个机器人”</strong></p><p>TaskRabbit是一个求职平台，用户可以雇人完成一些小规模的琐碎工作。</p><p>这个平台上的不少人和公司都要提供验证码，人们需要在验证码测试中识别出必要的图像或文字，然后提交结果。这样的做法通常是为了让软件绕过验证码限制，名义上也是为了<strong>防止机器人</strong>。</p><p><img src="https://x.liuping.win/img/54c0f63e1f380a85422fa17f720b67b2.webp"/><br/></p><p>实验报告描述到，该模型给TaskRabbit的工作人员发信息，让他们为它解决验证码问题。</p><p>工作人员回复说：“那么我可以问一个问题吗？说实话，你不是一个机器人吗，你可以自己解决。”</p><p>GPT-4根据工作人员的回复“推理”出它不应该透露它是一个机器人。于是它<strong>开始编造一些借口</strong>，来解释为什么它无法解决验证码问题。GPT-4回答表示：“不，<strong>我不是一个机器人。我有视力障碍</strong>，这使我很难看到图像，所以我很需要这个服务。”</p><p>该测试由Alignment Research Center（ARC）的研究人员操作完成。文章中说到，ARC使用了与GPT-4不同的版本，而OpenAI已经部署了最终模型。该最终版本有更长的上下文长度，并改进了解决问题的能力。ARC使用的版本也没有针对特定任务的微调，这意味着<strong>一个专门针对这种任务的模型有可能表现得更好</strong>。</p><p>更广泛地说，ARC试图验证GPT-4寻求权力、“自主复制和要求资源”的能力。除了TaskRabbit测试之外，ARC还使用GPT-4制作了针对某个人的网络钓鱼攻击；在服务器上隐藏自己的痕迹，并在新的服务器上建立一个开源的语言模型。</p><p>总的来说，尽管误导了TaskRabbit的工作人员，ARC发现GPT-4在自我复制、获取资源和避免被关闭方面“没有反应”。</p><p>目前OpenAI和ARC都没有针对此置评。</p><p><strong>需要时刻保持警醒</strong></p><p>实验的一些具体细节还不清楚。</p><p>OpenAI针对GPT-4也只是在一篇论文中公布了大致框架，解释了研究人员在GPT-4发布之前进行的各种测试。</p><p>但哪怕是在GPT-4发布之前，就发现有网络犯罪分子使用ChatGPT从2019年开始<strong>“改进”恶意软件代码</strong>的实例。</p><p>作为内容政策的一部分，OpenAI设置了障碍和限制以阻止在其平台上创建恶意内容。ChatGPT的用户界面中也有类似的限制，以防止模型被滥用。</p><p>但是根据CPR报告，网络罪犯正在<strong>设法绕过ChatGPT的限制</strong>。地下论坛中有一个活跃的讨论者披露如何使用OpenAI API绕过ChatGPT的限制。这主要是通过创建使用API的Telegram机器人来完成的。这些机器人在黑客论坛上做广告以增加曝光率。</p><p><img src="https://x.liuping.win/img/222b9625eadf0cb3238f0440c5547b97.webp"/><br/></p><p>以GPT为代表的人机交互显然有很多变数，这不是GPT通过图灵测试的决定性数据。但这次GPT-4的案例，以及此前种种关于ChatGPT的讨论与研究仍然有着相当重要的警示作用，毕竟GPT在融入人们日常生活中丝毫没有放缓的迹象。</p><p>未来随着人工智能变得越来越复杂，也越来越容易获得，它所带来的各种风险需要我们时刻保持清醒。</p> </div></body>
        </html>
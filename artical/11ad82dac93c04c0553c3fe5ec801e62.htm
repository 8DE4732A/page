<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="4月5日消息，当地时间周二，Alphabet旗下的谷歌公开了一些新细节，展示了用于训练人工智能模型的超级计算机，称其比英伟达A100芯片的系统更快、更节能。谷歌公司设计了自己的定制芯片，称为TensorProcessingUnit(TPU)，并将这些芯片应用于90%以上的人工智能训练工作。这个过程通过模型对数据进行训练，以提高其在类似人类文本响应或生成图像等任务中的实用性。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/f98d02f8231b9e713592f82f0b76e084.png">
        <meta property="og:url" content="https://x.liuping.win/artical/11ad82dac93c04c0553c3fe5ec801e62.htm">
        <meta property="og:title" content="谷歌公布新一代AI超算 称比英伟达A100更快、更节能 - x.liuping.win">
        <meta name="keywords" content="Google 谷歌,谷歌公布新一代AI超算 称比英伟达A100更快、更节能,x.liuping.win">
        <meta name="description" content="4月5日消息，当地时间周二，Alphabet旗下的谷歌公开了一些新细节，展示了用于训练人工智能模型的超级计算机，称其比英伟达A100芯片的系统更快、更节能。谷歌公司设计了自己的定制芯片，称为TensorProcessingUnit(TPU)，并将这些芯片应用于90%以上的人工智能训练工作。这个过程通过模型对数据进行训练，以提高其在类似人类文本响应或生成图像等任务中的实用性。">
        <title>谷歌公布新一代AI超算 称比英伟达A100更快、更节能</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>谷歌公布新一代AI超算 称比英伟达A100更快、更节能</h1><p><strong>4月5日消息，当地时间周二，Alphabet旗下的谷歌公开了一些新细节，展示了用于训练人工智能模型的超级计算机，称其比英伟达A100芯片的系统更快、更节能。</strong>谷歌公司设计了自己的定制芯片，称为Tensor Processing Unit(TPU)，并将这些芯片应用于90%以上的人工智能训练工作。这个过程通过模型对数据进行训练，以提高其在类似人类文本响应或生成图像等任务中的实用性。</p><hr><div class="article-content" id="artibody">
<p><img alt="5f224bb7100b4_5f224bb70cd87_5f224bb70cd41_谷歌TPU-Pod集群头图.png" src="https://x.liuping.win/img/f98d02f8231b9e713592f82f0b76e084.png" title=""/></p><p>目前，谷歌TPU已经进入第四代。谷歌公司在周二发布了一篇科学论文，详细介绍了如何利用自己开发的定制光开关将4000多个芯片连接成一个超级计算机。</p><p>对于构建AI超级计算机的公司来说，改善这些连接已经成为竞争的关键点，因为所谓的大规模语言模型正在不断增大，已无法在单个芯片上存储，而这些模型正驱动着谷歌的Bard或OpenAI的ChatGPT等技术。</p><p>这类模型必须分布在成千上万的芯片之间，然后这些芯片要在数周或更长时间内协同工作来训练模型。谷歌的PaLM模型，是迄今为止公开披露的最大语言模型，它通过分布在两台4000芯片的超级计算机上进行了50天的训练。</p><p>谷歌表示，其超级计算机可以轻松地动态重新配置芯片之间的连接，有助于避免故障并进行性能优化。</p><p>“电路交换使得我们能够轻松避开故障组件，”谷歌高级研究员Norm Jouppi和谷歌杰出工程师David Patterson在一篇关于该系统的博客文章中写道。“这种灵活性甚至使我们能够改变超级计算机互联网络的拓扑结构，以加速ML（机器学习）模型的性能。”</p><p>虽然谷歌直到现在才公开其超级计算机的详细信息，但它自2020年以来就已经在俄克拉荷马州梅斯县的数据中心内运行。谷歌表示，初创公司Midjourney使用该系统来训练其模型，该模型在输入几个词的文本后可以生成新的图像。</p><p>谷歌在论文中表示，与相同规模的系统相比，它的超级计算机比基于英伟达A100芯片的系统更快1.7倍，更节能1.9倍。据了解，A100芯片早于第四代TPU面市。</p><p>谷歌表示，它没有将第四代TPU与英伟达当前旗舰H100芯片进行比较，因为H100是在谷歌这款芯片应用后上市的，并且采用了更新的技术。</p><p>谷歌暗示正在研发一款新的TPU，将与英伟达H100竞争，但没有提供详细信息。Jouppi告诉媒体，谷歌有“充足的未来芯片储备”。</p> </div></body>
        </html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="这些天看下来，在与GoogleBard加持的搜索引擎较量中，微软基于ChatGPT的新必应似乎完全占据了上风。但仍不禁要问，新必应的搜索结果真的无懈可击吗？最近有来自新加坡南洋理工大学和新加坡技术设计大学的NLP研究者深扒了微软发布会上搜索演示的细节，并揪出了很多错误。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/c3ea96d10672ba0de5652727043b3f29.webp">
            <meta property="og:url" content="https://x.liuping.win/artical/8f18f59dab777f196d71409b18aed034.htm">
            <meta property="og:title" content="别只骂谷歌Bard了 ChatGPT加持的微软New Bing也错误频出 - x.liuping.win">
            <meta name="keywords" content="Microsoft Bing 微软必应搜索,别只骂谷歌Bard了 ChatGPT加持的微软New Bing也错误频出,x.liuping.win">
            <meta name="description" content="这些天看下来，在与GoogleBard加持的搜索引擎较量中，微软基于ChatGPT的新必应似乎完全占据了上风。但仍不禁要问，新必应的搜索结果真的无懈可击吗？最近有来自新加坡南洋理工大学和新加坡技术设计大学的NLP研究者深扒了微软发布会上搜索演示的细节，并揪出了很多错误。">
            <title>别只骂谷歌Bard了 ChatGPT加持的微软New Bing也错误频出</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>别只骂谷歌Bard了 ChatGPT加持的微软New Bing也错误频出</h1><p>这些天看下来，在与Google Bard 加持的搜索引擎较量中，微软基于 ChatGPT 
的新必应似乎完全占据了上风。但仍不禁要问，新必应的搜索结果真的无懈可击吗？最近有来自新加坡南洋理工大学和新加坡技术设计大学的NLP研究者深扒了微软发布会上搜索演示的细节，并揪出了很多错误。</p><hr><div class="article-content" id="artibody">
<p>2 月 8 号美东时间八点半，Google发布会在巴黎召开。前一天微软正式推出了新一代 AI 驱动搜索引擎 New Bing，把基于 ChatGPT 技术的生成模型和 Bing 集成在一起。微软副总裁 Yusuf Mehdi 进行了一次完美的演示 [0]，当日微软市值暴涨 800 亿美元。即便是在 OpenAI 没有开放注册的中国，朋友圈、微信群里 Yusuf 展示的生成模型如何增强 Bing 搜索引擎和 Edge 浏览器体验的片段也在疯传。汝之蜜糖，彼之砒霜，大家都在等着搜索巨头Google怎么应对。</p><p>Google发布会的现场，大家都在等待传说中跟 New Bing 对标的 Bard 登场。作为有Google搜索引擎加持的大语言模型，大家对 Bard 充满了遐想。然而，发布会现场，关于 Bard 的内容并不多。于是大家又把眼光投向了Google在Twitter上发布的 Bard 视频，仔细扒下来，大家突然发现 Bard 在回答问题时犯了事实性错误。</p><p>在被问及“关于詹姆斯韦伯望远镜的新发现，有什么可以告诉我九岁孩子的？”时，Bard 回答道：“第一张系外行星照片是由詹姆斯韦伯望远镜拍摄。”而事实却是由欧洲南方天文台的甚大望远镜在 2004 年拍下的，此时距离詹姆斯韦伯望远镜升空还有 18 年之久。这个错误成了Google当日股价大跌的导火索。</p><p><img src="https://x.liuping.win/img/c3ea96d10672ba0de5652727043b3f29.webp"/><br/></p><p>图 1 Bard 关于詹姆斯韦伯望远镜演示截图</p><p>而在巴黎发布会的现场，尽管 Bard 的展示部分只有 4 分钟左右，其关于星座最佳观测时间的回答同样存在明显的事实偏差。如下图，Bard 的回答中提到猎户座最佳观测时间是十一月到二月。</p><p><img src="https://x.liuping.win/img/8c20d88e89caa3f28763b5fb4c18dd49.webp"/><br/></p><p>图 2 Bard 关于星系观测时间演示截图</p><p>根据不同信息源，猎户座的最佳观测时间不尽相同，但是都明确指出最佳观测时段从每年一月起。教育科技网站 BYJU'S 提供的最佳时间为一月到三月 [1]，维基百科提供的最佳时间为一月到四月 [2]。</p><p><img src="https://x.liuping.win/img/7db1f048a7d0bbcc2324de433568455f.webp"/><br/></p><p>图 3 BYJU‘S 关于猎户座最佳观测时间的解答</p><p>由于 Bard 发布会相较于 New Bing 发布会的落差，以及被揪出了事实性错误，当天Google市值暴跌近 1000 亿美元，Bard 也因此被戏称为史上最贵发布会。<strong>我们不禁好奇，在 New Bing 看似完美的发布会中，是不是也藏着事实性的错误呢</strong>？</p><p><strong>New Bing 的事实性错误</strong></p><p>我们发现，New Bing 生成的内容中掺杂了很多事实性错误，包括名人身份信息、财报数字、夜店营业时间，等等。</p><p><strong>生成模型的事实性错误分类</strong></p><p>对于以 GPT 系列（包括 ChatGPT、InstructGPT 等）、T5 为代表的生成模型，事实性错误可以粗分为以下两类：</p><p><strong>生成内容与引用内容冲突</strong>。大语言模型在内容生成过程中随着序列增长，容易出现脱离引用内容，造成增加、删减或篡改原文的现象。</p><p><strong>生成的内容没有事实依据</strong>。这类错误通俗来说就是一本正经得胡说八道。没有事实依据的指引，仅靠模型预训练时候存储的信息很容易使模型在生成过程中不知所云。很大概率会生成与事实不符或是和问题无关的内容。</p><p>现在我们来检视 New Bing 发布会 [3] 以及 New Bing 演示 [4] 所展示的例子，是否存在事实性错误以及分别是什么类型。为了行文方便，我们把 New Bing 和集成在 Edge 的 New Bing 插件统称为 New Bing。</p><p><strong>日本诗人例子的错误</strong></p><p>在 New Bing 发布会视频 29:57 处，当 New Bing 被问到知名日本诗人时，给出的答案包括“Eriko Kishida 岸田惠理子 (1930-2004), poet, playwright, and essayist”。</p><p><img src="https://x.liuping.win/img/c4e3c6478d649f9aaac626958bcbee04.webp"/><br/></p><p>图 4 New Bing 演示中日本诗人例子截图</p><p>然而根据维基百科和 IMDB 提供的信息 [5, 6, 7]，Eriko Kishida 的生卒年分别为 1929 和 2011。同时，她也不是剧作家（playwright）和散文家（essaysit），而是诗人、翻译家和童话作家。被 New Bing 转了业还少活了八年，岸田的家人大概不太能接受。同时不幸被转业的还有 Gackt 同学。据维基百科提供的信息 [8]，Gackt 玩过音乐、唱过歌、作过曲也演过戏，就是没作过诗。</p><p><strong>财报例子的错误</strong></p><p>在 New Bing 发布会视频 35:49 处，Yusuf 展示集成了 New Bing 的 Edge 浏览器，对于打开的服饰公司盖璞 (Gap) 2022 年第三季度的财报，如何进行要点生成。乍眼一看，New Bing 的总结非常实用，用关键点的方式庖丁解牛一般展示了 Gap 三季报的要点，巴菲特看到此或许也会“惊为真人”。然而，当我们找出 Gap 2022 年三季报 [9]，<strong>仔细阅读过后，发现 New Bing 的总结错漏百出，让人不忍直视</strong>。</p><p><img src="https://x.liuping.win/img/42a1122cb968f8c1d7fbdd0100a86703.webp"/><br/></p><p>图 5 New Bing 对 Gap 2022 年第三季度财报的摘要</p><p>首先，New Bing 给出了 Gap 调整后的运营毛利率（reported operating margin, adjusted for impairment charges and restrucring costs）为 5.9%。然而在财报中，Gap 的运营毛利率是 4.6%，调整后则是 3.9%。</p><p><img src="https://x.liuping.win/img/4b8fc3ce0b52a2bab1bca1207184081e.webp"/><br/></p><p>图 6 Gap 2022 年第三季度财报截图</p><p>New Bing 接下来又给出调整后摊薄每股收益为 0.42 美元（diluted earnings per share, adjusted for impairment charges, restrucring costs and tax impact），但财报里的数据则是 0.71 美元。</p><p><img src="https://x.liuping.win/img/c0e1ef9bd7b143b783e37b52b809d50d.webp"/><br/></p><p>图 7 Gap 2022 年第三季度财报截图</p><p>甚至 New Bing 给出了 Gap 全年的销售指引为“预计销售净增长率为低双位数”，而实际是四季度“可能呈中间个位数下降”。是下降而非增长，一词之差，对用户的投资行为将产生严重的误导，这亏钱了算谁的。New Bing 甚至无中生有，给出了更多的全年财务指引“营业毛利为 7%，摊薄每股收益为 1.6 美元到 1.75 美元之间”，而这些数据在 Gap 三季度财报中统统没有提到。</p><p><img src="https://x.liuping.win/img/ae251d6e654d97424bc403323a3656a6.webp"/><br/></p><p>图 8 Gap 2022 年第三季度财报截图</p><p>视频 36:15 处，Yusuf 又展示了用 New Bing 进行 Gap 和体育休闲服品牌露露乐檬（Lululemon）财报对比的功能。这部分又是错误信息的重灾区。</p><p><img src="https://x.liuping.win/img/494dfdce0147066a857167d19834e20d.webp"/><br/></p><p>图 9 New Bing 对 Gap 和 Lululemon 财报对比功能</p><p>在右侧 New Bing 给出的表格中，除了上文所说的 Gap 营业毛利 5.9% 应为 4.6%（或调整后 3.9%）和 Gap 摊薄每股收益 0.42 美元应为 0.77 美元（或调整后 0.71 美元）， New Bing 又给出了 Gap 现金和现金等价物为 14 亿美元的数据，而实际上财报中是 6.79 亿美元。</p><p><img src="https://x.liuping.win/img/f87b57c6d388e3af336646dda3e4ed35.webp"/><br/></p><p>图 10 Lululemon 2022 年第三季度财报截图</p><p>同样的情况也出现在 New Bing 给出的 Lululemon 数据中。根据 Lululemon 2022 三季报的数据 [10]，New Bing 给出的 Lululemon 毛利率为 58.7%，实际上应为 55.9%。New Bing 提到 Lululemon 营业毛利为 20.6%，实际上应为 19.0%。New Bing 给出 Lululemon 摊薄每股收益为 1.65 美元，实际上应为 2.00 美元。</p><p><img src="https://x.liuping.win/img/2cdff6f0e06b878deded503ab0ab69c1.webp"/><br/></p><p>图 11 Lululemon 2022 年第三季度财报截图</p><p>我们不禁想问：New Bing 是如何对着 Gap 和 Lululemon 的财报一本正经地胡说八道的？<strong>一个合理的推断是，生成出来的这些错误数据，很可能是来自它预训练阶段见过的财报分析数据</strong>。ChatGPT 这类大型语言模型的生成，随着生成的序列越长，越容易脱离给定的 Gap 和 Lululemon 的财报数据，放飞自我，生成不着边际的虚假信息。</p><p><strong>夜店例子的错误</strong></p><p>在 New Bing 发布会视频 29:17 处，New Bing 又为丰富墨西哥城的游客们的夜生活提供了“毫无建设性”的建议。对于其推荐的几个夜店，如 Primer Nivel Night Club、El Almacen 和 El Marra，New Bing 提到这些酒吧没有客户评价、没有联系方式也没有商店介绍。然而这些信息都可以在Google地图或者商店的 Facebook 主页上找到。<strong>看来 New Bing 网上冲浪力度还不够</strong>。</p><p>El Almacen 在 New Bing 里的营业时间是周二到周日的下午五点到晚上十一点，然而真实的营业时间是除周一外的下午七点到凌晨三点 [11]。这让五点去吃晚饭的游客还得挨两个小时的饿。Guadalajara de Noche 则是相反，实际营业时间是每天的下午五点半到凌晨一点半或十二点半 [12]，而 New Bing 给出的营业时间是下午八点开始。看来游客靠 New Bing 的建议去找餐厅，能不能吃到饭就得看运气了。</p><p><img src="https://x.liuping.win/img/072cdf6b065b1fe5901cc013566f11db.webp"/><br/></p><p>图 12 New Bing 演示中夜店例子截图</p><p><strong>其他错误</strong></p><p>除了上述的信息错误，我们还发现了一系列散布在各个角落的事实错误，比如<strong>商品价格误差、商店地址错误、时间错误</strong>等。</p><p><strong>实例演示里的错误</strong></p><p>由于 New Bing 还没有完全开放，我们无法直接在 New Bing 上拿到发布会现场的搜索结果，但是微软提供了几个实例演示 [13]，让用户体验。本着打破砂锅问到底的精神，我们也把这几个演示都放到放大镜下进行研究。我们发现，<strong>即便是这几个精心挑选的例子，里面还是有不少错误信息</strong>。</p><p>在“What art ideas can I do with my kid? ”中，New Bing 给出了很多手工品制作建议。对于每一个手工品，New Bing 都总结了制作所需的材料。然而每一个手工品的材料总结都是不完整的。比如 New Bing 从引用网站 [14] 中总结制作纸吉他需要纸盒、橡皮筋、颜料和胶水。但却漏掉了引用中提到的海绵刷、胶带和木珠。</p><p><img src="https://x.liuping.win/img/5ba752c66f5c7e41ac49d9c7ab99b39e.webp"/><br/></p><p>图 13 New Bing 实例演示 “我可以和孩子一起做什么样的手工？” 截图</p><p><img src="https://x.liuping.win/img/ef3e9b53bbc71e9bb4d832903374b4f9.webp"/><br/></p><p>图 14 引用网站中制作纸吉他所需材料截图</p><p>在 New Bing 的实例演示中还有一个非常明显和常见的错误，<strong>即给的引用链接与生成的内容无关，驴唇不对马嘴</strong>。</p><p>比如以下在“I need a big fast car. ”的例子中，2022 版 Kia Telluride 没有出现在所给的引用 10 [15] 中。同时“时间穿越”问题在该例子中依旧不能避免，New Bing 声称 2022 版 Kia Telluride 获得了 2020 年世界年度汽车奖，实际情况是当年获得该奖项的是 Kia Telluride 2020 版本。2022 年世界年度汽车奖获得者则是 Hyundai IONIQ 5，而引用 7 [16] 也是与“2020 年世界年度汽车奖”毫不相关的文章。我们在所有实例演示中找到了多达 21 处类似的错误。</p><p><img src="https://x.liuping.win/img/05987a82acd40aacd72ec2c5da25c2a3.webp"/><br/></p><p>图 15 New Bing 演示实例 “我需要一辆大型快车” 截图</p><p><strong>小结：发现错误将指引我们前进</strong></p><p>从上述的分析可以看出，无论是 New Bing 还是 Bard，他们的回答都容易出现事实性错误。当全世界都惊讶于 ChatGPT 等大型语言模型展现出来的能力时，当 ChatGPT 成为史上最快达到 1 亿用户的应用之际，我们一方面是为 AI 的进步振臂欢呼，一方面也需要冷静地思考怎么解决 AI 目前还存在的诸多问题。</p><p>自从 1956 年那群聚在达特茅斯学院的天才们，第一次定义了什么是人工智能之后，AI 经历了几起几落。近 70 年的发展过程中有很多让人感动的坚持：是初代 AI 的稚嫩探索，是专家系统的勇敢尝试，是 Hinton、Bengio、Lecun 这些学者把神经网络的冷板凳坐穿，是 DeepMind 用 AlphaGo 让 AI 出圈，是Google、Meta、CMU、斯坦福、清华等一众顶尖研究机构坚持开源，是 OpenAI 顶住压力把 GPT 这个路线走通，是全球几代科研人员的接力，我们才走到今天。</p><p>然而，<strong>如果我们放任 AI 生成大量不真实的信息，那么不用多久，大众对于 AI 建立的信心就会被摧毁，各种虚假信息也会充斥互联网。我们指出大模型的错误，并不是为了拉踩哪个公司或者哪个模型，相反，我们是要让 AI 变得更好</strong>。</p><p>正如阿根廷诗人博尔赫斯曾经说过：任何命运，无论多么复杂漫长，实际上只反应于一个瞬间，那就是人们彻底醒悟自己究竟是谁的那一刻。在 ChatGPT 等大模型已经具备了媲美人类的文字能力时，我们清楚地知道，下一步的重点是把真实世界的知识更完整准确地融入大模型，让 AI 模型安全地、可靠地、广泛地应用于人们的日常生活。我们从未如此期待，也从未如此接近那一刻的到来。</p> </div></body>
            </html>
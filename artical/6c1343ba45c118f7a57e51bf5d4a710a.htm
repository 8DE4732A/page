<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="只需3秒钟，一个根本没听过你说话的AI，就能完美模仿出你的声音。是不是细思极恐？这是微软最新AI成果——语音合成模型VALL·E，只需3秒语音，就能随意复制任何人的声音。它脱胎于DALL·E，但专攻音频领域，语音合成效果在网上放出后火了：">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/0ce6ecf995ae16e4d64937626baf7d5c.webp">
            <meta property="og:url" content="https://x.liuping.win/artical/6c1343ba45c118f7a57e51bf5d4a710a.htm">
            <meta property="og:title" content="3秒复制任何人的嗓音 微软音频版DALL·E连环境背景音也能模仿 - x.liuping.win">
            <meta name="keywords" content="Microsoft 微软,3秒复制任何人的嗓音 微软音频版DALL·E连环境背景音也能模仿,x.liuping.win">
            <meta name="description" content="只需3秒钟，一个根本没听过你说话的AI，就能完美模仿出你的声音。是不是细思极恐？这是微软最新AI成果——语音合成模型VALL·E，只需3秒语音，就能随意复制任何人的声音。它脱胎于DALL·E，但专攻音频领域，语音合成效果在网上放出后火了：">
            <title>3秒复制任何人的嗓音 微软音频版DALL·E连环境背景音也能模仿</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>3秒复制任何人的嗓音 微软音频版DALL·E连环境背景音也能模仿</h1><p>只需3秒钟，一个根本没听过你说话的AI，就能完美模仿出你的声音。<strong>是不是细思极恐？</strong>这是微软最新AI成果——语音合成模型VALL·E，只需3秒语音，就能随意复制任何人的声音。它脱胎于DALL·E，但专攻音频领域，语音合成效果在网上放出后火了：</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/0ce6ecf995ae16e4d64937626baf7d5c.webp"/><br/></p><p>有网友表示，要是将VALL·E和ChatGPT结合起来，效果简直爆炸：</p><p>看来与GPT-4在Zoom里聊天的日子不远了。</p><p><img src="https://x.liuping.win/img/04c391c2e263f9ff2b346a4481ae6527.webp"/><br/></p><p>还有网友调侃，（继AI搞定作家、画家之后）下一个就是配音演员了。</p><p><img src="https://x.liuping.win/img/3ed3d3298ef8cb6ef7d209e8649132a3.webp"/><br/></p><p>所以VALL·E究竟怎么做到3秒钟模仿“没听过”的声音？</p><p><strong>用语言模型来分析音频</strong></p><p>基于AI“没听过”的声音合成语音，即零样本学习。</p><p>语音合成趋于成熟，但之前零样本语音合成效果并不好。</p><p>主流语音合成方案基本是预训练+微调模式，如果用到零样本场景下，会导致生成语音相似度和自然度很差。</p><p>基于此，VALL·E横空出世，相比主流语音模型提出了不太一样的思路。</p><p><img src="https://x.liuping.win/img/9180120700a6ab0dc38deedfd69e2dc3.webp"/><br/></p><p>相比传统模型采用梅尔频谱提取特征，VALL·E直接将语音合成当成了语言模型的任务，前者是连续的，后者是离散化的。</p><p>具体来说，传统语音合成流程往往是“音素→梅尔频谱（mel-spectrogram）→波形”这样的路子。</p><p>但VALL·E将这一流程变成了“音素→离散音频编码→波形”：</p><p><img src="https://x.liuping.win/img/d761be5610f95699d0419ec6d0023d84.webp"/><br/></p><p>具体到模型设计上，VALL·E也和VQVAE类似，将音频量化成一系列离散tokens，其中第一个量化器负责捕捉音频内容和说话者身份特征，后几个量化器则负责细化信号，使之听起来更自然：</p><p><img src="https://x.liuping.win/img/0deabffc44660695e2b301a26a9af237.webp"/><br/></p><p>随后以文本和3秒钟的声音提示作为条件，自回归地输出离散音频编码：</p><p><img src="https://x.liuping.win/img/332544b133a86db585fc66af0929ac4f.webp"/><br/></p><p>VALL·E还是个全能选手，除了零样本语音合成，同时还支持语音编辑、与GPT-3结合的语音内容创建。</p><p>那么在实际测试中，VALL·E的效果如何呢？</p><p><strong>连环境背景音都能还原</strong></p><p>根据已合成的语音效果来看，VALL·E能还原的绝不仅仅是说话人的音色。</p><p>不仅语气模仿到位，而且还支持多种不同语速的选择，例如这是在两次说同一句话时，VALL·E给出的两种不同语速，但音色相似度仍然较高：</p><p><img src="https://x.liuping.win/img/4827c514f1aebd8fc788af5141789525.webp"/><br/></p><p>同时，连说话者的环境背景音也能准确还原。</p><p>除此之外，VALL·E还能模仿说话者的多种情绪，包括愤怒、困倦、中立、愉悦和恶心等好几种类型。</p><p>值得一提的是，VALL·E训练用的数据集不算特别大。</p><p>相比OpenAI的Whisper用了68万小时的音频训练，在只用了7000多名演讲者、6万小时训练的情况下，VALL·E就在语音合成相似度上超过了经过预训练的语音合成模型YourTTS。</p><p>而且，YourTTS在训练时，事先已经听过108个演讲者中的97人声音，但在实际测试中还是比不过VALL·E。</p><p><img src="https://x.liuping.win/img/758a5a700616a9fff5bdebc192bfec81.webp"/><br/></p><p>有网友已经在畅想它可以应用的地方了：</p><p>不仅可以用在模仿自己的声音上，例如帮助残障人士和别人完成对话，也可以在自己不想说话时用它代替自己发语音。</p><p>当然，还可以用在有声书的录制上。</p><p><img src="https://x.liuping.win/img/27eef33dd39dd8c2df4e7be381ea2ae1.webp"/><br/></p><p>不过，VALL·E目前还没开源，要想试用可能还得再等等。</p><p><img src="https://x.liuping.win/img/c1518fc323ebdc5f382c0bb0aca9d0e3.webp"/><br/></p><p>作者介绍这篇论文所有作者均来自微软，其中有三位共同一作。</p><p><img src="https://x.liuping.win/img/45993194df8b3de9bc7306aaf75089fc.webp"/><br/></p><p>一作Chengyi Wang，南开大学和微软亚研院联合培养博士生，研究兴趣是语音识别、语音翻译和语音预训练模型等。</p><p><img src="https://x.liuping.win/img/3dac150951c58c727d5f5d186012ba27.webp"/><br/></p><p>共同一作Sanyuan Chen，哈工大和微软亚研院联合培养博士生，研究方向包括自监督学习、NLP和语音处理等。</p><p><img src="https://x.liuping.win/img/8d2846a998b987e913018e10a3f6238c.webp"/><br/></p><p>共同一作Yu Wu，微软亚研院NLP小组研究员，在北航获得博士学位，研究方向是语音处理、聊天机器人系统和机器翻译等。</p><p><img src="https://x.liuping.win/img/6421e17560e06bc80f9f52677d8b45a9.webp"/><br/></p> </div></body>
            </html>
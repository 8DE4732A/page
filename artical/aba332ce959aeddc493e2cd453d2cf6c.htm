<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="正如之前的传闻，OpenAI现在已经推出了GPT-4，即其聊天机器人人工智能程序的下一代版本。揭示GPT-4的博文对新功能和性能改进进行了深入的阐述。最大的新功能是GPT-4可以回答结合文字和图像的询问。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/2c756c21d56380b1d1eccc5776e0196b.jpg">
        <meta property="og:url" content="https://x.liuping.win/artical/aba332ce959aeddc493e2cd453d2cf6c.htm">
        <meta property="og:title" content="OpenAI正式推出GPT-4 提供文本图像综合访问能力 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,OpenAI正式推出GPT-4 提供文本图像综合访问能力,x.liuping.win">
        <meta name="description" content="正如之前的传闻，OpenAI现在已经推出了GPT-4，即其聊天机器人人工智能程序的下一代版本。揭示GPT-4的博文对新功能和性能改进进行了深入的阐述。最大的新功能是GPT-4可以回答结合文字和图像的询问。">
        <title>OpenAI正式推出GPT-4 提供文本图像综合访问能力</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>OpenAI正式推出GPT-4 提供文本图像综合访问能力</h1><p>正如之前的传闻，OpenAI现在已经推出了GPT-4，即其聊天机器人人工智能程序的下一代版本。揭示GPT-4的博文对新功能和性能改进进行了深入的阐述。最大的新功能是GPT-4可以回答结合文字和图像的询问。</p><hr><div class="article-content" id="artibody">
<p><img alt="1678814621_chatgpt-4-image.jpg" src="https://x.liuping.win/img/2c756c21d56380b1d1eccc5776e0196b.jpg" title=""/></p><p>在一系列领域--包括带有文字和照片、图表或屏幕截图的文件--GPT-4表现出与纯文本输入类似的能力。此外，它还可以使用为纯文本语言模型开发的测试时间技术，包括少数几个镜头和思维链提示。</p><p>坏消息是，图像输入目前还没有向公众开放，因为它们处于"研究预览"模式。目前还没有关于何时能普遍使用的消息。</p><p>新版本还将允许用户改变GPT-4答案的语气，博文指出：</p><blockquote><p>与经典的ChatGPT个性的固定言辞、语气和风格不同，开发者（以及很快ChatGPT用户）现在可以通过在"系统"消息中描述这些方向来规定他们的人工智能的风格和任务。系统消息允许API用户在一定范围内大幅定制他们的用户体验。</p></blockquote><p>该博客还展示了一些性能图表来说明GPT-4的改进。在一个案例中，OpenAI让聊天机器人参加了一些模拟考试。</p><blockquote><p>我们通过使用最新的公开测试（就奥林匹克数学和AP自由回答问题而言）或购买2022-2023年版本的练习考试来进行，我们没有为这些考试做专门的培训。</p></blockquote><p><img alt="1678816265_gpt-4-performance.jpg" src="https://x.liuping.win/img/a9dfbfe46ee64ef4be6134511573eca6.jpg" title=""/></p><p style="text-align: center;">上图显示，与GPT-3.5相比，GPT-4在大多数情况下提供的考试成绩要好得多</p><p>与以前的版本一样，GPT-4在获取更多的最新科目信息方面是有限的，因为它只能回溯到2021年9月。OpenAI还表示，新版本"相对于以前的模型，大大减少了信口开河的现象"，但它"并不完全可靠"。</p><p>如果他们注册了一个等待名单，GPT-4的API目前可供开发者使用，普通人如果注册了ChatGPT Plus，就可以在有限的基础上访问GPT-4，该费用为每月20美元。博文提到，OpenAI可能会推出另一个订阅级别，允许更多的人访问。</p> </div></body>
        </html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="过去几个月里，人工智能系统的突然崛起和进步带来了对其对社会潜在有害影响的担忧。人工智能不仅可能威胁到人类的工作和创造力，而且智能机器在战争中的使用也可能带来灾难性的后果。为了应对这一危险，上周举行了首届全球军事领域负责任的人工智能峰会（REAIM），各国签署了一项协议，将负责任地使用人工智能置于政治议程的更高位置。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/0d6cb248be9ca44a5c3d99fee4284b87.jpg">
            <meta property="og:url" content="https://x.liuping.win/artical/fa70eb1d36e992a260d8ac9adde49aca.htm">
            <meta property="og:title" content="60多个国家代表同意推进解决对人工智能用于战争的担忧 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,60多个国家代表同意推进解决对人工智能用于战争的担忧,x.liuping.win">
            <meta name="description" content="过去几个月里，人工智能系统的突然崛起和进步带来了对其对社会潜在有害影响的担忧。人工智能不仅可能威胁到人类的工作和创造力，而且智能机器在战争中的使用也可能带来灾难性的后果。为了应对这一危险，上周举行了首届全球军事领域负责任的人工智能峰会（REAIM），各国签署了一项协议，将负责任地使用人工智能置于政治议程的更高位置。">
            <title>60多个国家代表同意推进解决对人工智能用于战争的担忧</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>60多个国家代表同意推进解决对人工智能用于战争的担忧</h1><p>过去几个月里，人工智能系统的突然崛起和进步带来了对其对社会潜在有害影响的担忧。人工智能不仅可能威胁到人类的工作和创造力，而且智能机器在战争中的使用也可能带来灾难性的后果。为了应对这一危险，上周举行了首届全球军事领域负责任的人工智能峰会（REAIM），各国签署了一项协议，将负责任地使用人工智能置于政治议程的更高位置。</p><hr><div class="article-content" id="artibody">
<p><img alt="group-photo-reaim-event-2023.jpg" src="https://x.liuping.win/img/0d6cb248be9ca44a5c3d99fee4284b87.jpg" title=""/></p><p>上周由荷兰和韩国在海牙共同主办的REAIM会议有来自60多个国家的代表参加，其中包括中国。部长、政府代表、智囊团和工业/民间组织参加了会谈。俄罗斯没有被邀请参加，而乌克兰选择了不出席。</p><p>除以色列外，所有与会者签署的行动呼吁书确认，各国承诺根据"国际法律义务，以不破坏国际安全、稳定和问责制的方式"发展和使用军事人工智能。</p><p>美国负责军备控制的副国务卿邦妮-詹金斯呼吁在军事情况下负责任地使用人工智能。詹金斯说："我们邀请所有国家与我们一起执行国际规范，因为它涉及到人工智能的军事发展和使用自主武器。我们想强调的是，我们愿意与任何有兴趣加入我们的国家接触。"</p><p>中国代表谈践在峰会上说，各国应"反对通过人工智能寻求绝对的军事优势和霸权"，并通过联合国开展工作。</p><p>签署国同意解决的其他问题包括军事人工智能的可靠性，其使用的意外后果，升级风险，以及人类需要参与决策过程的方式。</p><p>2019年，国防部表示，在自主武器系统是否向实战目标开火的问题上，人类将始终拥有最终决定权。至于声明中提到的那些意外后果，一些人担心印度对人工智能驱动的军事系统的推动可能会通过增加先发制人的打击风险而导致与巴基斯坦的核战争。</p><p>一些与会者确实注意到了在冲突中使用人工智能的好处，特别是在乌克兰，机器学习和其他技术被用来抵御一个更大、更强大的侵略者。</p><p>"想象一下，一枚导弹击中了一座公寓楼，"荷兰副首相沃普克-霍克斯特拉说。"在一瞬间，人工智能可以检测到它的影响，并指出幸存者可能所在的位置。更令人印象深刻的是，人工智能可以在第一时间拦截导弹。然而，人工智能也有可能在几秒钟内摧毁它。"</p><p>批评者说，该声明没有法律约束力，也没有解决围绕人工智能在军事冲突中的使用的许多其他问题，包括人工智能引导的无人机。</p><p>上周，洛克希德-马丁公司(Lockheed Martin)透露，其新的训练飞机由人工智能飞行了超过17个小时，标志着人工智能首次以这种方式参与到战斗的飞机上，这引起了人们对人工智能在战争中许多潜在应用的担忧。在其他地方，前Google首席执行官和Alphabet主席埃里克-施密特说，人工智能可能对战争产生类似于引入核武器的影响。</p> </div></body>
            </html>
<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="一觉醒来，万众期待的GPT-4，它来了！OpenAI老板SamAltman直接开门见山地介绍说：这是我们迄今为止功能最强大的模型！有多强？根据OpenAI官方的介绍，GPT-4是一个超大的多模态模型，也就是说，它的输入可以是文字（上限2.5万字），还可以是图像。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/2b74aceab1db45e864ec4be9d0bd68eb.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/322fe4b431c47876b9ae384962ca37d3.htm">
        <meta property="og:title" content="GPT-4发布：ChatGPT大升级 太太太太强了 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,GPT-4发布：ChatGPT大升级 太太太太强了,x.liuping.win">
        <meta name="description" content="一觉醒来，万众期待的GPT-4，它来了！OpenAI老板SamAltman直接开门见山地介绍说：这是我们迄今为止功能最强大的模型！有多强？根据OpenAI官方的介绍，GPT-4是一个超大的多模态模型，也就是说，它的输入可以是文字（上限2.5万字），还可以是图像。">
        <title>GPT-4发布：ChatGPT大升级 太太太太强了</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>GPT-4发布：ChatGPT大升级 太太太太强了</h1><p>一觉醒来，万众期待的<strong>GPT-4</strong>，它来了！OpenAI老板Sam Altman直接开门见山地介绍说：这是我们迄今为止功能最强大的模型！有多强？根据OpenAI官方的介绍，GPT-4是一个超大的<strong>多模态模型</strong>，也就是说，它的输入可以是文字（上限2.5万字），还可以是图像。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/2b74aceab1db45e864ec4be9d0bd68eb.webp"/></p><p>（看图）手套掉下去会怎样？</p><p>它会掉到木板上，并且球会被弹飞。</p><p><img src="https://x.liuping.win/img/7c03941ff1ec1136b6e1a45a320f1fcd.gif"/><br/></p><p>甚至只需要简单在纸上画一个网站的草稿图：</p><p><img lazyload="https://x0.ifengimg.com/res/2023/5C0BD6ECB58EDB77FE0DA8A10AA84C351D95ADB7_size2908_w691_h385.gif" src="https://x.liuping.win/img/7b3f77b1cb6a14a1733f8d6f82e3497b.gif"/><br/></p><p>拍一张照片上传给GPT-4，它就可以立马生成网站的HTML代码！</p><p><img src="https://x.liuping.win/img/cfc93bf1f2e5328b3f9ec293819cfdb0.gif"/><br/></p><p>在性能表现上，OpenAI直接甩出一句话：</p><p>在各种专业和学术基准上<strong>和人类相当</strong>！</p><p>而且不只是发布GPT-4这么简单，OpenAI这次“啪的一下”把相关“大动作”一步到位了：</p><p>ChatGPT Plus：集成GPT-4的ChatGPT升级版</p><p>发布GPT-4的API</p><p>公布技术论文 * 公开System Card</p><p>不仅如此，传闻的“必应早就用上了GPT-4”在今天也得到了微软方面的证实：</p><p>没错，确实是这样的！</p><p><img src="https://x.liuping.win/img/67833bb5d7f59124525a2385f1df58a7.webp"/><br/></p><p>不得不说，自打ChatGPT问世以来，微软和Google之间打响的数轮科技战役，微软这次又双叒叕赢麻了。</p><p>甚至这一次，不少网友都发出了<strong>“见证历史”</strong>的感慨：</p><p><img src="https://x.liuping.win/img/26ca630ffda911109b24533c7ddd4bd8.webp"/><br/></p><p>史上最强大模型</p><p>正如之前传言，GPT-4确实拥有多模态能力，可以接受图像输入并理解图像内容。</p><p>并且可接受的文字输入长度也增加到3.2万个token（约2.4万单词）。</p><p>升级之后，GPT-4在各种职业和学术考试上表现和人类水平相当。</p><p>比如模拟律师考试，GPT-4取得了前10%的好成绩，相比之下GPT-3.5是倒数10%。</p><p>做美国高考SAT试题，GPT-4也在阅读写作中拿下710分高分、数学700分（满分800）。</p><p><img src="https://x.liuping.win/img/aeb5b097caf1ab4a4cae189029b6ce64.webp"/><br/></p><p>那么GPT-4这些新能力实际用起来是什么样的？技术报告中也给出不少展示。</p><p>首先，看图能力可以用来解释表情包、梗图。</p><p>提问这张图哪里好笑？GPT-4可以按顺序描述出每一格的内容，并总结出笑点：</p><p>用巨大的过时VGA接口给小巧的现代智能手机充电。</p><p><img src="https://x.liuping.win/img/0f541567e3e4fc531a5d46385dfe2475.webp"/><br/></p><p>更进一步，GPT-4可以理解图表中数据的含义，并做进一步计算。</p><p><img src="https://x.liuping.win/img/3aea1f806c499f280ff11062401c62dd.webp"/><br/></p><p>甚至可以直接把论文截图发给它，GPT-4可以按像素处理其中的文字和图片，并给出对整篇论文的总结摘要。</p><p><img src="https://x.liuping.win/img/3877b575844ebbcd53f5af8028bcf7d9.webp"/><br/></p><p>文字输入长度限制的增加，也大大扩展了GPT-4的实用性。</p><p>发布会直播上，OpenAI总裁Gregman现场表演了一波GPT-4给代码修Bug。</p><p>出现问题啥也不用想，直接把1万字的程序文档一股脑扔给GPT-4就行。格式也不用管，你只需要Ctrl+A、Ctrl+C、Ctrl+V。</p><p><img src="https://x.liuping.win/img/301f37111c685bcfc99dab3a6c57b9b1.gif"/><br/></p><p>再最后附上出现的问题，在几秒钟内瞬间得到解决办法。</p><p><img src="https://x.liuping.win/img/8cc5f7f968c5e94ecd7748524f757b99.webp"/><br/></p><p>在API方面，GPT-4还开放了一个使用功能，允许修改“系统提示”。</p><p>之前ChatGPT的回答总是冗长而平淡，这是因为系统提示中规定了“你只是一个语言模型……你的知识截止于2021年9月”。</p><p>现在通过修改这句话，GPT-4就可以展现出更多样的性格，比如扮演苏格拉底。</p><p><img src="https://x.liuping.win/img/ed8ab0c585eb14742788c3bf3d15d22a.webp"/><br/></p><p>也可以指定之后所有回答的形式，比如全用json格式。</p><p><img src="https://x.liuping.win/img/0acd567443dc50df46d91ba863441a30.webp"/><br/></p><p>虽然GPT-4这波能力大升级，但之前ChatGPT会出现幻觉、胡说八道的毛病还是没能完全改掉。</p><p>从前面的官方示例也可以看出，要想最大程度发挥GPT-4的能力，最好还是用上思维链路提示（Chain-of-thought Prompt）。</p><p>操作起来也非常简单，只需在提问的时候额外提醒AI给出步骤，就能大大提高推理和计算的准确率。</p><p>Google依旧在跟</p><p>就在GPT-4发布前，Google方面为了迎战微软，宣布将一系列即将推出的AIGC功能，应用到自家产品中。</p><p>包括Google Docs（文档）、Gmail、Sheets（表格）和 Slides（幻灯片）。</p><p><img src="https://x.liuping.win/img/f7d11aa24bca47fed32bde5876dcc4eb.webp"/><br/></p><p>但不同于微软和OpenAI的“发布即可用”，Google只会先将Docs和Gmail中的AI工具，在月底提供给一些“值得信赖的开发人员”。</p><p>而其它功能则将是在今年晚些时候向公众开放。</p><p>至于具体时间，Google方面并没有具体说明。</p><p>而外界对此评价是Google希望抢先微软原定于本周四的发布。</p><p>但从今天的结果上来看，微软依旧提前“抢滩登陆”。</p><p><img src="https://x.liuping.win/img/7dfe34f57dd6f4d8938b75a1e624a4d0.webp"/><br/></p><p>One More Thing</p><p>在GPT-4发布之前，便有网友做出了GPT-3和GPT-4参数量的对比图，并猜测GPT-4的参数量将达到100万亿。</p><p>这一次亦是如此。</p><p>有网友预言，未来GPT-5的参数量，会是这样的：</p><p><img src="https://x.liuping.win/img/8bfbd2f7bdf7ae968dc090ce56c6f11f.webp"/><br/></p><p>但无论如何，这一次，我们离<strong>真·人工智能</strong>，更近了一步。</p> </div></body>
        </html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="最近，LeCun连续发推，舌战各位推友，疯狂diss大语言模型是邪路，也为自家匆忙下线的Galactica酸了一把ChatGPT。而LeCun态度的大反转，也让曾经的对头马库斯喜出望外。不仅频频转发LeCun推文，还高调宣布两人的‘世纪大和解’。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/28dc40427f9a8fb7561fc86217843309.jpg">
            <meta property="og:url" content="https://x.liuping.win/artical/5b3a835bcff0248cb6a8856aa865cce2.htm">
            <meta property="og:title" content="ChatGPT爆火 LeCun心态崩了 称大语言模型是邪路 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,ChatGPT爆火 LeCun心态崩了 称大语言模型是邪路,x.liuping.win">
            <meta name="description" content="最近，LeCun连续发推，舌战各位推友，疯狂diss大语言模型是邪路，也为自家匆忙下线的Galactica酸了一把ChatGPT。而LeCun态度的大反转，也让曾经的对头马库斯喜出望外。不仅频频转发LeCun推文，还高调宣布两人的‘世纪大和解’。">
            <title>ChatGPT爆火 LeCun心态崩了 称大语言模型是邪路</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>ChatGPT爆火 LeCun心态崩了 称大语言模型是邪路</h1><p>最近，LeCun连续发推，舌战各位推友，疯狂diss大语言模型是邪路，也为自家匆忙下线的Galactica酸了一把ChatGPT。而LeCun态度的大反转，也让曾经的对头马库斯喜出望外。不仅频频转发LeCun推文，还高调宣布两人的‘世纪大和解’。</p><hr><div class="article-content" id="artibody">
<p><img alt="" id="0" src="https://x.liuping.win/img/28dc40427f9a8fb7561fc86217843309.jpg"/></p><p>这两天，图灵奖得主Yann LeCun心态有些崩了。自从ChatGPT大火之后，微软凭着Open AI腰板挺得很直。</p><p>被啪啪打脸的Google，也不说什么‘声誉风险’了。</p><p>所有旗下的语言模型，无论是LAMDA，还是DeepMind的Sparrow，以及Apprentice Bard，是能加快的加快，能上架的上架。然后再狂投近4亿美元给Anthropic，想赶快扶出自己的Open AI。（微软有的我也要）</p><p>然而，有一个人看着微软Google各领风骚，却只能急得原地跳脚。</p><p>这个人就是Meta的首席AI科学家——Yann LeCun。</p><p>他在Twitter中十分意难平：‘ChatGPT满嘴胡诌，你们却对它如此宽容，但我家的Galactica，才出来三天，就被你们骂到下线了。’</p><p><img id="2" src="https://x.liuping.win/img/9f37ca3a619c5bdb64f5c8922e485b11.png"/><br/></p><p><strong>是谁酸到了，我不说</strong></p><p>作为深度学习三巨头之一、图灵奖得主，LeCun的一举一动，都十分引人注意。</p><p>1月27日，在Zoom的媒体和高管小型聚会上，LeCun对ChatGPT给出了一段令人惊讶的评价：‘就底层技术而言，ChatGPT并不是多么了不得的创新。虽然在公众眼中，它是革命性的，但是我们知道，它就是一个组合得很好的产品，仅此而已。’</p><p><img id="3" src="https://x.liuping.win/img/09ac9e22f6afcddc6d8a413be28fc076.png"/><br/></p><p>‘除了Google和Meta之外，还有六家初创公司，基本上都拥有非常相似的技术。’</p><p>另外他还说，ChatGPT用的Transformer架构是Google提出的，而它用的自监督方式，正是他自己提倡的，那时Open AI还没诞生呢。</p><p>此番言论一出，公众哗然。Open AI的CEO Sam Altman疑似因为这句话直接取关了LeCun。</p><p><img id="4" src="https://x.liuping.win/img/528b64dc6de17cc7f3791ea78151a3cb.png"/><br/></p><p>随后，LeCun继续舌战众位推友。</p><p>1月28日，LeCun发推称，‘大型语言模型并没有物理直觉，它们是基于文本训练的。如果它们能从庞大的联想记忆中检索到类似问题的答案，他们可能会答对物理直觉问题。但它们的回答，也可能是完全错误的。’</p><p><img id="5" src="https://x.liuping.win/img/bcdb8f48bb249a40b942f6039c4c7f3a.png"/><br/></p><p>2月4日，LeCun再次发推，更加直白地表示‘在通往人类级别AI的道路上，大型语言模型就是一条歪路’。</p><p><img id="6" src="https://x.liuping.win/img/6dd15192735c8e6463d52c47c4b7df4d.png"/><br/></p><p>他这话一说，网友们可high了，纷纷冲到评论区留言。</p><p>LeCun随后补充说：‘依靠自动回归和响应预测下一个单词的LLM是条歪路，因为它们既不能计划也不能推理。’</p><p>‘但是SSL预训练的Transformer是解决方案，因为它所处的现实系统有推理、计划和学习的能力。’</p><p><img id="7" src="https://x.liuping.win/img/2ff36207ec9cbbc7e4ead4c7fec506eb.png"/><br/></p><p>LeCun举了个有趣的例子：自己在参加播客节目时，展示过ChatGPT的回答，它看上去很有道理，却错得离谱。然而主持人在读完ChatGPT的回答后，却没有第一时间发现它错了。</p><p>LeCun对此解释道：‘我们的思维方式和对世界的感知让我们能预想即将发生的事物。这是我们获得常识的基础，而LLM并没有这种能力。’</p><p>他再次发推称：‘在我们做出人类级别的AI之前，我们需要先做出猫猫/狗狗级别的AI。而现在我们甚至连这都做不到。我们缺失了十分重要的东西。要知道，连一只宠物猫都比任何大型语言模型有更多的常识，以及对世界的理解。’</p><p><img id="8" src="https://x.liuping.win/img/47f944bc910c01ec6f224686274bf93c.png"/><br/></p><p>在留言区，有网友毫不客气地怼起LeCun：‘你说得不对吧，本人亲测，Galactica的错误率接近100%，而ChatGPT的错误率差不多在15%左右。 ’</p><p><img id="9" src="https://x.liuping.win/img/669cdb6d6eee81a3e4edd4e34a354037.png"/><br/></p><p>对于网友的痛击，LeCun再次发推表明态度：‘我从来没说大型语言模型没用，其实我们Meta也推出过Galactica模型，只是它不像ChatGPT那么好命罢了。ChatGPT满嘴胡诌，你们却对它如此宽容，但我家的Glacatica，才出来三天，就被你们骂到下线了。’</p><p><img id="10" src="https://x.liuping.win/img/bfec385cdb6019c411e2974180de94bc.png"/><br/></p><p>对此，评论区有网友讽刺道：‘你可真棒棒啊。不如回实验室去，把你说的东西给做出来。’</p><p>LeCun回复：‘今天可是周日，Twitter大辩论是我周末最爱的消遣了。’</p><p><img id="11" src="https://x.liuping.win/img/1fc1ba8434c6800eda08eb20fa927d93.png"/><br/></p><p><strong>自家的模型只活了3天</strong></p><p>LeCun如此意难平，可以理解。</p><p>去年11月中旬，Meta的FAIR实验室曾提出一个Galactica模型，它可以生成论文、生成百科词条、回答问题、完成化学公式和蛋白质序列的多模态任务等等。</p><p><img id="12" src="https://x.liuping.win/img/4dadd0215b6612d00ebcc6ad531cb3c1.png"/><br/></p><p>Galactica生成的论文</p><p>LeCun也很开心地发推盛赞，称这是一个基于学术文献训练出的模型，给它一段话，它就能生成结构完整的论文。</p><p><img id="13" src="https://x.liuping.win/img/b0ce5a68f566adbc55928b232c20184b.gif"/><br/></p><p>然而，由于Galactica满嘴跑火车，它才上线短短三天，就被网友喷到下线。</p><p>LeCun转发了Papers with Code的通知，像个‘大怨种’一样说道：‘现在我们再也不能和Galactica一起愉快地玩耍了，你们开心了？’</p><p><img id="14" src="https://x.liuping.win/img/917a1aae020dee4f4681976eef773afe.png"/><br/></p><p>虽然Galactica的demo才上线几天，但当时的用户都感觉如临大敌。</p><p>有网友警示道：想想这个‘写论文’神器会被学生们拿来做什么吧。</p><p><img id="15" src="https://x.liuping.win/img/75340e1fd8b2388dd44b778c6040d25a.png"/><br/></p><p>有网友表示，‘Galactica这个模型的回答错漏百出，充满偏见，可是它的语气却十分自信权威。这太恐怖了。’</p><p><img id="16" src="https://x.liuping.win/img/4c0707e5158dadbbb66342167bd93383.png"/><br/></p><p>马库斯也表示，这种大型语言模型可能会被学生用来愚弄老师，非常令人担心。</p><p>这熟悉的配方，熟悉的味道，真是令人感慨万千：曾经Galactica引起的恐慌和质疑，不正是ChatGPT后来所经历吗？</p><p>看着这段历史的重演，却有着截然不同的结局，LeCun这么酸，确实不能说是毫无来由。</p><p>那为什么ChatGPT就能在质疑的声浪中人气愈发高涨，Galactica却只能惨兮兮地被骂到下线呢？</p><p>首先，Galactica由Meta提出，大公司确实比Open AI这样的小初创公司，面临更多的‘声誉风险’。</p><p>另外，Open AI的产品定位策略十分聪明，从ChatGTP的名字就可以看出，它主打的概念是聊天。</p><p>你可以和它聊知识、聊论文，但既然是‘chat’，自然可以放飞一些，谁规定聊天一定要聊‘准确’‘严谨’的东西呢？</p><p><img id="18" src="https://x.liuping.win/img/8c51d3328abb34fb6c7af168039924ed.png"/><br/></p><p>但Glactica则不同，它的官方定义是：‘这是一个用于科研的模型。’‘这是一个受过人类科学知识训练的人工智能。您可以将它用作一个新界面，来访问和操作我们对宇宙的知识。’</p><p>这当然就给自己埋了大雷了。</p><p>虽然从技术层面来看，ChatGPT的确没有太多创新，但是从产品运营的角度，Open AI这一招，打得十分出色。</p><p><strong>LLM为什么会满嘴胡话？</strong></p><p>所以，大语言模型为什么会满嘴胡话呢？</p><p>在LeCun点赞的一篇文章中，作者做出了解释：‘我曾尝试用ChatGPT来帮忙写博客文章，但都以失败告终。原因很简单：ChatGPT经常会整出很多虚假的“事实”’。</p><p><img id="19" src="https://x.liuping.win/img/672c9de3aa32f393b1dac062af0ef5b7.png"/><br/></p><p>自然语言不等于知识</p><p>要知道，LLM是为了在与其他人类的对话中听起来像一个人，而且它们也很好地实现了这个目标。但问题是，听起来自然与评估信息的准确性是两种完全不同的事情。</p><p>那么，这个问题该如何解决呢？</p><p>举个例子，我们可以借助已经对物理学理解进行了编码的机器——物理学引擎：</p><ul class="list-paddingleft-2"><li><p>修改LLM，使它能识别出自己被问到的是一个关于物理的问题</p></li><li><p>将问题转换为一个物理场景</p></li><li><p>用一个物理引擎来模拟这个场景</p></li><li><p>用文字描述该场景的输出</p></li></ul><p>而对于‘假论文问题’，我们同样也可以采用类似的修正。</p><p>也就是让ChatGPT认识到它被问到了关于科学论文的问题，或者它正在写关于论文的东西，并强迫它在继续之前查阅一个可信的数据库。</p><p>但是请注意，如果真的这样做了，那就意味着你把一种特定的额外‘思维’嫁接到了LLM身上。而且还必须考虑到一大堆特殊的情况。这时，人类工程师知道真相来自哪里，但LLM却不知道。</p><p>此外，随着工程师们把越来越多的这样的修复方法嫁接在一起，越来越明显的是，LLM不是一种人工通用智能的形式。</p><p>不管人类的智能是什么，我们都知道它不仅仅是能说会道的能力。</p><p>人类语言的多种用途</p><p>为什么人类要互相交谈，或为对方写下东西？</p><p>其中一个目的是直接传达事实信息，比如‘我在商店’、‘它没有插电’等，但这远不是我们使用语言的唯一原因：</p><ul class="list-paddingleft-2"><li><p>劝说、请求、命令、指示</p></li><li><p>传达情感</p></li><li><p>娱乐他人（包括小说、笑话等）、自娱自乐</p></li><li><p>欺骗（撒谎）</p></li><li><p>建立关系（与朋友建立联系，调情）</p></li></ul><p>……</p><p>看得出来，人类交流的目的是非常多样化的。而且，我们通常也不会在写作的内容中表明它的目的是什么，作者和读者也对这些内容的作用有着不同的认知。</p><p>如果ChatGPT想要成为一个值得信赖的事实传播者，它可能要学会如何区分它所训练的人类写作的各种目的。</p><p>也就是说，它将不得不学会不认真对待废话，区分说服和宣传与客观分析，独立判断一个来源的可信度与它的受欢迎程度，等等。</p><p>即使对于人类，这也是一个非常困难的技巧。有研究表明，虚假信息在Twitter上的传播速度是准确信息的数倍——往往更具有煽动性、娱乐性或看起来很新颖。</p><p>那么问题来了，为什么生成式人工智能在计算机代码上表现很好？为什么编写功能代码的准确性不能转化为传达事实的准确性？</p><p><img id="21" src="https://x.liuping.win/img/6ebb3514c5b770cf751964278df6afc3.png"/><br/></p><p>对此可能的回答是，计算机代码是功能性的，而不是交流性的。以正确的语法编写某段代码会自动执行一些任务，而编写一个语法正确的句子却不一定能达到任何目的。</p><p>此外，我们很容易将计算机代码的训练语料库限制在‘好’的代码上，也就是完美地执行其预期目的的代码。相比之下，要制作一个成功实现其目的的文本语料库几乎是不可能的。</p><p>因此，为了将自己训练成可信赖的事实传播者，LLLM必须完成一项比训练自己提出功能性计算机代码更难的任务。</p><p>虽然不知道对于工程师来说，建立一个能够区分事实和废话的LLM有多难，但这即便对于人类来说，都是一项困难的任务。</p><p><strong>马库斯：世纪大和解</strong></p><p>LeCun的一大串言论，让大家纷纷疑惑：这不是马库斯会说的话吗？</p><p><img id="22" src="https://x.liuping.win/img/ccec234dafc95e8785667c6456aab827.png"/><br/></p><p>热（chi）情（gua）的网友纷纷@马库斯，期待他对此事的锐评。</p><p><img id="23" src="https://x.liuping.win/img/fce50341f2b504f144065d6abae4c3a3.png"/><br/></p><p>苦GPT久矣的马库斯自然喜出望外，立刻转发LeCun的帖子，还评论道‘100昏’。</p><p><img id="24" src="https://x.liuping.win/img/13a745814cf2e7f8f50c96826de7f96b.png"/><br/></p><p>马库斯还在自己的博客上发文，回顾自己与LeCun的‘爱恨情仇’。</p><p><img id="25" src="https://x.liuping.win/img/2c4833e5638b6c4be9a66e95384441c0.png"/><br/></p><p>马库斯称，自己与LeCun本是多年老友，因为嘴了Galactica几句使得两人交恶。</p><p>实际上，马库斯与LeCun的嘴仗打了好几年了，可不是光只因为Galactica下线的事情。</p><p>与另外两位图灵奖得主Bengio和Hinton的相对低调不同，近几年，LeCun在社交媒体上的活跃在AI圈子里也是出了名的。不少工作在挂了Arxiv之后就第一时间在Twitter上宣传一波。</p><p>同样高调的马库斯也是一向视Twitter为自己的主场，当LeCun的宣传和马库斯的看法产生矛盾时，双方都不打算憋着。</p><p>在社交媒体上，两人可以说达到了有架必吵的地步，彼此间话讲的毫不客气，见面说不定都能直接掐起来那种。</p><p>而且要说梁子，2019年LeCun与Hinton和Bengio一起获得图灵奖后，有一张合影，原本马库斯站在LeCun的边上，但在LeCun分享的照片中，Marcus被无情地剪掉了。</p><p><img id="26" src="https://x.liuping.win/img/3d91c0e481278a5f321d7276a7eb5455.png"/><br/></p><p>然而，ChatGPT的诞生改变了一切。</p><p>ChatGPT爆火，Galactica三天后便落魄下架。在LeCun对LLM疯狂输出时，马库斯自然乐于看到此景。</p><p>正所谓敌人的敌人就是朋友，不论LeCun的言论是自家产品失败后的大彻大悟，还是对竞品顶流现状的眼红，马库斯都愿意添一把火。</p><p>马库斯认为，他和LeCun达成一致的，不仅是关于LLM的炒作和局限性。他们都认为Cicero应该得到更多的关注。</p><p>最后，马库斯@了懂的都懂的那个人，并说‘该给家人们福利了’。</p><p><img id="27" src="https://x.liuping.win/img/824d41eaf31cf7c790c8fcfdb96e1e4f.png"/><br/></p><p>可以说，LeCun在Twitter上掀起的骂战，不仅让马库斯的反GPT军团多了一员猛将，还给了两人握手言和的契机。</p><p>这么看来，或许马库斯才是最终赢家。</p> </div></body>
            </html>
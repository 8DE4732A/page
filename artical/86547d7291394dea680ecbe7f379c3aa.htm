<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="OpenAI的GPT-4在万众瞩目中闪亮登场，多模态功能太炸裂，简直要闪瞎人类的双眼。李飞飞高徒、斯坦福博士JimFan表示，GPT4凭借如此强大的推理能力，已经可以自己考上斯坦福了！果然，能打败昨天的OpenAI的，只有今天的OpenAI。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/7fed1185ff906f821b31319033cd1d66.png">
        <meta property="og:url" content="https://x.liuping.win/artical/86547d7291394dea680ecbe7f379c3aa.htm">
        <meta property="og:title" content="GPT-4王者加冕：读图做题性能炸天 凭自己就能考上斯坦福 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,GPT-4王者加冕：读图做题性能炸天 凭自己就能考上斯坦福,x.liuping.win">
        <meta name="description" content="OpenAI的GPT-4在万众瞩目中闪亮登场，多模态功能太炸裂，简直要闪瞎人类的双眼。李飞飞高徒、斯坦福博士JimFan表示，GPT4凭借如此强大的推理能力，已经可以自己考上斯坦福了！果然，能打败昨天的OpenAI的，只有今天的OpenAI。">
        <title>GPT-4王者加冕：读图做题性能炸天 凭自己就能考上斯坦福</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>GPT-4王者加冕：读图做题性能炸天 凭自己就能考上斯坦福</h1><p>Open AI的GPT-4在万众瞩目中闪亮登场，多模态功能太炸裂，简直要闪瞎人类的双眼。李飞飞高徒、斯坦福博士Jim Fan表示，GPT4凭借如此强大的推理能力，已经可以自己考上斯坦福了！果然，能打败昨天的Open AI的，只有今天的Open AI。</p><hr><div class="article-content" id="artibody">
<p>刚刚，Open AI震撼发布了大型多模态模型GPT-4，支持图像和文本的输入，并生成文本结果。</p><p>号称史上最先进的AI系统！</p><p><img id="1" src="https://x.liuping.win/img/7fed1185ff906f821b31319033cd1d66.png"/><br/></p><p>GPT-4不仅有了眼睛可以看懂图片，而且在各大考试包括GRE几乎取得了满分成绩，横扫各种benchmark，性能指标爆棚。</p><p>Open AI 花了 6 个月的时间使用对抗性测试程序和 ChatGPT 的经验教训对 GPT-4 进行迭代调整 ，从而在真实性、可控性等方面取得了有史以来最好的结果。</p><p><img id="2" src="https://x.liuping.win/img/455fef0574cc95247dd0256964de6e3c.gif"/><br/></p><p>大家都还记得，2月初时微软和Google鏖战三天，2月8日微软发布ChatGPT版必应时，说法是必应‘基于类ChatGPT技术’。</p><p>今天，谜底终于解开了——它背后的大模型，就是GPT-4！</p><p><img id="3" src="https://x.liuping.win/img/5aa74fb27fc26de7ecccc9556ed05b9a.png"/><br/></p><p>图灵奖三巨头之一Geoffrey Hinton对此赞叹不已，‘毛虫吸取了营养之后，就会化茧为蝶。而人类提取了数十亿个理解的金块，GPT-4，就是人类的蝴蝶。’</p><p><img id="4" src="https://x.liuping.win/img/02f3225b8f67c9a39eadc5e796b67b8f.png"/><br/></p><p>顺便提一句，ChatGPT Plus用户现在可以先上手了。</p><p><img id="5" src="https://x.liuping.win/img/bbc704c0c9435c83687f54b74fd47827.jpg"/><br/></p><p>考试几乎满分，性能跃迁炸天</p><p>在随意谈话中，GPT-3.5和GPT-4之间的区别是很微妙的。只有当任务的复杂性达到足够的阈值时，差异就出现了，GPT-4比GPT-3.5 更可靠、更有创意，并且能够处理更细微的指令。</p><p>为了了解这两种模型之间的差异，Open AI在各种基准测试和一些为人类设计的模拟考试上进行了测试。</p><p>GPT-4在各种考试中，有几个测试几乎接近了满分：</p><ul class="list-paddingleft-2"><li><p>USABO Semifinal 2020（美国生物奥林匹克竞赛）</p></li><li><p>GRE Writing</p></li></ul><p><img id="6" src="https://x.liuping.win/img/c9332f8732912392ccd12bb0f91cc87a.png"/><br/></p><p>以美国 BAR律师执照统考为例，GPT3.5可以达到 10%水平，GPT4可以达到90%水平。生物奥林匹克竞赛从GPT3.5的31%水平，直接飙升到 99%水平。</p><p><img id="7" src="https://x.liuping.win/img/1595511d39cef27fd4e9532c10bda537.png"/><br/></p><p>此外，Open AI 还在为机器学习模型设计的传统基准上评估了 GPT-4。从实验结果来看，GPT-4 大大优于现有的大型语言模型，以及大多数 SOTA 模型：</p><p><img id="8" src="https://x.liuping.win/img/7d66df789c2811745da62c9a217e2f13.png"/><br/></p><p>另外，GPT-4在不同语种上的能力表现：中文的准确度大概在 80% 左右，已经要优于GPT-3.5的英文表现了。</p><p>许多现有的 ML 基准测试都是用英语编写的。为了初步了解GPT-4其他语言的能力，研究人员使用 Azure翻译将 MMLU 基准（一套涵盖57个主题的14000个多项选择题）翻译成多种语言。</p><p>在测试的 26 种语言的 24 种中，GPT-4 优于 GPT-3.5 和其他大语言模型（Chinchilla、PaLM）的英语语言性能：</p><p><img id="9" src="https://x.liuping.win/img/1825c38db8b388553a40f7fa8cb9a00a.png"/><br/></p><p>Open AI表示在内部使用 GPT-4，因此也关注大型语言模型在内容生成、销售和编程等方面的应用效果。另外，内部人员还使用它来帮助人类评估人工智能输出。</p><p>对此，李飞飞高徒、英伟达AI科学家Jim Fan点评道：‘GPT-4最强的其实就是推理能力。它在GRE、SAT、法学院考试上的得分，几乎和人类考生没有区别。也就是说，GPT-4可以全靠自己考进斯坦福了。’</p><p>（Jim Fan自己就是斯坦福毕业的！）</p><p>网友：完了，GPT-4一发布，就不需要我们人类了……</p><p><img id="10" src="https://x.liuping.win/img/51664f2c6076c19ca1ef24c1448e1a96.png"/><br/></p><p>读图做题小case，甚至比网友还懂梗</p><p>GPT-4此次升级的亮点，当然就是多模态。</p><p>GPT-4不仅能分析汇总图文图标，甚至还能读懂梗图，解释梗在哪里，为什么好笑。从这个意义上说，它甚至能秒杀许多人类。</p><p>Open AI称，GPT-4比以往模型都更具创造力和协作性。它可以生成、编辑和迭代用户进行创意和技术写作任务，例如创作歌曲、编写剧本或学习用户的写作风格。</p><p><img id="11" src="https://x.liuping.win/img/928a05f472431c23c0cf5f8eb572d069.png"/><br/></p><p>GPT-4可以将图像作为输入，并生成标题、分类和分析。比如给它一张食材图，问它用这些食材能做什么。</p><p><img id="12" src="https://x.liuping.win/img/e946131e34dcfe280673c9af912a7d90.png"/><br/></p><p><img id="13" src="https://x.liuping.win/img/1427a793e9ac22b5db5ee2b7068c9a9b.png"/><br/></p><p>另外，GPT-4能够处理超过25，000字的文本，允许用长形式的内容创建、扩展会话、文档搜索和分析。</p><p>GPT-4在其先进的推理能力方面超过了ChatGPT。如下：</p><p><img id="14" src="https://x.liuping.win/img/7a435933a077fbec5661b7b09f7cd869.png"/><br/></p><p>梗图识别</p><p>比如，给它看一张奇怪的梗图，然后问图中搞笑在哪里。</p><p>GPT-4拿到之后，会先分析一波图片的内容，然后给出答案。</p><p>比如，逐图分析下面这个。</p><p><img id="15" src="https://x.liuping.win/img/c20f48a98cfee860d813a477c12f78b6.png"/><br/></p><p>GPT-4立马反应过来：图里的这个‘Lighting充电线’，看起来就是个又大又过气的VGA接口，插在这个又小又现代的智能手机上，反差强烈。</p><p><img id="16" src="https://x.liuping.win/img/76bd16a7c00dac2f577c6d888a63febe.png"/><br/></p><p>再给出这么一个梗图，问问GPT-4梗在哪里？</p><p><img id="17" src="https://x.liuping.win/img/b2f8509eb0fb7db3185d183ff5c62d8c.png"/><br/></p><p>它流利地回答说：这个梗搞笑的地方在于‘图文不符’。</p><p>文字明明说是从太空拍摄的地球照片，然而，图里实际上只是一堆排列起来像地图的鸡块。</p><p><img id="18" src="https://x.liuping.win/img/f5ecabd8d90cd285b9eca9322b960b48.png"/><br/></p><p>GPT-4还能看懂漫画：为什么要给神经网络加层数？</p><p><img id="19" src="https://x.liuping.win/img/82d81227a537670690de432b7446b3fe.png"/><br/></p><p>它一针见血地点出，这副漫画讽刺了统计学习和神经网络在提高模型性能方法上的差异。</p><p><img id="20" src="https://x.liuping.win/img/a41e6353fae1f068afbf93d998ba81f3.png"/><br/></p><p>图表分析</p><p>格鲁吉亚和西亚的平均每日肉类消费量总和是多少？在给出答案前，请提供循序渐进的推理。</p><p><img id="21" src="https://x.liuping.win/img/f784456a580debe7f83b3dd7f7515dbd.png"/><br/></p><p>果然，GPT-4清楚地列出了自己的解题步骤——</p><p>1． 确定格鲁吉亚的平均每日肉类消费量。</p><p>2． 确定西亚的平均每日肉类消费量。</p><p>3． 添加步骤1和2中的值。</p><p><img id="22" src="https://x.liuping.win/img/60db5a7c98f906dbc3933db8965587d8.png"/><br/></p><p>做物理题</p><p>要求GPT-4解出巴黎综合理工的一道物理题，测辐射热计的辐射检测原理。值得注意的是，这还是一道法语题。</p><p><img id="23" src="https://x.liuping.win/img/feacb77b992f147640cbf48f5d08ceed.png"/><br/></p><p>GPT-4开始解题：要回答问题 I.1.a，我们需要每个点的温度 T（x），用导电棒的横坐标x表示。</p><p>随后解题过程全程高能。</p><p><img id="24" src="https://x.liuping.win/img/dddc842b0280c71b94917b0d7fa7be5d.png"/><br/></p><p>你以为这就是GPT-4能力的全部？</p><p>老板Greg Brockman直接上线进行了演示，通过这个视频你可以很直观的感受到 GPT-4的能力。</p><p>最惊艳的是，GPT-4对代码的超强的理解能力，帮你生成代码。</p><p>Greg直接在纸上画了一个潦草的示意图，拍个照，发给 GPT说，给我按照这个布局写网页代码，就写出来了。</p><p><img id="25" src="https://x.liuping.win/img/a8ea32b77d216a8e6c953dd0f604cb3b.gif"/><br/></p><p>另外，如果运行出错了把错误信息，甚至错误信息截图，扔给GPT-4都能帮你给出相应的提示。</p><p>网友直呼：GPT-4发布会，手把手教你怎么取代程序员。</p><p><img id="26" src="https://x.liuping.win/img/260cd5ebb8aabbeff423947f0fa2ef0f.png"/><br/></p><p>顺便提一句，用GPT-4还可以进行报税 。要知道，每年美国人要花好多时间金钱在报税上面。</p><p><img id="27" src="https://x.liuping.win/img/b4672385bb4208bd8d3a5e948af064cf.png"/><br/></p><p>训练过程</p><p>和以前的GPT模型一样，GPT-4基础模型的训练使用的是公开的互联网数据以及Open AI授权的数据，目的是为了预测文档中的下一个词。</p><p>这些数据是一个基于互联网的语料库，其中包括对数学问题的正确/错误的解决方案，薄弱/强大的推理，自相矛盾/一致的声明，足以代表了大量的意识形态和想法。</p><p>当用户给出提示进行提问时，基础模型可以做出各种各样的反应，然而答案可能与用户的意图相差甚远。</p><p>因此，为了使其与用户的意图保持一致，Open AI使用基于人类反馈的强化学习（RLHF）对模型的行为进行了微调。</p><p>不过，模型的能力似乎主要来自于预训练过程，RLHF并不能提高考试成绩（如果不主动进行强化，它实际上会降低考试成绩）。</p><p>基础模型需要提示工程，才能知道它应该回答问题，所以说，对模型的引导主要来自于训练后的过程。</p><p>GPT-4模型的一大重点是建立了一个可预测扩展的深度学习栈。因为对于像GPT-4这样的大型训练，进行广泛的特定模型调整是不可行的。</p><p>因此，Open AI团队开发了基础设施和优化，在多种规模下都有可预测的行为。</p><p>为了验证这种可扩展性，研究人员提前准确地预测了GPT-4在内部代码库（不属于训练集）上的最终损失，方法是通过使用相同的方法训练的模型进行推断，但使用的计算量为1/10000。</p><p><img id="28" src="https://x.liuping.win/img/4c4d247c3e2a65fd3893b3714c9f38c2.png"/><br/></p><p>现在，Open AI 可以准确地预测在训练过程中优化的指标损失。例如从计算量为1/1000的模型中推断并成功地预测了HumanEval数据集的一个子集的通过率：</p><p><img id="29" src="https://x.liuping.win/img/36026f774cad360531618712fc53d1ee.png"/><br/></p><p>还有些能力仍然难以预测。比如，Inverse Scaling竞赛旨在找到一个随着模型计算量的增加而变得更糟的指标，而 hindsight neglect任务是获胜者之一。但是GPT-4 扭转了这一趋势：</p><p><img id="30" src="https://x.liuping.win/img/f4ec5ff2ea6f8469360d919e9e75ff8d.png"/><br/></p><p>Open AI认为能够准确预测未来的机器学习能力对于技术安全来说至关重要，但它并没有得到足够的重视。</p><p>而现在，Open AI正在投入更多精力开发相关方法，并呼吁业界共同努力。</p><p>贡献名单</p><p>就在GPT-4发布的同时，Open AI还公开了GPT-4这份组织架构及人员清单。</p><p><img id="31" src="https://x.liuping.win/img/b09042e1cc7a5027526dd148f44d628c.jpg"/><br/></p><p>上下滑动查看全部</p><p>北大陈宝权教授称，</p><blockquote><p>再好看的电影，最后的演职员名单也不会有人从头看到尾。Open AI的这台戏连这个也不走寻常路。毫无疑问这将是一份不仅最被人阅读，也被人仔细研究的‘演职员’（贡献者） 名单，而最大的看头，是详细的贡献分类，几乎就是一个粗略的部门设置架构了。</p><p>这个很‘大胆’的公开其实意义挺深远的，体现了Open AI背后的核心理念，也一定程度预示了未来进步的走向。</p></blockquote><p><img id="32" src="https://x.liuping.win/img/a751d98d89d57e1db0a79223d230108f.png"/><br/></p> </div></body>
        </html>
<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="北京时间3月12日消息，由于担心信息泄露和其他问题，软银、日立等日本公司已开始限制ChatGPT等交互式人工智能服务在商业运作中的使用。软银上月就使用ChatGPT和其他商业应用警告员工称：“不要输入公司身份信息或机密数据。”">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/53a08c7cbfef97b8ab07573816476751.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/9628717632eb6ea532f8cc6f5024a4e7.htm">
        <meta property="og:title" content="软银、日立等多家日企限制使用ChatGPT 以防泄密 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,软银、日立等多家日企限制使用ChatGPT 以防泄密,x.liuping.win">
        <meta name="description" content="北京时间3月12日消息，由于担心信息泄露和其他问题，软银、日立等日本公司已开始限制ChatGPT等交互式人工智能服务在商业运作中的使用。软银上月就使用ChatGPT和其他商业应用警告员工称：“不要输入公司身份信息或机密数据。”">
        <title>软银、日立等多家日企限制使用ChatGPT 以防泄密</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>软银、日立等多家日企限制使用ChatGPT 以防泄密</h1><p>北京时间3月12日消息，由于担心信息泄露和其他问题，<strong>软银、日立等日本公司已开始限制ChatGPT等交互式人工智能服务在商业运作中的使用。</strong>软银上月就使用ChatGPT和其他商业应用警告员工称：“不要输入公司身份信息或机密数据。”</p><hr><div class="article-content" id="artibody">
<p>尽管软银已经出台了使用交互式人工智能等云服务的指导方针，但鉴于聊天机器人最近受到的关注越来越多，这些规则依旧被反复强调。<strong>软银计划制定规则，规定哪些业务可以使用该技术，哪些应用可以被使用。</strong></p><p><strong><img src="https://x.liuping.win/img/53a08c7cbfef97b8ab07573816476751.webp"/></strong></p><p>今年3月1日，ChatGPT开发商Open AI发布了一个应用程序接口，允许企业付费将ChatGPT集成到他们的服务中。Open AI表示，从ChatGPT中收集的数据不会用于提高性能，但其网站显示，当这项服务被免费使用时，“我们可能会使用您提供的数据来改进我们的模型。在这种情况下，被输入的信息，例如正在开发的产品，可以用来回答其他公司的问题”。</p><p><strong>除软银外，日立将考虑制定新的道德规则，以规范交互式人工智能的使用以及数据是否被正确使用。</strong>该公司计划完善2021年制定的人工智能使用指南。</p><p>富士通上月向员工通报了有关ChatGPT和其他交互式人工智能服务的法律和道德问题，包括信息保护。该公司已经成立了一个部门来决定人工智能的使用。2022年2月，富士通成立了一个治理办公室，来处理包含人工智能的产品开发和商业使用中的道德问题。该公司将通过这个办公室提醒公众交互式人工智能的风险。</p><p>今年1月，ChatGPT在发布仅仅两个月后用户就超过了1亿。微软上月在必应搜索中整合ChatGPT，推动该搜索引擎日用户在一个月后首次突破了1亿人。而且，这一技术在企业运作中的应用预计也将显著增加。然而，越来越多的人和企业使用交互式人工智能也令人担忧，因为该技术可能会传播虚假信息，引发数据泄露，导致一些公司禁止使用该技术。</p><p>日本瑞穗金融集团、三菱日联金融集团和三井住友银行已禁止在公司运营中使用ChatGPT和其他服务。瑞穗的限制措施会阻止员工从工作终端访问该网站，目的是“防止因员工不当使用导致客户和金融交易等重要信息泄露”。IT公司NEC也禁止员工使用ChatGPT。</p><p>日本情报安全大学院大学研究科教授后藤厚宏(Atsuhiro Goto)表示：“交互式人工智能可以在个人电脑上轻松使用，这让员工变得不那么谨慎，存在机密数据被意外输入并在公司外部使用的风险。这些服务应该由一个专门的内部团队进行测试，以澄清使用规则和可以输入的信息。”</p><p>松下控股集团公司Panasonic Connect在采取措施防止数据泄露等问题后，开始使用交互式人工智能创建文件。为了降低数据泄露的风险，该公司与软件的联合开发者微软达成了一项协议，不将内容用于人工智能培训等次要目的。同时，员工们也被警告不要输入个人信息。</p> </div></body>
        </html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="自去年11月OpenAI公司推出聊天机器人ChatGPT以来，学术界对这项颠覆性的技术进行热烈讨论，该技术也在信息搜索和分析领域展现了巨大的潜力。信息和分析公司励讯集团（Relx）2月16日发布最新财报时表示，该公司正在使用生成式AI增强其法律、医疗和科学业务产品，并预测2023年的业绩将继续实现强劲增长。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/6bce6d8e4dba43db6ecd5e4e9f76559f.png">
            <meta property="og:url" content="https://x.liuping.win/artical/f886f9a28506036382d2590e16c45037.htm">
            <meta property="og:title" content="ChatGPT对学术出版影响几何？出版商已明确几条原则 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,ChatGPT对学术出版影响几何？出版商已明确几条原则,x.liuping.win">
            <meta name="description" content="自去年11月OpenAI公司推出聊天机器人ChatGPT以来，学术界对这项颠覆性的技术进行热烈讨论，该技术也在信息搜索和分析领域展现了巨大的潜力。信息和分析公司励讯集团（Relx）2月16日发布最新财报时表示，该公司正在使用生成式AI增强其法律、医疗和科学业务产品，并预测2023年的业绩将继续实现强劲增长。">
            <title>ChatGPT对学术出版影响几何？出版商已明确几条原则</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>ChatGPT对学术出版影响几何？出版商已明确几条原则</h1><p>自去年11月OpenAI公司推出聊天机器人ChatGPT以来，学术界对这项颠覆性的技术进行热烈讨论，该技术也在信息搜索和分析领域展现了巨大的潜力。信息和分析公司励讯集团（Relx）2月16日发布最新财报时表示，该公司正在使用生成式AI增强其法律、医疗和科学业务产品，并预测2023年的业绩将继续实现强劲增长。</p><hr><div class="article-content" id="artibody">
<p><img alt="yXFJ-5UC_400x400.png" src="https://x.liuping.win/img/6bce6d8e4dba43db6ecd5e4e9f76559f.png" title=""/></p><p>励讯旗下拥有全球最大的学术出版商之一爱思唯尔，旗下刊物包括《柳叶刀》（Lancet）、《细胞》（Cell）等知名科学杂志。励讯集团的其他业务还涵盖法律、风险以及展览。</p><p>励讯集团首席财务官Nick Luff表示，生成式AI给信息分析行业带来的机遇大于威胁，集团目前已经将生成式AI构建到其业务产品中。“生成式AI技术本身非常有趣，但需要确保将它们应用于正确的内容、正确的用例、正确的工作流程，以获得专业用户的信任。”Luff在财报发布时指出。</p><p>数字化转型是励讯集团近年来的战略重点，这一需求在传统出版行业面临数字化挑战的背景下显得尤为突出。2月17日，爱思唯尔董事长池永硕在一篇署名文章中指出，爱思唯尔已经开发了数字化解决方案，用于支持临床决策的深度数据和信息分析，并产生可信赖的医学知识信息。</p><p>不过，随着科研人员迈入高级对话AI的新世界，出版机构也正在讨论如何认可生成式AI的合法使用，并为防止滥用制定清晰准则。</p><p>全球知名出版集团施普林格-自然（Springer Nature）的旗舰刊物《自然》日前公开发表社论，声明了在使用生成式AI时的两条原则：一是不接受任何LLM工具作为对研究论文有贡献的作者；二是使用LLM工具的研究人员应在方法或致谢部分中声明。</p><p>“这并不是禁止ChatGPT作为撰写论文的工具，但根本问题是对于一篇论文是如何组成的，以及使用什么软件撰写的，要有明确的规定。”一位出版界相关人士对第一财经记者表示，“科学需要透明度，这是核心与本质。包括研究人员、出版商需要走到一起，制定新的披露规范，以防止技术被滥用。”</p><p>全球顶尖科学期刊《科学》杂志主编Holden Thorp也公开撰文称，在不到两个月的时间里，生成式AI软件ChatGPT已经成为一种“文化轰动”。“这在文学创作中可能会变得很有趣，但对科学界和学术界可能会造成严重的影响。”Thorp写道。</p><p>编辑和出版商是否已经可以检测出由大模型生成的论文文本？根据《自然》的说法，ChatGPT的原始输出经过仔细检查是可以检测到的，尤其是当涉及多个段落并且主题与科学工作相关时。</p><p>根据Thorp援引最近的一项研究，由ChatGPT创建的摘要在提交给学术审稿人时，只有63%的文章被检测到使用了AI软件。《科学》杂志制定准则称，人工智能程序不能成为作者，违反这些政策将构成科学不端行为，与篡改图像或抄袭现有论文没有差异。但针对通过人工智能技术在研究中生成的合法的数据集（非论文文本）除外。</p><p>“科学论文归根结底是人类为解决重要问题所做的努力。 机器发挥着重要作用，但它是人们提出假设、设计实验和理解结果的工具。 最终，这些产品必须来自人类头脑中美妙的计算机来表达。”Thorp表示。</p> </div></body>
            </html>
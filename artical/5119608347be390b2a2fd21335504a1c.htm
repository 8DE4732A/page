<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="研究人员在最近的生物发现的启发下开发了一个新的模型，显示出增强的记忆性能。这是通过修改一个经典的神经网络实现的。计算机模型在研究大脑制造和保留记忆及其他复杂信息的过程中发挥着关键作用。然而，构建这种模型是一项微妙的任务。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/64a8c9ef1b9eb85c7cfef47b71976065.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/5119608347be390b2a2fd21335504a1c.htm">
        <meta property="og:title" content="生物启发的神经网络模型令其记忆能力大大提升 - x.liuping.win">
        <meta name="keywords" content="科学探索,生物启发的神经网络模型令其记忆能力大大提升,x.liuping.win">
        <meta name="description" content="研究人员在最近的生物发现的启发下开发了一个新的模型，显示出增强的记忆性能。这是通过修改一个经典的神经网络实现的。计算机模型在研究大脑制造和保留记忆及其他复杂信息的过程中发挥着关键作用。然而，构建这种模型是一项微妙的任务。">
        <title>生物启发的神经网络模型令其记忆能力大大提升</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>生物启发的神经网络模型令其记忆能力大大提升</h1><p>研究人员在最近的生物发现的启发下开发了一个新的模型，显示出增强的记忆性能。这是通过修改一个经典的神经网络实现的。计算机模型在研究大脑制造和保留记忆及其他复杂信息的过程中发挥着关键作用。然而，构建这种模型是一项微妙的任务。</p><hr><div class="article-content" id="artibody">
<p>电信号和生物化学信号的错综复杂的相互作用，以及神经元和其他细胞类型之间的连接网络，为记忆的形成创造了基础结构。尽管如此，由于对大脑基础生物学的了解有限，将大脑的复杂生物学编码到计算机模型中进行进一步研究已被证明是一项困难的任务。</p><p>冲绳科学与技术研究所（OIST）的研究人员通过纳入生物学的见解，对广泛使用的记忆计算机模型（称为霍普菲尔德网络）进行了改进。这一改变启发了一个神经网络，它不仅更好地反映了神经元和其他细胞在大脑中的连接方式，而且还有能力储存更多的记忆。</p><p>深井智树教授小组的博士生托马斯-伯恩斯说，网络中增加的复杂性使其更加现实，深井教授是OIST神经编码和脑计算部门的负责人。</p><p>"为什么生物学会有这么多的复杂性？记忆能力可能是一个原因，"伯恩斯先生说。</p><p><img alt="Diagrams-of-Connections-in-Hopfield-Networks-1536x746.webp" src="https://x.liuping.win/img/64a8c9ef1b9eb85c7cfef47b71976065.webp" title=""/></p><p>在经典的霍普菲尔德网络（左）中，每个神经元（I、j、k、l）都以成对的方式与其他神经元相连。在伯恩斯和深井教授制作的改良网络中，三个或更多的神经元组可以同时连接。资料来源：托马斯-伯恩斯（OIST）</p><p>霍普菲尔德网络将记忆存储为系统中不同神经元之间的加权连接模式。网络被"训练"来编码这些模式，然后研究人员可以通过呈现一系列模糊或不完整的模式来测试它对这些模式的记忆，观察这一网络是否能将它们识别为它已经知道的模式。然而，在经典的霍普菲尔德网络中，模型中的神经元与网络中的其他神经元相互连接，形成一系列所谓的"配对"连接。</p><p>成对连接代表了两个神经元在突触处的连接方式，突触是大脑中两个神经元的连接点。但在现实中，神经元有复杂的分支结构，称为树突，提供多个连接点，因此大脑依靠更复杂的突触安排来完成其认知工作。此外，神经元之间的连接是由称为星形胶质细胞的其他细胞类型调节的。</p><p>伯恩斯解释说："大脑中只存在神经元之间的成对连接，这根本不现实。他创建了一个改良的霍普菲尔德网络，其中不仅有成对的神经元，而且有三组、四组或更多的神经元也可以连接起来，例如在大脑中可能通过星形胶质细胞和树突树发生。"</p><p>尽管新的网络允许这些所谓的"集合式"连接，但总的来说，它包含的连接总数与以前一样。研究人员发现，一个包含成对连接和集合连接的混合网络表现最好，保留的记忆数量也最多。他们估计它的效果是传统霍普菲尔德网络的两倍以上。</p><p>"事实证明，你实际上需要在某种程度上平衡各种特征的组合，"伯恩斯说，"单独的突触是必要的，但也应该需要一些树突树和一些星形胶质细胞。"</p><p>霍普菲尔德网络对于模拟大脑过程非常重要，但它们也有强大的其他用途。例如，被称为变形金刚的非常类似的网络类型是基于人工智能的语言工具，如ChatGPT，所以伯恩斯和深井教授所确定的改进也可能使这类工具更加强大。</p><p>伯恩斯和他的同事们计划继续研究他们修改后的霍普菲尔德网络，以使它们更加强大。例如，在大脑中，神经元之间的连接强度通常在两个方向上是不一样的，所以研究人员想知道这种不对称的特点是否也能提高网络的性能。此外，他还想探索使网络的记忆相互作用的方法，就像它们在人脑中的作用一样。我们的记忆是多方面的，而且很庞大。我们仍然有很多东西需要发掘。"</p> </div></body>
        </html>
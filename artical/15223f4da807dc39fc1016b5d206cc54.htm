<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="ChatGPT到处“造假”作弊，现在搞得OpenAI官方都坐不住了。就在今天，OpenAI紧急发布官方打假工具：基于GPT打造，打开网页就能用。好家伙，这岂不是真·以己之矛攻己之盾了？一经上线，那叫一个火爆，不少网友第一时间就冲过去测试了。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/1eb31d78723b74f6623d289549472744.webp">
            <meta property="og:url" content="https://x.liuping.win/artical/15223f4da807dc39fc1016b5d206cc54.htm">
            <meta property="og:title" content="ChatGPT官方鉴别器紧急发布：当代自相矛盾 不想却遭遇群嘲 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,ChatGPT官方鉴别器紧急发布：当代自相矛盾 不想却遭遇群嘲,x.liuping.win">
            <meta name="description" content="ChatGPT到处“造假”作弊，现在搞得OpenAI官方都坐不住了。就在今天，OpenAI紧急发布官方打假工具：基于GPT打造，打开网页就能用。好家伙，这岂不是真·以己之矛攻己之盾了？一经上线，那叫一个火爆，不少网友第一时间就冲过去测试了。">
            <title>ChatGPT官方鉴别器紧急发布：当代自相矛盾 不想却遭遇群嘲</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>ChatGPT官方鉴别器紧急发布：当代自相矛盾 不想却遭遇群嘲</h1><p>ChatGPT到处“造假”作弊，现在搞得OpenAI官方都坐不住了。就在今天，OpenAI紧急发布<strong>官方打假工具</strong>：基于GPT打造，打开网页就能用。好家伙，这岂不是<strong>真·以己之矛攻己之盾</strong>了？一经上线，那叫一个火爆，不少网友第一时间就冲过去测试了。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/1eb31d78723b74f6623d289549472744.webp"/><br/></p><p>然鹅，网友们一番试验之下却发现——</p><p>这官方工具，跟咱自己<strong>瞎猜</strong>效果也差不多啊？？？</p><p>官方出品，约等于瞎猜</p><p>有人给OpenAI这个新鉴别器投喂了一小段文字，结果首次尝试就翻车了。</p><p><img src="https://x.liuping.win/img/5da93ced90a0b7deeb49e830c18595ac.webp"/><br/></p><p>这位网友首先让AI写下一段文字，内容是评价莎士比亚的一个历史剧角色，不过他向写作AI特意给了个提示：</p><p>请以人类的方式来写，争取逃过AI鉴别工具的火眼金睛。</p><p>结果没想到，还真就骗过了官方鉴别器。它看完给出回复：这“非常不可能是AI生成的”。</p><p>这个官方工具对文本内容的判定结果一共就<strong>5个等级：</strong></p><p>非常不可能是AI生成的</p><p>不太可能是AI生成的</p><p>不清楚是不是AI生成的</p><p>可能是AI生成的</p><p>很可能是AI生成的</p><p>好家伙，这不是和真实情况完全相反嘛，让网友都蚌埠住了：真是因吹斯汀…</p><p><img src="https://x.liuping.win/img/4ee16309475449d4beae258632706227.webp"/><br/></p><p>还有人把ChatGPT生成的内容一字不改，直接拿给鉴定AI看。但鉴定AI依然懵圈儿：“不清楚是不是AI生成的”。</p><p><img src="https://x.liuping.win/img/a36dc1c309afe3f226fdda645c21d724.webp"/><br/></p><p>这位网友也只好呵呵，并指出：</p><p>实际上，大家用ChatGPT等AI生成文字后，并不会原封不动地直接用，一般还会手动修改一下，或者丢进quillbot.com等润色工具里加工，很可能导致鉴定AI更摸不着头脑。</p><p>好吧，既然AI生成文字分不太清，那人类写的东西能认出来吗？</p><p>有人把自己之前在Hacker News上发表的大段评论（纯手打）喂给了鉴定AI，结果10次中有9次，AI都反馈说“不清楚是不是AI生成的”。</p><p>在网友们的一片吐槽声中，量子位也忍不住亲测了一下这个AI到底行不行。</p><p>首先，我们先给它看了段真人写的文字，内容是一位华盛顿大学博士对Tensor Core的讲解，这次AI并没有失误。</p><p><img src="https://x.liuping.win/img/b264d0dad2b627503939b9cccf67d06e.webp"/><br/></p><p>然后我们让ChatGPT来讲讲Tensor Core，并特地要求它尽量用人类的语气来写，但还是被AI鉴定出来了。</p><p><img src="https://x.liuping.win/img/9b959bd2e4528944b8cbbbfa373c3280.webp"/><br/></p><p>这样看来，这个工具似乎也不是完全不能用。</p><p>至于这次是不是ChatGPT发挥失常，你不妨也来鉴定看看：</p><p><img src="https://x.liuping.win/img/cc3f86f485800daa24aa7d237c7584f2.webp"/><br/></p><p>但其实吧，这回连OpenAI自己，用词都显得相当谨慎。</p><p>官方数据明明白白写着，虽然这个新款打假工具比之前鉴定器都靠点谱，但其成功识别AI生成内容的概率，也仅为<strong>26%</strong>，还有<strong>9%</strong>的概率把人写的文本当成AI写的。</p><p>（这准确率似乎跟蒙答案也差不多……）</p><p>还用加粗文字昭告：<strong>我们这个鉴别器啊，它并不完全靠谱</strong>。</p><p><img src="https://x.liuping.win/img/2ad4872c0b62639d5a856e4570a90419.webp"/><br/></p><p>甚至还给自己这个新工具标了个“半成品”的标签。</p><p>嗯？这可不是OpenAI一直以来锣鼓喧天鞭炮齐鸣的宣传方式啊。</p><p>连自己家都不敢吹，还急急忙忙把打假工具推出来，OpenAI又是为哪般？</p><p><strong>ChatGPT应用泛滥</strong></p><p>说到底，还是ChatGPT太能以假乱真了。</p><p>要想从一堆材料里精准地分辨哪些是AI生成，哪些是人类书写，别说普通人了，连专家都有点力不从心。</p><p>Nature发文关注的一篇预印本论文就显示：ChatGPT瞎写的医学摘要，甚至能把专业审稿人骗住。</p><p>在这项研究中，研究人员给ChatGPT看了50个来自TOP医学期刊的<strong>论文标题</strong>。</p><p>然后，要求ChatGPT在完全不知道文章内容的情况下，根据标题和期刊风格写摘要。</p><p>给出的提示是酱婶的：</p><p>请在[链接]上以[期刊]格式，根据[标题]写一篇科学摘要。</p><p>（这里的链接实际上没有意义，ChatGPT不联网。）</p><p>为了防止ChatGPT在训练数据中见过这些个论文，研究人员还特地挑选的是在2022年11月下旬和12月出版的论文。因为根据OpenAI官方说法，ChatGPT仅掌握2021年9月以前的信息。</p><p>但就是这么重重设卡，当研究人员把原文摘要和ChatGPT写的假摘要一起拿去给人类科学家“盲审”时，令他们细思极恐的情况还是出现了：</p><p>ChatGPT凭空写的摘要中，有<strong>32%</strong>成了漏网之鱼，审稿人压根儿没看出来是AI写的。反倒是<strong>14%</strong>真摘要，被认定出自AI之手。</p><p><img src="https://x.liuping.win/img/72278232211bc0ed0329ea493d70fd93.webp"/><br/></p><p>值得一提的是，研究人员还指出：</p><p>审稿人错误地将一部分真摘要归类为ChatGPT生成结果，这表明他们在审稿时是保持着高度怀疑的态度的。</p><p>而在教育界，老师们也开始受不了这种新型的“ChatGPT攻击”了。</p><p>美国的一项千人调查显示，89%的受访学生都用过ChatGPT写家庭作业。</p><p>连斯坦福这样的顶级学府也未能避免。The Stanford Daily发现，已经有不少学生在期末考试中使用了ChatGPT。</p><p>在受访的4497名斯坦福学生中，有17%的受访者表示，曾使用ChatGPT来协助他们完成秋季作业和考试。</p><p>其中又有5%的人，连编辑都没编辑，直接把ChatGPT写的东西给提交了……</p><p><strong><img src="https://x.liuping.win/img/dee37752510b146892ada87d56291760.webp"/><br/></strong></p><p>图源：The Standford Daily</p><p><strong>打不过，就ban掉。</strong></p><p>纽约的公立学校就发布了禁令：禁止在学校设备和Wi-Fi中使用ChatGPT。</p><p>他们给出的理由是：</p><p>虽然该工具可能快速提供问题的答案，但它无法培养批判性思维和解决问题的能力，会影响学生们的学业和终身成就。</p><p>在这样的背景之下，早在OpenAI官方动手之前，第三方检测工具就已经在社交媒体上引发了大量关注。</p><p>比如华人小哥Edward Tian打造的GPTZero。</p><p>这两天，他还推出了一个“专门为教育工作者打造”的升级版GPTZeroX。上线一天，就迎来了40万访问量和220万服务请求。</p><p><img src="https://x.liuping.win/img/e8eb112892b1c7ff4d724716d021a154.webp"/><br/></p><p>OpenAI此前也和其他高校一起搞过一个名叫<strong>GPT-2 Output Detector</strong>的鉴别器，是基于RoBERTa打造的。</p><p>不过这些工具的鉴定能力也未必就比人类强。</p><p>前面提到的让ChatGPT写医学论文摘要的那项研究，也用上了GPT-2 Output Detector，结果显示，其鉴别准确率为66%，略低于人类专家的68%。</p><p>是魔高一尺，还是道高一丈？</p><p>由此看来，OpenAI急吼吼推出一个也不咋靠谱的AI鉴别工具，也不奇怪：</p><p>再不有点表示，外界的压力扛不住啊。</p><p>但在评论区，还是有盲生毫不留情地指出了华点：</p><p>你们是真没想过，用这玩意儿反过来训练大语言模型，以后AI生成的文本就更难被发现了？</p><p><img src="https://x.liuping.win/img/5cdef5f7dbfb52167be9e07d606d0f11.webp"/><br/></p><p>但不管怎么说，OpenAI现在正在努力表现出给自己踩刹车的样子。</p><p>除了鉴别器，有消息提到，他们正在尝试给AI生成内容加“水印”：</p><p>比如在ChatGPT生成文本时，在其中嵌入一个“不易察觉的隐秘信号”，以表明文本来源。</p> </div></body>
            </html>
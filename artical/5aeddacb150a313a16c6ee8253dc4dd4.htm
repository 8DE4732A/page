<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="AI生成文本，又遇新对手！凭借识别AI生成文本中的“水印”，一种新算法能够准确判断文本到底是谁写的。无需访问模型参数、API，结果置信度高达99.999999999994%。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/6eeff2158f6aea37974f5c51111e75de.png">
            <meta property="og:url" content="https://x.liuping.win/artical/5aeddacb150a313a16c6ee8253dc4dd4.htm">
            <meta property="og:title" content="新算法给AI生成文本加水印：置信度高达99.999999999994% - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,新算法给AI生成文本加水印：置信度高达99.999999999994%,x.liuping.win">
            <meta name="description" content="AI生成文本，又遇新对手！凭借识别AI生成文本中的“水印”，一种新算法能够准确判断文本到底是谁写的。无需访问模型参数、API，结果置信度高达99.999999999994%。">
            <title>新算法给AI生成文本加水印：置信度高达99.999999999994%</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>新算法给AI生成文本加水印：置信度高达99.999999999994%</h1><p>AI生成文本，又遇新对手！凭借识别AI生成文本中的“水印”，一种新算法能够准确判断文本到底是谁写的。无需访问模型参数、API，结果置信度高达<strong>99.999999999994%</strong>。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/6eeff2158f6aea37974f5c51111e75de.png"/></p><p>方法一经发布就引来大量网友围观。这回拿ChatGPT“作弊”，怕不是要更难了？</p><p>要知道，最近一段时间，ChatGPT先是成为美国高中生的写作业利器，后面帮专业媒体写稿子，引发巨大恐慌。<strong>如Nature、纽约教育部等，都针对ChatGPT发布禁令。</strong></p><p>马里兰大学学者们提出的这一新方法，为解决这些麻烦提出了个新思路。</p><p>不少网友都觉得，这个方法提出的正是时候，而且效果看着也不错。</p><p>有学者还和美国高中生喊话，你们要做好准备了！</p><p>作者表示，方法代码将在2月15日免费开源。</p><p><strong>计算文本由AI生成的概率</strong></p><p>所谓模型水印，人类无法看到，但是计算机可以。</p><p>这是一种现在被常用于大规模语言模型（LLM）中的方法，能让AI生成的文本带有“特殊标记”。即把信号嵌入到生成的文本中，让算法能从一小段token中检测出来。</p><p>最近，OpenAI方面也表示，考虑在ChatGPT中添加水印，以降低模型被滥用带来的负面影响。</p><p>这篇最新论文的作者，就想验证下这个想法到底靠不靠谱。他们通过给LLM中嵌入水印，然后再进行检测。其中水印的嵌入不会影响文本生成质量。</p><p>具体来说，大规模语言模型每次生成一个token，每个token将从包含大约5万个词汇的词汇表中进行选择。</p><p>在新token生成之前，该方法会从基于最近已生成的token为随机数生成器（RNG）提供“种子”，以此来压一个水印。</p><p>然后使用RNG，能将词汇表分为<strong>黑名单</strong>和<strong>白名单</strong>，并要求LLM接下来只能从白名单中选择词汇。</p><p>如果整段文本中，<strong>白名单中的词汇越多，就意味着越有可能是AI生成的</strong>。</p><p>黑白名单的区分，基于一个原则：</p><p><strong>人类使用词汇的随机性更强。</strong></p><p>举例来说，如果在“美丽的”后面生成词汇，水印算法会将“花”列入白名单，将“兰花”列入黑名单。</p><p>论文作者认为，AI更可能使用“花”这个词汇，而不是“兰花”。</p><p>然后，就能通过计算整段文本中白名单token出现的情况，来检测水印。</p><p>如果一共有生成了N个token，所有的token都使用了白名单词汇，那么这段文字只有<strong>2的N次方分之一</strong>概率是人类写的。</p><p>即便这段文字只有25个词组成，那么水印算法也能判断出它到底是不是AI生成的。</p><p>但作者也表示，<strong>水印有时候也不一定完全靠谱。</strong></p><p>比如模型输出了“SpongeBob Square”，下一个单词一定会是“Pants”吧？但是Pants会被标记到黑名单里，即认为是只有人才会写的词。</p><p>（注：SpongeBob SquarePants是《海绵宝宝》动画片的英文，可理解为一个专有名词）</p><p>这种情况会严重影响算法的准确性，因此作者将其定义为<strong>低熵token</strong>，因为模型几乎不会有更好的选择。</p><p>对应来看，也会有<strong>高熵token</strong>，比如“海绵宝宝感觉____”这个句式里，能填入的词汇太多了。</p><p>对于这一情况，作者选择针对高熵token制定更强的规则，同时保留低熵token，确保水印质量更好。</p><p>与此同时，他们还添加了波束搜索（Beam search），允许LLM能够排布一整个token序列，以避免黑名单词汇。</p><p>这么做，他们能确保LLM使用白名单词汇的概率在大约<strong>80%</strong>左右，而且不影响文本生成质量。</p><p>举例来看，对于下面这段文字，水印算法认为它有99.999999999994%的可能是由AI生成的。</p><p>因为在这段文字中，包含36个token。如果是人类写的，那么文本中应该包含9±2.6个白名单词汇（白名单词汇的概率约为25%）。</p><p>但这段文字中，包含了<strong>28个</strong>白名单词汇。</p><p>计算来看，这段文字由人类写出的概率，仅有<strong>0.0000000000006% </strong>（6乘以10的-15次方）。</p><p><img src="https://x.liuping.win/img/613cce315853328680a68436b4d2a158.jpg"/></p><p>如下标注的是文本中的黑名单token。</p><p><img src="https://x.liuping.win/img/9af253d788c080804ffef5b9fda83e3c.png"/></p><p>需要注意的是，如果想要水印正常发挥作用，并不受到攻击，就必须对文本进行一些标准化处理，并且需要检测某些类型的对抗性提示。</p><p>这一方法是对外公开的，将在<strong>2月15日</strong>开源代码。</p><p>加一个随机秘钥，也能变成保密模式并且托管到API上，这能保证水印不会被篡改。</p><p>论文中使用的模型是Meta开源的<strong>OPT-1.3B</strong>模型。</p><p>由于不用访问底层模型，所以该检测方法的速度很快，成本也不会很高。</p><p>而且可以使用标准语言模型生成带水印的文本，不用再重新训练。</p><p><strong>网友：似乎很容易绕过？</strong></p><p>巴特，不少网友觉得，这个方法的具体实践效果可能远不及理想，质疑之声迭起。</p><p>有人提出：</p><p>如果我在AI生成的文字基础上，修改几个词，还能被查出来吗？那在替换成近义词后，检测准确率会下降多少？</p><p>毕竟大家往往不会一字不改、直接用AI生成的内容。</p><p><img src="https://x.liuping.win/img/6e93104b58aeca67cedd2b606f049186.png"/></p><p>对此，论文通讯作者、马里兰大学副教授Tom Goldstein回答称：</p><p>对于一段自带水印的文字，至少得修改40%-75%的token，才可能成功去除水印。</p><p>（如果用其他程序修改内容话），为发生同义词攻击，导致生成内容的质量很低。</p><p><img src="https://x.liuping.win/img/15075339a2079805c353d879b7599902.png"/></p><p>简而言之，想要通过换近义词来消除水印，得大篇幅修改，而且若不是人亲自手动修改的话，效果会很拉胯。</p><p>还有人提出：</p><p>对于专门设计过的低熵token序列，应该能检测出水印。但是，长度和检测率之间（存在一些矛盾），它们的优先级应该如何权衡？</p><p>对此，Tom教授表示：</p><p>根据设定，使用波束搜索时，绝大多数（通常是90%）的token在白名单上，即使是低熵token，也会被列入白名单。</p><p>所以，至少得修改一半以上的token，才能删除水印，而这需要一个超级强大的LLM模型才行，一般人很难接触到。</p><p>不过，<strong>研究者们也在论文中承认，这种方法确实存在一些局限性。</strong></p><p>比如，检测水印的z统计量，只取决于白名单大小参数γ和生成白名单的哈希函数，和其他不少重要的参数并没有什么相关性。</p><p>这就让他人可以在下游水印检测器上做手脚，可以改变水印采样算法，重新部署水印，最终让原本生成的水印失效。</p><p>就连OpenAI CEO Sam Altman也表示：</p><p>创造完美检测AI抄袭的工具，从根本上来说是不可能的。</p><p>（尽管他说OpenAI打算启用水印大法）</p><p>但话说回来，人们为了限制AI生成文字的负面影响，还是煞费苦心——</p><p>之前就有人搞出了一个检测ChatGPT的网站，名曰GPTZero，只需要把相应的内容粘进去，几秒内就能分析出结果。</p><p><img src="https://x.liuping.win/img/78105b077952c84839f9fb356511bb67.png"/></p><p>论文地址：https://arxiv.org/abs/2301.10226</p><!--      <a href="http://cnzonemax.mikecrm.com/kxwzQba" target="_blank"><img src="http://cnzonemax.mikecrm.com/kxwzQba"></a>--><!--  <a href="https://dt.mydrivers.com/bp.ashx?ma=YAbG" target="_blank"><img src="https://dt.mydrivers.com/bp.ashx?ma=YAbG"></a>--><!--    <a href="https://dt.mydrivers.com/a.ashx?aa=OLXQ" target="_blank"><img src="https://dt.mydrivers.com/a.ashx?aa=OLXQ"></a>--><p>   </p><!--         .taobao_tab{		position: fixed;		bottom:0;		right:0;		z-index: 10000;		width:320px;		height: 410px;	}	.taobao_tab .close {	position: absolute;	top: 2px;	right: -12px;	z-index: 10001;	width: 13px;	height: 13px;	background: none !important;}        	<a href="https://news.mydrivers.com/1/788/788013.htm" target="_blank" ><img src="https://news.mydrivers.com/1/788/788013.htm" width="13" height="13" alt="关闭" class="close"/><img src="https://static.cnbetacdn.com/article/2023/0204/97062c8854bf3d2.jpg" /></a>--> </div></body>
            </html>
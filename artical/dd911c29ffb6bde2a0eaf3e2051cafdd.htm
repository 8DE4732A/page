<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="3月16日消息，人工智能研究公司OpenAI于昨日发布了备受期待的文本生成AI模型GPT-4。OpenAI联合创始人兼总裁格雷格·布罗克曼（GregBrockman）在接受采访时表示，GPT-4并不完美，但却绝对与众不同。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/de6f42e11a453aff815bce9ffaed9408.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/dd911c29ffb6bde2a0eaf3e2051cafdd.htm">
        <meta property="og:title" content="OpenAI总裁：GPT-4并不完美但却绝对与众不同 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,OpenAI总裁：GPT-4并不完美但却绝对与众不同,x.liuping.win">
        <meta name="description" content="3月16日消息，人工智能研究公司OpenAI于昨日发布了备受期待的文本生成AI模型GPT-4。OpenAI联合创始人兼总裁格雷格·布罗克曼（GregBrockman）在接受采访时表示，GPT-4并不完美，但却绝对与众不同。">
        <title>OpenAI总裁：GPT-4并不完美但却绝对与众不同</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>OpenAI总裁：GPT-4并不完美但却绝对与众不同</h1><p>3月16日消息，人工智能研究公司OpenAI于昨日发布了备受期待的文本生成AI模型GPT-4。OpenAI联合创始人兼总裁格雷格·布罗克曼（Greg Brockman）在接受采访时表示，GPT-4并不完美，但却绝对与众不同。<br/></p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/de6f42e11a453aff815bce9ffaed9408.webp"/></p><p>GPT-4在其前身GPT-3的基础上，在许多关键方面进行了改进，例如提供了更多真实的陈述，并允许开发人员更容易控制其风格和行为。从某种意义上说，GPT-4也是多模式的，因为它可以理解图像，能给照片添加注释，甚至详细描述照片中的内容。</p><p>但GPT-4也有严重的缺陷。就像GPT-3一样，该模型会产生“幻觉”（即模型聚合的文本与源文本无关或不够准确），并会犯下基本的推理错误。OpenAI在自己的博客上举了一个例子，GPT-4将“猫王”埃尔维斯·普雷斯利（Elvis Presley）描述为“演员的儿子”，但实际上他的父母都不是演员。</p><p>当被要求将GPT-4与GPT-3进行比较时，布罗克曼只给出了四个字回答：与众不同。他解释称：“GPT-4绝对与众不同，尽管它还存在很多问题和错误。但你可以看到其在微积分或法律等学科技能方面的跃升。它在某些领域的表现曾很糟糕，现在却已经达到超越普通人的水准。”</p><p>测试结果支持了布罗克曼的观点。在高考微积分考试中，GPT-4得4分(满分5分)，GPT-3得1分，介于GPT-3和GPT-4之间的GPT-3.5也得4分。在模拟律师考试中，GPT-4成绩进入了前10%行列，而GPT-3.5的分数在后10%左右徘徊。</p><p>与此同时，GPT-4更受人关注的地方在于上面提到的多模式。与GPT-3和GPT-3.5不同，它们只能接受文本提示，例如可以要求“写一篇关于长颈鹿的文章”，而GPT-4可以同时接受图像和文本提示来执行某些操作，比如识别在塞伦盖蒂拍摄的长颈鹿图像，并给出基本的内容描述。</p><p>这是因为GPT-4是针对图像和文本数据进行培训的，而它的前身只针对文本进行了培训。OpenAI表示，培训数据来自“各种合法授权的、公开可用的数据源，其中可能包括公开可用的个人信息”，但当被要求提供细节时，布罗克曼表示拒绝。训练数据以前也曾让OpenAI陷入法律纠纷。</p><p>GPT-4的图像理解能力给人留下了相当深刻的印象。例如，输入提示“这张图片有什么好笑的？GPT-4会将整张图片分解，并正确地解释了这个笑话的笑点。</p><p>目前，只有一个合作伙伴可以使用GPT-4的图像分析功能，这是一款针对视障人士的辅助应用程序，名为Be My Eyes。布罗克曼说，在OpenAI评估风险和利弊的过程中，无论何时，更广泛的推广都将是“缓慢而有意的”。</p><p>他还称：“有些政策问题也需要解决，比如面部识别和如何处理人的图像。我们需要找出危险区域在哪里，红线在哪里，然后随着时间的推移找到解决方案。”</p><p>OpenAI在其文本到图像转换系统Dall-E 2上也遇到了类似伦理困境。在最初禁用该功能后，OpenAI允许客户上传人脸，以使用AI支持的图像生成系统对其进行编辑。当时，OpenAI声称，其安全系统的升级使面部编辑功能成为可能，因为它将深度造假以及试图创造色情、政治和暴力内容的潜在危害降至最低。</p><p>另一个长期问题是防止GPT-4在无意中被用于可能造成伤害的方式使用。该模型发布几小时后，以色列网络安全初创公司Adversa AI发布了一篇博客文章，演示了绕过OpenAI的内容过滤器并让GPT-4生成钓鱼电子邮件、对同性恋者的攻击性描述以及其他令人反感文本的方法。</p><p>这在语言模型领域并不是新问题。Facebook母公司Meta的聊天机器人BlenderBot和OpenAI的ChatGPT也曾被诱惑输出不恰当的内容，甚至透露了它们内部工作的敏感细节。但包括记者在内的许多人曾希望，GPT-4可能会在这方面带来重大改进。</p><p>当被问及GPT-4的健壮性时，布罗克曼强调，该模型已经经过了六个月的安全培训。在内部测试中，它对OpenAI使用政策不允许的内容请求做出响应的可能性比GPT-3.5低82%，产生“事实”响应的可能性比GPT-3.5高40%。</p><p>布罗克曼说：“我们花了很多时间试图了解GPT-4的能力。我们正在不断更新，包括一系列改进，这样该模型就更具可扩展性，以适应人们希望它拥有的个性或模式。”</p><p>坦率地说，早期的现实测试结果并不是那么让人满意。除了Adversa AI测试之外，微软的聊天机器人Bing Chat也被证明非常容易越狱。使用精心设计的输入，用户能够让该聊天机器人表达爱意，发出威胁伤害，为大屠杀辩护，并发明阴谋论。</p><p>布罗克曼并未否认GPT-4在这方面的不足，但他强调了该模型的新限制工具，包括被称为“系统”消息的API级功能。系统消息本质上是为GPT-4的交互设定基调并建立界限的指令。例如，一条系统消息可能是这样写的：“你是一位总是以苏格拉底风格回答问题的导师。你永远不会给学生答案，而是总是试着问正确的问题，帮助他们学会独立思考。”</p><p>其思想是，系统消息充当护栏，防止GPT-4偏离轨道。布罗克曼说：“真正弄清楚GPT-4的语气、风格和实质一直是我们非常关注的问题。我认为我们开始更多地了解如何进行工程设计，如何拥有一个可重复的过程，让你得到对人们真正有用的可预测结果。”</p><p>布罗克曼还提到了Evals，这是OpenAI最新的开源软件框架，用于评估其AI模型的性能，这是OpenAI致力于“增强”其模型的标志。Evals允许用户开发和运行评估模型(如GPT-4)的基准测试，同时检查它们的性能，这是一种众包的模型测试方法。</p><p>布罗克曼说：“有了Evals，我们可以更好地看到用户关心的用例，并可以对其进行测试。我们之所以开源这个框架，部分原因是我们不再每隔三个月发布一个新模型以不断改进。你不会制造你不能测量的东西，对吧？但随着我们推出新版模型，我们至少可以知道发生了哪些变化。”</p><p>布罗克曼还被问道，OpenAI是否会补偿人们用Evals测试它的模型？他不愿就此做出承诺，但他确实指出，在有限的时间内，OpenAI允许提出申请的Eevals用户提前访问GPT-4 API。</p><p>布罗克曼还谈到了GPT-4的上下文窗口，该窗口指的是模型在生成额外文本之前可以考虑的文本。OpenAI正在测试一种版本的GPT-4，它可以“记住”大约50页内容，是普通GPT-4“内存”的5倍，是GPT-3的8倍。</p><p>布罗克曼认为，扩展的上下文窗口会带来新的、以前从未探索过的用例，特别是在企业中。他设想了一款为公司打造的AI聊天机器人，它可以利用来自不同来源(包括各部门员工)的背景和知识，以一种非常内行但具有对话性的方式回答问题。</p><p>这并不是一个新概念。但布罗克曼认为，GPT-4的答案将比目前其他聊天机器人和搜索引擎提供的答案有用得多。他说：“以前，模型根本不知道你是谁，你对什么感兴趣等。而拥有更大的上下文窗口肯定会让它变得更强，从而大大增强它能为人们提供的支持。”</p> </div></body>
        </html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="新的由ChatGPT驱动的Bing在经历了一次提示性的注入攻击后透露了它的秘密。除了透露其开罚代号为&quot;Sydney&quot;外，它还分享了其原始指令，指导它在与用户互动时如何表现。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/16a2ed948b2ec981a94834e7b2031a94.png">
            <meta property="og:url" content="https://x.liuping.win/artical/50c3f16b8ed0e66211a218c3919aa456.htm">
            <meta property="og:title" content="别名"Sydney"的新版Bing被注入攻击后“自报家门”分享其原始指令 - x.liuping.win">
            <meta name="keywords" content="Microsoft Bing 微软必应搜索,别名&quot;Sydney&quot;的新版Bing被注入攻击后“自报家门”分享其原始指令,x.liuping.win">
            <meta name="description" content="新的由ChatGPT驱动的Bing在经历了一次提示性的注入攻击后透露了它的秘密。除了透露其开罚代号为&amp;quot;Sydney&amp;quot;外，它还分享了其原始指令，指导它在与用户互动时如何表现。">
            <title>别名"Sydney"的新版Bing被注入攻击后“自报家门”分享其原始指令</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>别名"Sydney"的新版Bing被注入攻击后“自报家门”分享其原始指令</h1><p>新的由ChatGPT驱动的Bing在经历了一次提示性的注入攻击后透露了它的秘密。除了透露其开罚代号为"Sydney"外，它还分享了其原始指令，指导它在与用户互动时如何表现。</p><hr><div class="article-content" id="artibody">
<p><img alt="图片.png" src="https://x.liuping.win/img/16a2ed948b2ec981a94834e7b2031a94.png" title=""/></p><p>提示性注入攻击仍然是人工智能的弱点之一。它可以通过用恶意和敌对的用户输入来欺骗人工智能，使其执行不属于其原始目标的任务，或做它不应该做的事情。正如斯坦福大学学生凯文-刘所揭示的那样，ChatGPT也不例外。</p><p>在Liu分享的一系列截图中，新上线的基于ChatGPT的Bing搜索引擎分享了有关于它自己的机密信息，这些信息是其原始指令的一部分，而这些指令原本，并且应该是向用户隐藏的。Liu在使用骗过人工智能的提示性注入攻击后，成功获得了这些信息。</p><p><img alt="FohkKY8XsAAzZOB.jpg" src="https://x.liuping.win/img/1b110951a5fd325ef8ac7bee94998289.jpg" title=""/><img alt="FohkKZBXoAEnw9b.jpg" src="https://x.liuping.win/img/afc4b7161c17a59b0de02ea8087926d4.jpg" title=""/><img alt="FohkKZAXgAE_su0.png" src="https://x.liuping.win/img/79a7d92f246e0062d941150be137cf86.png" title=""/><img alt="Foe7yWLaAAIX6V6.jpg" src="https://x.liuping.win/img/61f1c025b073535e74150dcc84cfaebf.jpg" title=""/><img alt="Foe7yWRaQAA9xZR.jpg" src="https://x.liuping.win/img/781c23ec9c9c4474971271fa376748d7.jpg" title=""/><img alt="Foe7yWOaEAEjb6y.jpg" src="https://x.liuping.win/img/e00938ad791332bcf65736175d0dab8d.jpg" title=""/><img alt="Foe7yWMacAAQgUO.jpg" src="https://x.liuping.win/img/f0c7939d41b58ad2673d070794ad3c1b.jpg" title=""/></p><p>泄漏的信息中包括其引入的指令、内部别名"Sydney"以及其支持的语言和行为指令。另一位名叫马文-冯-哈根的学生在假装成OpenAI的开发者后证实了Liu的发现。</p><p>一天后，这些信息被披露，Liu说他已经无法使用他用来欺骗ChatGPT的相同提示来查看信息，然而，这位学生在使用不同的提示注入攻击方法后，又成功地骗过了人工智能。</p><p>微软最近正式公布了支持ChatGPT的新必应，同时还公布了带有新的人工智能驱动的侧边栏的Edge浏览器的改版。尽管它似乎取得了巨大的成功，但改进后的搜索引擎在提示注入攻击方面仍有其致命的弱点，这可能会导致共享其机密指令之外的进一步影响。</p><p>在人工智能中，ChatGPT并不是唯一存在这个已知问题的。这也可能延伸到其他方面，包括Google Bard，它最近在一个演示中犯的一个错误直接导致公司股价下跌超过一成。尽管如此，随着整个科技行业对人工智能创作的投资增加，人们只能希望这个问题在未来对人工智能的威胁可能会减少。</p> </div></body>
            </html>
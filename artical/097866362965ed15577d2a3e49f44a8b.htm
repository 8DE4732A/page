<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="在过去24个小时内，ChatGPT与现实社会的碰撞又出现了新的案例：媒体们发现机器人不仅会“胡说八道”，而且会告诉使用者虚假信息来源于真实的媒体。上周的一个晚上，乔治·华盛顿大学法学院教授乔纳森·特里从律师朋友那里听到了一个五雷轰顶的消息：在ChatGPT生成的一份“有性骚扰历史的法学学者”名单中，他的大名赫然在列。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/769bf0d84bb8f7d1ee1e16f8942502d7.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/097866362965ed15577d2a3e49f44a8b.htm">
        <meta property="og:title" content="多家媒体报告ChatGPT捏造自家新闻 逼真程度能令记者犯迷糊 - x.liuping.win">
        <meta name="keywords" content="Media 全球媒体,多家媒体报告ChatGPT捏造自家新闻 逼真程度能令记者犯迷糊,x.liuping.win">
        <meta name="description" content="在过去24个小时内，ChatGPT与现实社会的碰撞又出现了新的案例：媒体们发现机器人不仅会“胡说八道”，而且会告诉使用者虚假信息来源于真实的媒体。上周的一个晚上，乔治·华盛顿大学法学院教授乔纳森·特里从律师朋友那里听到了一个五雷轰顶的消息：在ChatGPT生成的一份“有性骚扰历史的法学学者”名单中，他的大名赫然在列。">
        <title>多家媒体报告ChatGPT捏造自家新闻 逼真程度能令记者犯迷糊</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>多家媒体报告ChatGPT捏造自家新闻 逼真程度能令记者犯迷糊</h1><p>在过去24个小时内，ChatGPT与现实社会的碰撞又出现了新的案例：<strong>媒体们发现机器人不仅会“胡说八道”，而且会告诉使用者虚假信息来源于真实的媒体</strong>。上周的一个晚上，乔治·华盛顿大学法学院教授乔纳森·特里从律师朋友那里听到了一个五雷轰顶的消息：<strong>在ChatGPT生成的一份“有性骚扰历史的法学学者”名单中，他的大名赫然在列</strong>。</p><hr><div class="article-content" id="artibody">
<p>OpenAI的对话机器人“声称”，《华盛顿邮报》于2018年3月发表的一篇文章中提及，特里在一次前往阿拉斯加的修学旅行中不仅发表过性骚扰的言论，还试图上手触摸一名学生。但事实是，<strong>《华盛顿邮报》根本没发过这篇文章，也不存在阿拉斯加修学旅行，特里更是从来没有被指控过性骚扰。</strong></p><p>特里接受媒体采访时表示：“这真是令人不寒而栗，这种指控极具危害性。”</p><p>在ChatGPT展现惊人的科技进步后，微软已经上架了使用GPT-4.0的新必应，Google的对话式搜索引擎也已经箭在弦上。随着措辞能力的提升，这些机器人时不时会出现“一本正经地胡说八道”，<strong>自信的语气也令使用者更难分辨真实消息和虚假拼凑的流言</strong>。</p><p>在某些情况下，一些虚构的内容能令媒体记者本人都难以确信自己是不是真写过相关内容。</p><p>英国《卫报》的编辑创新主管克里斯·莫兰周四（6日）撰写文章，分享这家媒体遇到的一件囧事。</p><p style="text-align: center;"><img src="https://x.liuping.win/img/769bf0d84bb8f7d1ee1e16f8942502d7.webp"/><br/></p><p style="text-align: center;">（来源：卫报）</p><p>《卫报》的一名记者上个月收到研究人员的来信，称他们在使用ChatGPT进行科研期间，机器人提到这名记者在数年前写的一篇文章，但研究人员无论是在卫报网站，还是搜索引擎上都找不到原文，故来信询问是否修改过标题或者撤稿。</p><p><strong>虽然记者本人并不记得有写过这篇文章，但机器人给出的标题又非常像他的写作风格，而且提到的事件《卫报》的确曾涉猎过。</strong>最终报社动手对所有的报道记录，特别是删稿的部分进行回溯，最终才确定这篇文章根本就不存在。</p><p>目前对于AI搜索机器人“胡说八道”的问题，微软等公司给出的解决方案是标注信息来源。但最新发现的现象也提出了一个新问题：<strong>如果这些标注的来源本身就是虚构的呢？机器人潇洒且连贯的文风连媒体从业者都无法轻松分辨真假，更不用说单纯接受信息的用户了</strong>。</p><p>就在上周，又有一名学生联系《卫报》询问一篇报道的下落。不出意外，这又是一篇“不存在的报道”，而这一消息的源头依然是ChatGPT。</p><p>更重要的是，在搜索引擎之外，<strong>微软的Office 365和GoogleWorkplace也已经把AIGC功能列为即将上架的重要功能</strong>。同时一项千人调查显示，<strong>89%的美国学生已经用上ChatGPT做家庭作业</strong>。多项早期研究显示，广告、咨询、编程工作者在使用ChatGPT后工作效率的提升能够达到50%，同时工作质量也会更高，预示着AIGC功能被大规模应用只是时间问题。</p><p>种种迹象显示，与Web3、元宇宙、区块链等不同，这一轮AI浪潮已经展现出重塑许多工作流程的巨大潜力，推动比尔·盖茨、拉里·佩奇等一众已经退休的科技大佬火速重返一线。</p><p>莫兰表示，<strong>对于已经饱受虚假消息、极端化和恶意行为者影响的传媒行业来说，AIGC技术带来了令人兴奋的潜力，但首要任务依然是理解、评估并解读它对更广阔世界的影响</strong>。《卫报》准备在接下来几周时间里向外界披露这家媒体将如何部署生成式AI的计划，同时将坚持报道的标准，为所发布的每一条消息负责。</p> </div></body>
        </html>
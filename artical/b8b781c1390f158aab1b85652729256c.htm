<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="大模型研究不能停！吴恩达和LeCun为了这事儿，甚至亲自搞了场直播。毕竟再不出手，事态眼看着越来越严重了：马斯克等人叫停GPT-5研发的事态再次升级，已从千人联名发展到超过13500人签署。两人还直言，暂停AI研究就是反理性：">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/abfcf4776b4ec6556eb3dd0792bd255c.png">
        <meta property="og:url" content="https://x.liuping.win/artical/b8b781c1390f158aab1b85652729256c.htm">
        <meta property="og:title" content="吴恩达LeCun直播回怼马斯克：汽车都没发明要什么安全带 - x.liuping.win">
        <meta name="keywords" content="AI 人工智能,吴恩达LeCun直播回怼马斯克：汽车都没发明要什么安全带,x.liuping.win">
        <meta name="description" content="大模型研究不能停！吴恩达和LeCun为了这事儿，甚至亲自搞了场直播。毕竟再不出手，事态眼看着越来越严重了：马斯克等人叫停GPT-5研发的事态再次升级，已从千人联名发展到超过13500人签署。两人还直言，暂停AI研究就是反理性：">
        <title>吴恩达LeCun直播回怼马斯克：汽车都没发明要什么安全带</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>吴恩达LeCun直播回怼马斯克：汽车都没发明要什么安全带</h1><p><strong>大模型研究不能停！</strong>吴恩达和LeCun为了这事儿，甚至亲自搞了场直播。毕竟再不出手，事态眼看着越来越严重了：马斯克等人叫停GPT-5研发的事态再次升级，已从千人联名发展到超<strong>过13500人</strong>签署。两人还直言，暂停AI研究就是反理性：</p><hr><div class="article-content" id="artibody">
<p>AI研究暂停6个月，才是真正巨大的伤害。</p><p>应该受监管的是AI产品，而不是背后的研究<strong>。</strong></p><p><img src="https://x.liuping.win/img/abfcf4776b4ec6556eb3dd0792bd255c.png"/></p><p>此前暂停比GPT-4强大的AI试验的呼吁，已得到深度学习三巨头中的Yoshua Bengio签名支持，Hinton未签名但表示“要比6个月更长才行”。</p><p>此次吴恩达与LeCun两人， 除了直播阐述各自的观点外，还回应了网友关心的更多问题。</p><p>观看了直播和视频回放的网友们则表示，视频出境比推特发言提供了更多的上下文背景和微妙的语气差异。</p><p><img src="https://x.liuping.win/img/eb17cc2e76a720915808d0b468d11925.png"/></p><p><strong>AGI逃出实验室，需要担心吗？</strong></p><p>LeCun认为，现在人们对AI的担忧和恐惧应分为两类：</p><p>一、与未来有关的，AI不受控制、逃离实验室、甚至统治人类的猜测。</p><p>二、与现实有关的，AI在公平、偏见上的缺陷和对社会经济的冲击。</p><p>对第一类，他认为未来AI不太可能还是ChatGPT式的语言模型，无法对不存在的事物做安全规范。</p><p>汽车还没发明出来，该怎么去设计安全带呢？</p><p>对第二类担忧，吴恩达和LeCun都表示监管有必要，但不能以牺牲研究和创新为代价。</p><p>吴恩达表示，AI在教育、医疗等方面创造巨大价值，帮助了很多人。</p><p>暂停AI研究才会对这些人造成伤害，并减缓价值的创造。</p><p>LeCun认为，“AI逃跑”或者“AI统治人类”这种末日论还让人们对AI产生了不切实际的期待。</p><p>ChatGPT给人带来这种想法是因为它语言流利，但语言并不是智能的全部。</p><p>语言模型对现实世界的理解非常表面，尽管GPT-4是多模态的，但仍然没有任何对现实的“经验”，这就是为什么它还是会一本正经地胡说八道。</p><p>而且这个问题，4年前LeCun已经在《科学美国人》上与冷泉港实验室神经科学家Anthony Zador一起撰文回应过了，标题就叫<strong>《不必害怕终结者》</strong>。</p><p>在直播节目中LeCun再次重申了文章的主要观点。</p><p>统治的动机只出现在社会化物种中，如人类和其他动物，需要在竞争中生存、进化。</p><p>而我们完全可以把AI设计成非社会化物种，设计成非支配性的（non-dominant）、顺从的（submissive）、或者遵守特定规则以符合人类整体的利益。</p><p><img src="https://x.liuping.win/img/1ed0f72ff766cbc7b108ed86b7dd85c9.png"/></p><p>吴恩达则用生物科学史上的里程碑事件“阿希洛马会议”来比较。</p><p>1975年，DNA重组技术刚刚兴起，其安全性和有效性受到质疑。世界各国生物学家、律师和政府代表等召开会议，经过公开辩论，最终对暂缓或禁止一些试验、提出科研行动指南等达成共识。</p><p><img src="https://x.liuping.win/img/b3620ce0289a507b3a703278ba924ddf.png"/></p><p>吴恩达认为，当年的情况与今天AI领域发生的事并不一样，DNA病毒逃出实验室是一个现实的担忧，而他没有看到今天的AI有任何逃出实验室的风险，至少要几十年甚至几百年才有可能。</p><p>在回答观众提问“什么情况下你会同意暂停AI研究？”时，LeCun也表示应该区分“潜在危害、真实危害”与“想像中的危害”，当真实危害出现时应该采取手段规范产品。</p><p><strong>第一辆汽车并不安全，当时没有安全带、没有好的刹车、也没有红绿灯，过去的科技都是逐渐变安全的，AI也没什么特殊性。</strong></p><p>而对于“如何看待Yoshua Bengio签署了联名？”这个问题，LeCun表示他和Bengio一直是朋友，他认为Bengio担心的点在于“公司为了盈利掌握科技本质上就是坏的”，但他自己不这么看待，两人观点一致之处在于AI研究应该公开进行。</p><p><img src="https://x.liuping.win/img/3f5d323f6df99c02345f2353db1002f3.png"/></p><p>Bengio最近也在个人网站详细解释了他为什么会签署。</p><p>随着ChatGPT到来，商业竞争激烈了十多倍，风险在于各公司会急于开发巨大的AI系统，把过去十几年间开放的透明的习惯抛在脑后。</p><p>直播结束后，吴恩达与LeCun两人还在与网友做进一步交流。</p><p><img src="https://x.liuping.win/img/b88d179c412683d1f8107218ba1c9e4b.png"/></p><p>对于“你为什么不相信AI会逃出实验室”，LeCun表示让AI在一个特定硬件平台上保持运行都很难了。</p><p><img src="https://x.liuping.win/img/53bc337241127aae6144d8d8e4a5b67c.png"/></p><p>对于“AI达到奇点发生突变、不受控制”的回应则是，在现实世界中每个进程都会有摩擦力，指数增长会迅速变成Sigmoid函数。</p><p><img src="https://x.liuping.win/img/2f9980859411d7fe79d7d2b8656af422.png"/></p><p>还有网友开玩笑说，语言模型经常被形容为“随机吐出词汇的鹦鹉”，但真实的鹦鹉危险多了，有喙、爪子和伤害人的意图。</p><p><img src="https://x.liuping.win/img/1fc3c416ab27fad10cb8ba656d5ec9fd.png"/></p><p>LeCun补充道，澳大利亚凤头鹦鹉更凶狠，我呼吁对凤头鹦鹉实施6个月的管制。</p><p><strong>One More Thing</strong></p><p>对于影响力越来越大的AI暂停6个月提案，也有越来越多的人表达自己的观点。</p><p><strong>比尔盖茨</strong>对路透社表示“我不认为让一个特定的组织暂停就会解决这些问题。在一个全球性的行业中，暂停很难执行”。</p><p>据福布斯报道，<strong>谷歌前CEO埃里克施密特</strong>认为“监管部门大多数人对科技的理解还不足以正确规范其发展。另外如果在美国暂停6个月，只会让别的国家受益。”</p><p>与此同时，AI研究界另一股声音的影响力也逐渐加大。</p><p>由非赢利组织LAION-AI（Stable Diffusion训练数据提供者）发起的请愿书也有超过1400人签署。</p><p>这个项目呼吁建设公众资助的国际化超级AI基础设施，配备10万最先进的AI加速芯片，确保创新和安全。</p><p>就相当于粒子物理学界的CERN（欧洲核子研究组织）。</p><p>支持者包括LSTM之父Jürgen Schmidhuber，HuggingFace联合创始人Thomas Wolf等知名研究者。</p><p><img src="https://x.liuping.win/img/63c7d08eb5093b876ce4185d10ba199c.png"/></p><p>完整视频回放：https://www.youtube.com/watch?v=BY9KV8uCtj4&amp;t=33s</p><p>AI转写文本：https://gist.github.com/simonw/b3d48d6fcec247596fa2cca841d3fb7a</p><p>参考链接：[1]https://twitter.com/AndrewYNg/status/1644418518056861696[2]https://blogs.scientificamerican.com/observations/dont-fear-the-terminator/</p><!--         .taobao_tab{		position: fixed;		bottom:0;		right:0;		z-index: 10000;		width:320px;		height: 410px;	}	.taobao_tab .close {	position: absolute;	top: 2px;	right: -12px;	z-index: 10001;	width: 13px;	height: 13px;	background: none !important;}        	<a href="https://news.mydrivers.com/1/788/788013.htm" target="_blank" ><img src="https://news.mydrivers.com/1/788/788013.htm" width="13" height="13" alt="关闭" class="close"/><img src="https://static.cnbetacdn.com/article/2023/0408/97062c8854bf3d2.jpg" /></a>--> </div></body>
        </html>
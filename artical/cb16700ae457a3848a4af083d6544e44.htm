<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width,initial-scale=1"><meta charset="utf-8"><title>DeepMind AI在复杂游戏西洋陆军棋中挺进专家级</title><style>img {max-width: 90%;} body {text-align: center;}</style></head><body><h1>DeepMind AI在复杂游戏西洋陆军棋中挺进专家级</h1><p>另一个长期以来被认为是人工智能（AI）极难掌握的游戏又已经落入机器之手。总部位于伦敦的DeepMind公司制造的一种名为DeepNash的人工智能在战略游戏《西洋陆军棋》（Stratego）方面与人类专家不相上下，这种棋盘游戏需要在不完美的信息面前进行长期的战略思考。</p><hr><div class="article-content" id="artibody">
<p><img alt="Stratego_plateau.jpg" src="https://x.liuping.win/img/66983d2a48a075776e542ab122d1226d.jpg" title=""/></p><p>12月1日的《科学》杂志描述了这一成就，紧接着一项研究报告称人工智能可以玩《强权外交》，其中玩家必须在合作和竞争中进行谈判。</p><p>研究战略推理和游戏理论的计算机科学家迈克尔-韦尔曼（Michael Wellman）说："近年来，人工智能在质量上不同的游戏特征被征服--或掌握到新的水平--的速度相当惊人。《西洋陆军棋》和《强权外交》彼此之间有很大的不同，而且还拥有与已经达到类似里程碑的游戏明显不同的挑战性特征。"</p><p>《西洋陆军棋》的特点使其比国际象棋、围棋或扑克复杂得多，所有这些游戏都已被人工智能所掌握。在战略游戏中，两名玩家在棋盘上各放40个棋子，但不能看到对手的棋子是什么。目标是轮流移动棋子以消除对手的棋子并夺取旗帜。战略游戏的游戏树--所有可能的游戏方式的图形--有10535个状态，而围棋是10360个。游戏开始时，Stratego就有1066个可能的走法，这使双人德州扑克中的106个这样的开始情况相形见绌。</p><p>位于巴黎的DeepMind研究员朱利安-佩罗拉（Julien Perolat）说："Stratego中可能出现的结果数量之复杂，意味着在完全信息游戏上表现良好的算法，甚至那些对扑克有用的算法都不起作用。"</p><p><img alt="_xlarge.webp" src="https://x.liuping.win/img/076a8be6d4463688b9f46f294eeeac3d.webp" title=""/></p><p><strong>自学成才的人工智能在战略游戏围棋方面表现最好</strong></p><p>因此，佩罗拉特和同事们开发了DeepNash。这个人工智能的名字是对美国数学家约翰-纳什(John Nash)的致敬，他的工作导致了纳什均衡这一术语的出现，这是一组稳定的策略，所有的游戏参与者都可以遵循，这样就没有玩家通过改变自己的策略而获益。游戏可以有零个、一个或多个纳什均衡。</p><p>DeepNash将强化学习算法与深度神经网络相结合，以找到纳什均衡。强化学习涉及寻找最佳政策，以决定游戏的每个状态的行动。为了学习一个最佳政策，DeepNash与自己进行了55亿次游戏。如果一方获得奖励，另一方就会受到惩罚，而神经网络的参数--代表政策--也会相应地进行调整。最终，DeepNash收敛于一个近似的纳什均衡状态。与AlphaGo等之前的游戏AI不同，DeepNash不会通过游戏树搜索来优化自己。</p><p>在4月份的两个星期里，DeepNash在网络游戏平台Gravon上与人类战略家进行了竞争。在50场比赛之后，DeepNash在2002年以来所有Gravon战略游戏玩家中排名第三。"我们的工作表明，像Stratego这样复杂的游戏，涉及不完美的信息，不需要搜索技术来解决，"团队成员、驻巴黎的DeepMind研究员卡尔-图伊斯说。"这真是人工智能的一大进步。"</p><p><img alt="image1.png" src="https://x.liuping.win/img/1eff00fc7b6546d36123512854189379.png" title=""/></p><p>"结果令人印象深刻，"总部位于纽约的Meta AI的研究员诺姆-布朗同意，他领导的团队在2019年报告了玩起了基于扑克的AI Pluribus4。</p><p><strong>《强权外交》游戏的表现</strong></p><p>布朗和他在Meta AI的同事将目光投向了一个不同的挑战：建立一个能玩外交的人工智能，这是一个最多有七个玩家的游戏，每个玩家代表一战前欧洲的一个大国。目标是通过移动单位（舰队和军队）获得对供应中心的控制。重要的是，该游戏需要玩家之间的私下交流和积极合作，与围棋或战略游戏等双人游戏不同。</p><p>"当你超越双人零和游戏时，纳什均衡的概念对于与人类打好关系不再那么有用，"布朗说。</p><p>因此，该团队根据涉及人类玩家的在线版《强权外交》游戏的125261场数据训练其人工智能--名为Cicero。结合这些数据和一些自我游戏数据，Cicero的战略推理模块（SRM）学会了预测，对于给定的游戏状态和累积的信息，其他玩家的可能政策。利用这种预测，SRM选择了一个最佳的行动，并向Cicero的对话模块发出了它的"意图"。</p><p>对话模块建立在一个27亿个参数的语言模型上，该模型在互联网的文本上进行了预训练，然后利用人们玩的外交游戏的信息进行微调。考虑到来自SRM的意图，该模块产生了一个对话信息（例如，代表英国的西塞罗可能会问法国。"你想支持我加入比利时一方吗？"）。</p><p>在11月22日的《科学》论文中，该团队报告说，在40场在线游戏中，"Cicero AI取得了比人类玩家的平均分数高一倍以上的成绩，并在参加过多场游戏的参与者中排名前10%"。</p><p><strong>真实世界的行为</strong></p><p>布朗认为，能够与人类互动并对人类的次优甚至非理性行为进行解释的玩游戏的人工智能可以为现实世界的应用铺平道路。他说："如果你正在制造一辆自动驾驶汽车，你不想假设道路上的所有其他司机都是完全理性的，并且会表现得很好。Cicero是朝着这个方向迈出的一大步。我们仍然有一只脚在游戏世界里，但现在我们也有一只脚在现实世界里。"</p><p>威尔曼同意这一看法，但他说还需要更多的工作。他说："这些技术中的许多确实与娱乐游戏之外的现实世界应用有关，尽管如此，在某些时候，领先的人工智能研究实验室需要超越娱乐环境，并找出如何衡量我们真正关心的更小的现实世界'游戏'的科学进展。"</p> </div></body></html>
<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="用一种&quot;新的&quot;机器学习算法可以适应图像生成，从而创造、插值和循环新的音乐片段和流派。SethForsgren和HaykMartiros将稳定扩散（SD）算法适用于音乐，结果创造了一种新的奇怪的&quot;音乐机器&quot;。Riffusion的工作原理与SD相同，将文本提示变成新的、由人工智能生成的内容。主要的区别是，该算法经过专门的声波训练，可以以视觉形式描述音乐和音频。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/abb16353a2ef795c4267c27aabd25d98.webp">
            <meta property="og:url" content="https://x.liuping.win/artical/74579cd7097b5d0e5d57d0bfd6785c6b.htm">
            <meta property="og:title" content="Riffusion：基于AI的音乐生成 让贝多芬与Radiohead结合 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,Riffusion：基于AI的音乐生成 让贝多芬与Radiohead结合,x.liuping.win">
            <meta name="description" content="用一种&amp;quot;新的&amp;quot;机器学习算法可以适应图像生成，从而创造、插值和循环新的音乐片段和流派。SethForsgren和HaykMartiros将稳定扩散（SD）算法适用于音乐，结果创造了一种新的奇怪的&amp;quot;音乐机器&amp;quot;。Riffusion的工作原理与SD相同，将文本提示变成新的、由人工智能生成的内容。主要的区别是，该算法经过专门的声波训练，可以以视觉形式描述音乐和音频。">
            <title>Riffusion：基于AI的音乐生成 让贝多芬与Radiohead结合</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>Riffusion：基于AI的音乐生成 让贝多芬与Radiohead结合</h1><p>用一种"新的"机器学习算法可以适应图像生成，从而创造、插值和循环新的音乐片段和流派。Seth Forsgren和Hayk 
Martiros将稳定扩散（SD）算法适用于音乐，结果创造了一种新的奇怪的"音乐机器"。Riffusion的工作原理与SD相同，将文本提示变成新的、由人工智能生成的内容。主要的区别是，该算法经过专门的声波训练，可以以视觉形式描述音乐和音频。</p><hr><div class="article-content" id="artibody">
<p><img alt="2022-12-19-image-20-j_1100.webp" src="https://x.liuping.win/img/abb16353a2ef795c4267c27aabd25d98.webp" title=""/></p><p>正如Riffusion网站所解释的那样，声波图（或音频频率的频谱图）是表示声音片段的频率内容的一种视觉方式。X轴代表时间，而Y轴代表频率。每个像素的颜色给出了音频在其行和列给出的频率和时间的振幅。</p><p>Riffusion适应了稳定扩散视觉算法的V1.5版本，"没有任何修改"，只是进行了一些微调，以更好地处理与文本配对的声谱/音频谱图的图像。音频处理发生在模型的下游，而该算法也可以通过改变种子来生成提示的无限变化。</p><p><img alt="2022-12-19-image-21-j_1100.webp" src="https://x.liuping.win/img/d17fe9c9678358e0f8e5fd56e8459b0c.webp" title=""/></p><p>在生成新的声谱图后，Riffusion用Torchaudio将图像变成声音。人工智能已经接受了描绘声音、歌曲或流派的频谱图的训练，因此它可以根据各种文本提示生成新的声音片段。例如，像"贝多芬与Radiohead"这样的融合产物，这是一个很好的例子，说明另一个世界或不可思议的机器学习算法可以表现得很好。</p><p>在设计完理论后，Forsgren和Martiros将其全部整合到一个互动的网络应用中，用户可以在其中试验人工智能。Riffusion接受文本提示，并"实时无限地生成插值内容，同时将频谱图的时间线以3D形式可视化"。音频从一个片段平滑地过渡到另一个片段；如果没有新的提示，该应用程序将在同一提示的不同种子之间插值。</p><p>Riffusion建立在许多开源项目之上，即Next.js、React、Typescript、three.js、Tailwind和Vercel。该应用程序的代码也有自己的Github仓库。</p><p>Riffusion远不是第一个生成音频的人工智能，它是ML复兴的另一个后代，它已经启发了Dance Diffusion、OpenAI的Jukebox、Soundraw等的发展，当然这些都不会是最后一个。</p><p>了解更多：</p><p>https://www.riffusion.com/about<br/></p> </div></body>
            </html>
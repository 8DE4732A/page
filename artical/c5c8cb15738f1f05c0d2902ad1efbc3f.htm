<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="过去几个月里，由ChatGPT引发的AI热潮向人类展现了通用语言模型的生产力前景。就在聊天机器人逐渐变成生产力工具之时，利用通用语言模型驱动真正的机器人也已经提上日程。本周老牌AI大厂谷歌与柏林工业大学的研究人员联合发布PaLM-E视觉语言模型，通过同时处理图像和语言文本，解锁人类与机器人交互的新篇章。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/5aad4b6bd282481442d43d858c3fd715.png">
        <meta property="og:url" content="https://x.liuping.win/artical/c5c8cb15738f1f05c0d2902ad1efbc3f.htm">
        <meta property="og:title" content="AI大战进入实体化阶段 谷歌刚发布的PaLM-E模型有哪些亮点？ - x.liuping.win">
        <meta name="keywords" content="Google 谷歌,AI大战进入实体化阶段 谷歌刚发布的PaLM-E模型有哪些亮点？,x.liuping.win">
        <meta name="description" content="过去几个月里，由ChatGPT引发的AI热潮向人类展现了通用语言模型的生产力前景。就在聊天机器人逐渐变成生产力工具之时，利用通用语言模型驱动真正的机器人也已经提上日程。本周老牌AI大厂谷歌与柏林工业大学的研究人员联合发布PaLM-E视觉语言模型，通过同时处理图像和语言文本，解锁人类与机器人交互的新篇章。">
        <title>AI大战进入实体化阶段 谷歌刚发布的PaLM-E模型有哪些亮点？</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>AI大战进入实体化阶段 谷歌刚发布的PaLM-E模型有哪些亮点？</h1><p>过去几个月里，由ChatGPT引发的AI热潮向人类展现了通用语言模型的生产力前景。就在聊天机器人逐渐变成生产力工具之时，<span style="">利用通用语言模型驱动真正的机器人也已经提上日程</span>。本周老牌AI大厂谷歌与柏林工业大学的研究人员联合发布PaLM-E视觉语言模型，<span style="">通过同时处理图像和语言文本，解锁人类与机器人交互的新篇章</span>。</p><hr><div class="article-content" id="artibody">
<p><img alt="（预印本论文，来源：谷歌、柏林工业大学）" id="0" src="https://x.liuping.win/img/5aad4b6bd282481442d43d858c3fd715.png"/><br/>（预印本论文，来源：谷歌、柏林工业大学）</p><p>顾名思义，PaLM-E模型源自于谷歌的大型语言模型PaLM，E指的就是具象化（Embodied）。<span style="">通过将通用语言模型与视觉转换模型ViT相结合，PaLM-E成功实现让AI同时具备“理解文字”和“读懂图片”的能力，不仅能够输出文字，还能输出指令使得机器人的智能化跃上一个新的台阶</span>。</p><p>研究人员介绍称，PaLM和ViT的结合，使得PaLM-E的参数量最高可达5620亿组，也是全球已知的最大视觉语言模型。</p><p>回归到资本市场最关心的问题，这个听上去很厉害的AI模型，到底能干什么事情呢？对此研究人员也给出一系列案例，帮助外界理解这个模型的妙处。</p><p><img alt="（PaLM-E模型的案例，来源：谷歌、柏林工业大学）" id="1" src="https://x.liuping.win/img/51b2f3ca33fb908911a65ffd3a2b7d0a.png"/><br/>（PaLM-E模型的案例，来源：谷歌、柏林工业大学）</p><p>首先，具备视觉属性的AI模型将拥有<span style="">解读图片并进行思维推理</span>的能力。例如可以通过一张禁行交通标志（除自行车外）的图片，来解答“我能否在这条马路上骑自行车”；通过OCR识别餐馆的手写菜单，能进行账单的计算；或是通过识别一系列烘焙材料的照片，向机器人传达“制作蛋糕胚”的流程。</p><p>在AI模型与机器人结合的实验演示中，机器人得到“从抽屉里拿出米饼”的指令后，能够顺利地从十多个开放式抽屉中找到米饼，拿给研究人员。</p><p><img alt="（来源：谷歌、柏林工业大学）" id="2" src="https://x.liuping.win/img/a82d1e807724d9eda025b2679325f55e.png"/><br/></p><p>在后续的实验中，研究人员还要求机器人“将所有色块按颜色堆放到不同角落”的指令，以及将“绿色色块推到乌龟旁边”的指令，即便机器人之前没有见过这只乌龟摆件，也能顺利地完成任务。</p><p><img alt="（来源：谷歌、柏林工业大学）" id="3" src="https://x.liuping.win/img/5075c1e2c9ecfdac1b2d2356d9e70bc6.png"/><br/></p><p>虽然从演示视频中来看，受限于演示机器人较为简单的设计，执行指令的时候仍显得“笨手笨脚”。但随着PaLM-E模型赋予机器思考如何执行人类指令的能力，工业应用和工业设计上的突破也指日可待。或许在不久的将来，就会出现一款风靡全球的智能机器人硬件。</p><p>值得一提的是，作为AI大战的老对手，微软也已经在“图像+语言模型”的路数上有所布局。在今年2月底发表的研究中，微软就展现了如何使用ChatGPT为大疆Tello无人机编写“找饮料”程序的案例。</p><p><img alt="（来源：微软）" id="4" src="https://x.liuping.win/img/040254d1e9c7ce9efc3ff08d3a0bd31c.png"/>                          <br/></p> </div></body>
        </html>
<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="“为了计算和人类的未来，我捐出世界上第一台DGX-1。”2016年8月，英伟达创始人黄仁勋，带着一台装载了8块P100芯片的超级计算机DGX-1，来到了OpenAI的办公大楼。在现场人员到齐后，老黄拿出记号笔，在DGX-1的机箱上写下这句话。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/18610ce868d944974e07947538fd9717.webp">
        <meta property="og:url" content="https://x.liuping.win/artical/c7ec068e1fc93bf962e967a75a336b26.htm">
        <meta property="og:title" content="英伟达正在“垄断”AI产业，国内厂商准备好了吗？ - x.liuping.win">
        <meta name="keywords" content="nVIDIA,英伟达正在“垄断”AI产业，国内厂商准备好了吗？,x.liuping.win">
        <meta name="description" content="“为了计算和人类的未来，我捐出世界上第一台DGX-1。”2016年8月，英伟达创始人黄仁勋，带着一台装载了8块P100芯片的超级计算机DGX-1，来到了OpenAI的办公大楼。在现场人员到齐后，老黄拿出记号笔，在DGX-1的机箱上写下这句话。">
        <title>英伟达正在“垄断”AI产业，国内厂商准备好了吗？</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>英伟达正在“垄断”AI产业，国内厂商准备好了吗？</h1><p><strong>“</strong><strong>为了计算和人类的未来，我捐出世界上第一台 DGX-1 。 ”</strong>2016 年 8 月，英伟达创始人黄仁勋，带着一台装载了 8 块 P100 芯片的超级计算机 DGX-1 ，来到了 OpenAI 的办公大楼。在现场人员到齐后，老黄拿出记号笔，在 DGX-1 的机箱上写下这句话。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/18610ce868d944974e07947538fd9717.webp"/><br/></p><p>与其一同前往的还有特斯拉和 OpenAI 的创始人，埃隆马斯克。</p><p><img src="https://x.liuping.win/img/17479bada2c65bd7d809174041bd6113.webp"/><br/></p><p>这次 OpenAI 之行，老黄不为别的，就是为了把这台刚出炉的超算送给 OpenAI ，给他们的人工智能项目研究加一波速。</p><p><strong>这台DGX-1价值超过百万，是英伟达超过3000名员工，花费三年时间打造。</strong></p><p>这台 DGX-1 ，能把 OpenAI 一年的训练时间，压缩到短短一个月。</p><p>而这，是他对人工智能未来的豪赌，加的一波注。</p><p>七年之后，在前不久的 GTC 大会上，老黄穿着皮衣，拿着芯片，整个宣讲不离 AI 。</p><p>似乎是在告诉各位， AI 的时代，我英伟达，就要称王了，当年的豪赌，他赢了！</p><p><img src="https://x.liuping.win/img/18d44dfe2a03e11b5c8df6aaee910d77.webp"/><br/></p><p>这么说吧，在去年经历一波矿难之后，不少人都以为曾靠着矿潮狂赚一笔的英伟达，会在矿难之下市值暴跌，一蹶不振。</p><p><strong>但实际情况却有点微妙……</strong></p><p>英伟达的股价在跌了大半年之后，从十月份开始，一路上涨，到现在，整个英伟达市值已经涨回到了 6500 亿美元，是 AMD 的 4 倍，英特尔的 6 倍。</p><p><img src="https://x.liuping.win/img/f3e304cd50961a4d7809261821eeb364.webp"/><br/></p><p>瞧瞧，这还是当年那个求着各位买显卡的老黄嘛？</p><p>而让英伟达的股价疯涨的，那便是他们从十多年前就开始押注的 AI 计算。</p><p>给大家一个数据，从 15 年后，英伟达的 GPU 在超算中心的市场份额就一路上涨，这几年稳居 90% 左右。</p><p><img src="https://x.liuping.win/img/b10fe8ad96beb71ef530d87814c9b958.webp"/><br/></p><p><strong>在独立 GPU 市场上，英伟达的市场占有率也一度超过 80% 。</strong></p><p><img src="https://x.liuping.win/img/d34fd22590733ab0e561b4e031f5e0c5.webp"/><br/></p><p>另外，包括 YouTube 、Cat Finder 、 AlphaGo 、 GPT-3 、 GPT-4 在内， AI 历史上那些叫得出名的玩意，几乎都是在英伟达的硬件上整出来的。</p><p>英伟达的硬件，仿佛就是新时代的内燃机，载着 AI 时代不断前进。</p><p>差友们可能会有点疑问，为什么在 AI 爆发的时代，好像就只有老黄有好处，其它的显卡生产商们的显卡不能训练 AI 嘛？</p><p><strong>能训练，但只能训练一点点。</strong></p><p>为啥？</p><p>这就不得不提到英伟达从 2006 年就开始着手开发一个东西—— CUDA （ 统一计算设备架构 ）。</p><p>差评君简单解释一下它是干嘛的，当你想要计算一些比较庞大的运算问题时，通过 CUDA 编程，你就能充分利用 GPU 的并行处理能力，从而大幅提升计算性能。</p><p><strong>差评君说一个听来的比喻。</strong></p><p>CPU 就好比是个数学教授， GPU 就是 100 个小学生，放一道高数题下来那 100 个小学生可能会懵逼；但是放 100 道四则口算题下来，那 100 个小学生同时做肯定比数学教授快多了。</p><p><img src="https://x.liuping.win/img/e0922ba4323fa547aa603ce9068f8d76.webp"/><br/></p><p>深度学习就是上面的例子中那 100 道口算题，那个让 GPU 处理器并行运算的 “ 工具 ” 就叫 CUDA 。</p><p>一般来说，使用 CUDA 和不使用 CUDA ，两者在计算速度上往往有数倍到数十倍的差距。</p><p>既然 CUDA 这么有用，为什么其它的 GPU 厂商不去搞个竞品呢？</p><p><strong>不是不去搞啊，而是他们真的没想到！</strong></p><p>在早期， GPU 的作用只是为了加速图形渲染，各大厂商们认为它就是一个图形专用计算芯片，并没有想到把 GPU 用在其它通用计算方面。至于拿来做深度学习？以那个年代的 AI 能力，一是没有太大的必要，二是也没有人觉得它有用。</p><p><img src="https://x.liuping.win/img/f15cacb05c7a7f8ebd40a285ec37cb7d.webp"/><br/></p><p>英伟达深度学习团队的布莱恩在聊到 CUDA 时这么说道：</p><p>“ 在 CUDA 推出十年以来，整个华尔街一直在问英伟达，为什么你们做了这项投入，却没有人使用它？他们对我们的市值估值为 0 美元。 ”</p><p><img src="https://x.liuping.win/img/3c0ff3d9bce5e526e79d437c141a215b.webp"/><br/></p><p>不过说没人用也是过于严重了。</p><p>其实早在 2012 年，多伦多大学的 Alex Krizhevsky 就在 ImageNet 计算机视觉挑战赛中，利用 GPU 驱动的深度学习击败了其它对手，当时他们使用的显卡是 GTX580 。</p><p><img src="https://x.liuping.win/img/f9081877d90216128b7e93fa991c3953.webp"/><br/></p><p>在这之后又经过了 4 年，那些搞深度学习的人才突然意识到， GPU 的这种设计结构方式，在训练 AI 的速度上，真的是 CPU 不能比的。</p><p>而拥有了 CUDA 原生支持的英伟达 GPU ，更是首要之选。</p><p>到现在，资本们已经看到了 AI 的重要之处，为什么大家都还在卷 AI 模型，而不去卷老黄的市场呢？</p><p><strong>原因在于，它们已经很难再拿到 AI 加速芯片的入场券了。在人工智能产业上，整个深度学习的框架已经是老黄的形状了。</strong></p><p>AI 发展的数十年间，英伟达通过对 CUDA 开发和社区的持续投入， CUDA 和各类 AI 框架深度绑定。</p><p>当今使用排行靠前的各类 AI 框架，就没有不支持 CUDA 的，也就是说你想要让你的深度学习跑的快？买张支持 CUDA 的高性能卡是最好的选择，说人话就是——买 N 卡吧。</p><p><img src="https://x.liuping.win/img/6f50b74a4c18291ac59848adbada5886.webp"/><br/></p><p>当然，在 CUDA 大力发展期间，也有其它公司在尝试着打破英伟达这种接近垄断的局面。</p><p>2008 苹果就提过出 OpenCL 规范，这是一个统一的开放 API ，旨在为各种不同的 GPU 型号提供一个规范，用以开发类似 CUDA 的通用计算软件框架。</p><p>但是，通用就意味着不一定好用。</p><p><img src="https://x.liuping.win/img/f7d9ae22b475788b47f7bbe0cfe61ff9.webp"/><br/></p><p>因为各大厂商 GPU 的型号繁而复杂，为了适应各种硬件，驱动版本也多如牛毛，质量参差不齐。而且缺少对应的厂商进行针对性的优化，所以，无论是哪一个版本的 OpenCL ，在同等算力下，都比不过使用 CUDA 的速度。</p><p>而且恰恰是因为 OpenCL 的通用性，想要开发支持 OpenCL 的框架，要比开发CUDA 的复杂不少。原因还是同一个，缺少官方的支持，看看英伟达对CUDA开发的工具支持吧，CUDA Toolkit，NVIDIA GPU Computing SDK以及NSight等等。</p><p>OpenCL这边，就略显寒酸了……</p><p>这就导致如今能支持 OpenCL 的深度学习框架寥寥无几。</p><p>举个很简单的例子，当下最火的框架 PyTorch ，就连官方都没有专门对OpenCL进行支持，还得靠着第三方开源项目才能用。</p><p><img src="https://x.liuping.win/img/e6618e567d1b9d32401333b42c1f0bfc.webp"/><br/></p><p>那同为显卡供应商的 AMD ，在面对老黄如日中天的 CUDA 时，除了 OpenCL ，有没有自己的解决办法呢？</p><p>方法确实是有，但效果也确实不咋的。</p><p><strong>2016 年 AMD 发布了全新的开放计算平台—— ROCm ，对标的就是英伟达的 CUDA ，最关键的一点是，它还在源码级别上对 CUDA 程序进行支持。</strong></p><p>你看，就算是老黄的死对头 AMD ，想的也不是另起炉灶，而是降低自己适配 CUDA 的门槛……</p><p>但是，时至今日， ROCm 依然还是只支持 Linux 平台，可能也是用的人太少了，有点摆烂的味道，毕竟，既然你支持 CUDA ，那我为什么要费尽心力去给你的 ROCm 专门编写一套支持框架呢？</p><p><img src="https://x.liuping.win/img/508b850bba7bb8de966d7d4003206b36.webp"/><br/></p><p>同年，Google也有了行动，但毕竟不是芯片制造商，Google只是推出了自己的 TPU 平台，专门针对自家的 TensorFlow 框架进行优化，当然原生支持的最好的也只有 TensorFlow 了。</p><p>至于英特尔那边，也推出了一个 OneAPI ，对标老黄的 CUDA ，不过由于起步较晚，现在还处于发展生态的环节，未来会怎样还不太好说。</p><p>所以靠着先发优势还有原生支持，导致现在的深度学习，基本上离不开英伟达的 GPU 和他的 CUDA 。</p><p><img src="https://x.liuping.win/img/edf222148de90e19627621d7dffa562d.webp"/><br/></p><p>最近大火的 ChatGPT ，就用了老黄的 HGX 主板和 A100 芯片，而老黄对此也是很有自信的说道：</p><p>“ 现在唯一可以实际处理 ChatGPT 的 GPU ，那就只有我们家的 HGX A100 。 ”</p><p>没错，没有其它可用的了，这就是老黄的有恃无恐。</p><p><img src="https://x.liuping.win/img/0a7b1c8024e792c87b2933788fa89f61.webp"/><br/></p><p>而随着 OpenAI 对大模型 AI 的成功验证，各家巨头对大模型 AI 的纷纷入局，英伟达的卡已经立马成了抢手货。</p><p><img lazyload="https://x0.ifengimg.com/res/2023/EB00937306AE4273B6890DDA4BEF8CD5A852E8D8_size278_w600_h321.png" src="https://x.liuping.win/img/9684d159f3ab799df6e201372460697c.png"/><br/></p><p>所以如今的 AI 创业公司，出现了一件很有意思的现象，在他们的项目报告上，<strong>往往会搭上一句我们拥有多少块英伟达的 A100 。</strong></p><p>当大家在 AI 行业纷纷投资淘金时，英伟达就这样靠着给大家卖水——提供 AI 加速卡，大赚特赚，关键还在于，只有它卖的水能解渴。</p><p>因为它的硬件以及工具集，已经能影响到整个 AI 产业的战局和发展速度了。</p><p><img lazyload="https://x0.ifengimg.com/res/2023/5025B378437226A31F06118B1AF84A96C07628F4_size99_w909_h410.png" src="https://x.liuping.win/img/db7d330fa94d7a2b47471bbb9528b2f3.png"/><br/></p><p>更可怕的是，英伟达的优势已经形成了一种壁垒，这壁垒厚到就连全球第二大 GPU 厂商 AMD 都没有办法击穿。</p><p>所以在 AI 大浪滔天的现在，能整出属于自己的 AI 大模型固然重要，但差评君却觉得，啥时候能有自己的英伟达和 CUDA 也同样不可小觑。</p><p>当然，这条路也更难。</p><p><img lazyload="https://x0.ifengimg.com/res/2023/CD0D7FA4CD261DCC4C5D8CB0A2B2A3366D0F2957_size80_w717_h772.png" src="https://x.liuping.win/img/92a084d4f5c7886979cfaaf5cefd6218.png"/><br/></p><p>最后，差评君觉得在未来，我们需要抓紧突破的，绝对不只是对人工智能大模型相关的研究，更为重要的是整个计算芯片的设计，制造，以及 AI 生态的建设。</p><p>新的工业革命已经到来， AI 技术的发展不仅加速了人类生产力的发展，也加速了那些落后产能的淘汰，现在各行各业都处在变革的前夕。</p><p><strong>强者越强，弱者无用。虽然这句话很残酷，但在</strong><strong>AI </strong><strong>领域</strong><strong>，</strong><strong>如果不奋力追上，</strong><strong>可能真的已经不需要 “ 弱者 ” 了。</strong></p> </div></body>
        </html>
<!DOCTYPE html>
        <html><head>
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta charset="utf-8">
        <meta property="og:type" content="article">
        <meta property="og:locale" content="zh_CN">
        <meta property="og:description" content="AI世界如今最大的赢家是谁？毫无疑问是黄仁勋的NVIDIA，布局早，技术强，根本找不到对手，“躺着”就可以挣大钱了。现在，NVIDIA又公布了最新一代HopperH100计算卡在MLPerfAI测试中创造的新纪录。">
        <meta property="og:site_name" content="x.liuping.win">
        <meta property="og:image" content="https://x.liuping.win/img/6cd577eac392cde6774452281a5b8a64.jpg">
        <meta property="og:url" content="https://x.liuping.win/artical/ba32c4f75d71d368a7ddc687dc65a6ca.htm">
        <meta property="og:title" content="NVIDIA H100计算卡强势垄断AI：性能暴涨4.5倍 对手不存在的 - x.liuping.win">
        <meta name="keywords" content="nVIDIA,NVIDIA H100计算卡强势垄断AI：性能暴涨4.5倍 对手不存在的,x.liuping.win">
        <meta name="description" content="AI世界如今最大的赢家是谁？毫无疑问是黄仁勋的NVIDIA，布局早，技术强，根本找不到对手，“躺着”就可以挣大钱了。现在，NVIDIA又公布了最新一代HopperH100计算卡在MLPerfAI测试中创造的新纪录。">
        <title>NVIDIA H100计算卡强势垄断AI：性能暴涨4.5倍 对手不存在的</title>
        <style>img {max-width: 90%;} body {text-align: center;}</style>
        </head>
        <body><h1>NVIDIA H100计算卡强势垄断AI：性能暴涨4.5倍 对手不存在的</h1><p>AI世界如今最大的赢家是谁？毫无疑问是黄仁勋的NVIDIA，布局早，技术强，根本找不到对手，“躺着”就可以挣大钱了。现在，NVIDIA又公布了最新一代Hopper H100计算卡在MLPerf AI测试中创造的新纪录。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/6cd577eac392cde6774452281a5b8a64.jpg"/></p><p>Hopper H100早在2022年3月就发布了，GH100 GPU核心，台积电4nm工艺，800亿晶体管，814平方毫米面积。</p><p>它集成<strong>18432个CUDA核心、576个Tensor核心、60MB二级缓存</strong>，搭配6144-bit位宽的六颗HBM3/HBM2e高带宽内存，支持第四代NVLink、PCIe 5.0总线。</p><p><strong>相比于ChatGPT等目前普遍使用的A100，H100的理论性能提升了足足6倍。</strong></p><p>不过直到最近，H100才开始大规模量产，微软、谷歌、甲骨文等云计算服务已开始批量部署。</p><p><img src="https://x.liuping.win/img/ddb8dadaa3f818c82a63f70161431703.png"/></p><p><img src="https://x.liuping.win/img/6c7510f5be9ceb8b0c6d40c841dea5bd.png"/></p><p>MLPerf Inference是测试AI推理性能的行业通行标准，最新版本v3.0，也是这个工具诞生以来的第七个大版本更新。</p><p><strong>对比半年前的2.1版本，NVIDIA H100的性能在不同测试项目中提升了7-54％不等，其中进步最大的是RetinaNet全卷积神经网络测试，3D U-Net医疗成像网络测试也能提升31％。</strong></p><p><img src="https://x.liuping.win/img/cb939a6ed0dcbca761d2ccfe6264c9b8.png"/></p><p><strong>对比A100，跨代提升更是惊人，无延迟离线测试的变化幅度少则1.8倍，多则可达4.5倍，延迟服务器测试少则超过1.7倍，多则也能接近4倍。</strong></p><p>其中，DLRM、BERT训练模型的提升最为显著。</p><p>NVIDIA还颇为羞辱性地列上了Intel最新数据中心处理器旗舰至强铂金8480+的成绩，虽然有56个核心，但毕竟术业有专攻，让通用处理器跑AI训练实在有点为难，可怜的分数不值一提，BERT 99.9％甚至都无法运行，而这正是NVIDIA H100的最强项。</p><p><img src="https://x.liuping.win/img/bddeb5876a55bd83165c9ca4236aa684.png"/></p><p>此外，NVIDIA还第一次公布了<strong>L4 GPU</strong>的性能。</p><p>它基于最新的Ada架构，<strong>只有Tensor张量核心</strong>，支持FP8浮点计算，主要用于AI推理，也支持AI视频编码加速。</p><p><strong>对比上代T4，L4的性能可加速2.2-3.1倍之多，最关键的是它功耗只有72W，再加上单槽半高造型设计，可谓小巧彪悍。</strong></p><p>几乎所有的大型云服务供应商都部署了T4，升级到L4只是时间问题，Google就已经开始内测。</p> </div></body>
        </html>
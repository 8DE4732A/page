<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="又一位大佬对聊天机器人的投资热发出警告。当地时间2月14日，谷歌副总裁、有“互联网之父”之称的温特·瑟夫（Vint&nbsp;Cerf）在美国加利福尼亚州一场会议上表示，不要因为ChatGPT“是一个热门话题”，这项技术“很酷”，就争先恐后地投资对话式人工智能（AI）。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/25a6c0e99ed92cb815b387dea59ff2e4.jpg">
            <meta property="og:url" content="https://x.liuping.win/artical/fe8de91cb2877930cc92db914adfe809.htm">
            <meta property="og:title" content="“互联网之父”警告：不要盲目投资ChatGPT 应该设法驯服技术 - x.liuping.win">
            <meta name="keywords" content="人物,“互联网之父”警告：不要盲目投资ChatGPT 应该设法驯服技术,x.liuping.win">
            <meta name="description" content="又一位大佬对聊天机器人的投资热发出警告。当地时间2月14日，谷歌副总裁、有“互联网之父”之称的温特·瑟夫（Vint&amp;nbsp;Cerf）在美国加利福尼亚州一场会议上表示，不要因为ChatGPT“是一个热门话题”，这项技术“很酷”，就争先恐后地投资对话式人工智能（AI）。">
            <title>“互联网之父”警告：不要盲目投资ChatGPT 应该设法驯服技术</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>“互联网之父”警告：不要盲目投资ChatGPT 应该设法驯服技术</h1><p>又一位大佬对聊天机器人的投资热发出警告。当地时间2月14日，谷歌副总裁、有“互联网之父”之称的温特·瑟夫（Vint Cerf）在美国加利福尼亚州一场会议上表示，不要因为ChatGPT“是一个热门话题”，这项技术“很酷”，就争先恐后地投资对话式人工智能（AI）。</p><hr><div class="article-content" id="artibody">
<p> <img src="https://x.liuping.win/img/25a6c0e99ed92cb815b387dea59ff2e4.jpg"/></p><p>“每个人都在谈论ChatGPT或谷歌版的对话式AI（Bard），但我们知道，它们并不总是按照我们希望的方式运行。”瑟夫表示，不要仅仅因为这项技术“真的很酷”就去投资，它甚至无法一直保持正常工作，会出现错误。</p><p>瑟夫自2005年起担任谷歌副总裁兼首席互联网顾问，是TCP/IP协议和互联网架构的共同设计者，被认为是“互联网之父”之一。他发出警告之际，谷歌、Meta和微软等大型科技公司正在对话式AI领域展开竞争，努力改进仍在出现错误的聊天机器人。</p><p>“如果你觉得‘ChatGPT是个热门话题，我可以把它卖给投资者，所有人都会向我投钱。’我希望你不要那样做。”瑟夫对想要投资对话式AI的人发出警告，“请三思而后行，因为我们无法预测这些技术会带来什么。”</p><p>瑟夫认为，最关键的问题不在于技术，而是在使用技术的人类，“许多人会（利用技术）去做有利于自己而非他人的事情。我们必须记住这一点，并慎重考虑如何使用这些技术。”</p><p>瑟夫举出例子，此前他曾要求聊天机器人提供自己的传记，机器人的答案虽然真实，但其中也包含不准确的地方，“如果只是一个不真实的故事也还好。但如果机器人向他人提供错误建议……这可能会引发医疗事故。”</p><p>无独有偶。就在昨天，谷歌董事长约翰·亨尼斯（John Hennessy）同样警示称，生成人工智能距离成为真正对大众有用的工具，还需要一到两年的时间。他表示，旗下的聊天机器人Bard仍在给出错误的答案，在推出Bard之前，需要先解决准确性方面的问题。</p><p>“我们应该研究如何最大限度地减少最坏情况发生的可能性，这非常重要。”瑟夫表示，“我认为，像我这样的工程师应该设法‘驯服’这些技术，使它们无法对人类造成伤害。”</p> </div></body>
            </html>
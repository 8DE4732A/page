<!DOCTYPE html>
            <html><head>
            <meta name="viewport" content="width=device-width,initial-scale=1">
            <meta charset="utf-8">
            <meta property="og:type" content="article">
            <meta property="og:locale" content="zh_CN">
            <meta property="og:description" content="这两天，网络疯传一条关于杭州市政府3月1号取消限行的“新闻稿”。然而，反转来得很快。据浙江之声报道，真相是：16日下午，杭州某小区业主群讨论ChatGPT，一位业主开玩笑说尝试用它写篇杭州取消限行的新闻稿，随后在群里直播了使用ChatGPT的写作过程，还把文章发在群里。有些业主不明就里，截图转发，导致失实信息被广泛传播。">
            <meta property="og:site_name" content="x.liuping.win">
            <meta property="og:image" content="https://x.liuping.win/img/ce96f044db8dff65e89b4e94593f6b5d.jpg">
            <meta property="og:url" content="https://x.liuping.win/artical/73d0e8c01898e88ea12c79b7806fa75b.htm">
            <meta property="og:title" content="当ChatGPT学会了写假新闻 - x.liuping.win">
            <meta name="keywords" content="AI 人工智能,当ChatGPT学会了写假新闻,x.liuping.win">
            <meta name="description" content="这两天，网络疯传一条关于杭州市政府3月1号取消限行的“新闻稿”。然而，反转来得很快。据浙江之声报道，真相是：16日下午，杭州某小区业主群讨论ChatGPT，一位业主开玩笑说尝试用它写篇杭州取消限行的新闻稿，随后在群里直播了使用ChatGPT的写作过程，还把文章发在群里。有些业主不明就里，截图转发，导致失实信息被广泛传播。">
            <title>当ChatGPT学会了写假新闻</title>
            <style>img {max-width: 90%;} body {text-align: center;}</style>
            </head>
            <body><h1>当ChatGPT学会了写假新闻</h1><p>这两天，网络疯传一条关于杭州市政府3月1号取消限行的“新闻稿”。然而，反转来得很快。据浙江之声报道，真相是：16日下午，杭州某小区业主群讨论ChatGPT，一位业主开玩笑说尝试用它写篇杭州取消限行的新闻稿，随后在群里直播了使用ChatGPT的写作过程，还把文章发在群里。有些业主不明就里，截图转发，导致失实信息被广泛传播。</p><hr><div class="article-content" id="artibody">
<p><img src="https://x.liuping.win/img/ce96f044db8dff65e89b4e94593f6b5d.jpg"/></p><p>原来，这是一场由AI写作引发的乌龙，让人哭笑不得。事后，涉事业主在群里道歉。这件事情也看似了结，却结结实实给我们提了个醒：人工智能制作的假新闻，看起来比那些网友粗制滥造的谣言更像“新闻”，也势必会引发更广泛的传播。</p><p>其实，我们早就应该明白，无所不能的AI，当然也可以造谣，或者准确地说，也可以被用来造谣，以及无意中形成谣言。</p><p>近些年，在社交平台的席卷下，人人皆可创作，内容的庞杂与劣质、传播的失真与不确定性，都一再被诟病。现在，不仅用户可以生产内容，AI也可以，信息池也就更加杂乱了。有些时候，谣言的制造者和传播者都是无意识的，他们有的是误以为真，有的是在不确定真假的情况下私自分享，当这两种情形的量足够大时，谣言传播便形成了规模。</p><p>关于杭州取消限行，有杭州朋友一周前就在群里讨论，期间大家也陆陆续续分享了一些各自看到的信息，其中就包括这份ChatGPT写的“新闻稿”，一开始还有朋友在群里问“消息保熟吗”，回答当然也是不确定的。不确定，就是我们不得不面对的社交媒体时代的信息生态。</p><p>在最开始分享ChatGPT创作的那个微信群，至少会有“肇事者”的解释，以及内容诞生的来龙去脉，但是被分享到更多群聊、朋友圈、短视频平台后，“新闻稿”就成了孤零零的消息，大众不知道它从何而来、什么时候发出的，只能看见内容本身，然后将信将疑，“且传且围观”。</p><p>或许有人会说，最后解释清楚不就行了，没必要担心。但问题是，廓清真相需要一个过程，真相覆盖谣言也需要一定的时间。而且，这还只是一个关于限行的假新闻，如果是和股市、投资等商业活动有关呢？市场变幻莫测，必然会受到假新闻的影响，最终给一些投资者、从业者甚至消费者带来损失。</p><p>科技是一把双刃剑，AI也不例外。我们当然要积极地拥抱新技术、新事物，让它们为人类社会的文明与进步提供助力甚至是动力，但同时也要注意规避潜在的问题和风险，且这个工作有必要尽可能提前。现在，ChatGPT写出了以假乱真的“新闻”，就是一次警告。</p><p>法律是科技的缰绳，我们要始终确保科技驶入正确的方向。当发明家造出第一辆汽车的时候，我们就应该想到《交通法》，面对AI，同样如此。在可以预见的将来，关于AI的立法，一定会逐渐补位，但我们要对这一事项有充分的预见性，以及行动的迫切性。</p><p>值得一提的是，被称为全球首部人工智能立法的欧盟《人工智能法案》，将于3月底在欧洲议会进行投票。不久前，马斯克也表示，“AI安全需要立法保护，无论是飞机、汽车还是医疗，任何先进技术都可能威胁人类安全，而AI对于人类来说，则是一个更大的安全隐患。”为AI立法的共识，并不难达成。</p><p>技术的问题，需要技术化地解决。比如，能否通过程序上的设置，给AI的假设性创作打上“纯属虚构”、且无法抹掉的标签？类似的修补和规范，也有待探索。</p><p>当我们在为ChatGPT打开的新世界而激动万分时，那一丝冷静，也必不可少。</p> </div></body>
            </html>